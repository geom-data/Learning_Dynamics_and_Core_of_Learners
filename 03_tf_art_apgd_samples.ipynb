{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bae8e9f",
   "metadata": {},
   "source": [
    "# ART APGD sample generation (TF2.10)\n",
    "\n",
    "Generate APGD-CE adversarial samples using ART against:\n",
    "- $\\mathcal{U}^{(0)}$: baseline ensemble (4 ResNet + 4 VGG probability models)\n",
    "- $\\mathcal{U}^{(1)}$: first immunized generation ensemble\n",
    "\n",
    "Outputs are saved under `data/adversarial_samples/apgdce_ART/` as `.npz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9109ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils import load_yaml\n",
    "\n",
    "PATHS = load_yaml(\"./configs/paths.yaml\")\n",
    "EXP   = load_yaml(\"./configs/exp.yaml\")\n",
    "\n",
    "data_root   = PATHS[\"data_root\"]\n",
    "tf_model_dir = PATHS[\"tf_model_dir\"]\n",
    "apgd_out    = PATHS[\"apgd_out\"]\n",
    "\n",
    "seed = int(EXP[\"seed\"])\n",
    "apgd_cfg = EXP[\"art_apgd\"]\n",
    "APGD_SETTINGS = {\n",
    "    \"weak\":   (0.5, 0.2, 2,  4),\n",
    "    \"strong\": (0.7, 0.2, 10, 4),\n",
    "}\n",
    "APGD_OUT = Path(apgd_out)\n",
    "APGD_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tf_model_dir = Path(tf_model_dir)\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "(x_all, y_all), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_all  = y_all.reshape(-1).astype(np.int64)\n",
    "y_test = y_test.reshape(-1).astype(np.int64)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_all, y_all,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=y_all\n",
    ")\n",
    "\n",
    "# normalize to [0,1]\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_val   = x_val.astype(np.float32) / 255.0\n",
    "x_test  = x_test.astype(np.float32) / 255.0\n",
    "\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_val   = y_val.astype(np.int64)\n",
    "\n",
    "from source.utils import make_train_chunks\n",
    "\n",
    "splits: List[Tuple[str, np.ndarray, np.ndarray]] = []\n",
    "splits.extend(make_train_chunks(x_train, y_train, chunk_size=10000))\n",
    "splits.append((\"val\",  x_val,  y_val))\n",
    "splits.append((\"test\", x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5a1ef",
   "metadata": {},
   "source": [
    "## Load ensembles for $\\mathcal{U}^{(0)}$\n",
    "\n",
    "We load probability-output Keras models (`.keras`) and build an average-probability ensemble for ART."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "U0_GLOB = [\n",
    "    str(tf_model_dir / \"resnet_*.keras\"),\n",
    "    str(tf_model_dir / \"vgg*_raw.keras\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.helpers03note import gen_for_ensemble, merge_train_chunks\n",
    "from source.utils import collect_model_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eaceef",
   "metadata": {},
   "source": [
    "## Generate APGD-CE samples for $\\mathcal{U}^{(0)}$\n",
    "\n",
    "We generate and save `.npz` for each split chunk to avoid memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234da600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current config is the \"weak\" perturbation.\n",
    "u0_paths = collect_model_paths(U0_GLOB)\n",
    "gen_for_ensemble(\"U0\", u0_paths, [APGD_SETTINGS['weak']], splits, APGD_OUT)\n",
    "merge_train_chunks(\"U0\", [APGD_SETTINGS['weak']], APGD_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d776e5a",
   "metadata": {},
   "source": [
    "# Get $\\mathcal{U}^{(1)}$\n",
    "\n",
    "Get specialist on weak-APGD against $U^{(0)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74419530",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_DIR = Path(\"./data/specialized_models\")\n",
    "from source.utils import specialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {}\n",
    "y_true_dict = {}\n",
    "for p in os.listdir(APGD_OUT):\n",
    "    d = np.load(APGD_OUT/Path(p))\n",
    "    adv_name = 'APGD_weak' if d['max_iter'] == 2 else 'APGD_strong'\n",
    "    split = str(d['split'])\n",
    "    tag = str(d[\"tag\"]) if \"tag\" in d.files else \"\"\n",
    "    sample_name = f\"{adv_name}_{tag}_{split}\" if tag else f\"{adv_name}_{split}\"\n",
    "    samples[sample_name] = d['x_adv']\n",
    "    y_true_dict[sample_name] = d['y']\n",
    "\n",
    "x_temp = np.concatenate([samples['APGD_weak_U0_train'],samples['APGD_weak_U0_val']],axis=0)\n",
    "y_temp = np.concatenate([y_true_dict['APGD_weak_U0_train'],y_true_dict['APGD_weak_U0_val']],axis=0)\n",
    "\n",
    "new_stratified_x_train, new_stratified_x_val, new_stratified_y_train, new_stratified_y_val = train_test_split(\n",
    "        x_temp,\n",
    "        y_temp,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_temp\n",
    "    )\n",
    "\n",
    "specialized_model_dict={}\n",
    "\n",
    "model_dict = {}\n",
    "for f_name in sorted(os.listdir(\"./data/models/\")):\n",
    "    if 'original' not in f_name and f_name.endswith('keras'):\n",
    "        print(f_name)\n",
    "        m = load_model(f\"./data/models/{f_name}\")\n",
    "        model_dict[f_name] = m\n",
    "        \n",
    "adv_sample_name = 'APGD_weak'\n",
    "for model_name, m in model_dict.items():\n",
    "    model_name = model_name[:-6]\n",
    "    model_name = model_name.split('_')[0] if model_name[0] == 'v' else model_name.split('_')[0] + model_name.split('_')[-1] + 'v'+model_name.split('_')[1][-1]\n",
    "    info = specialize(\n",
    "        (new_stratified_x_train, to_categorical(new_stratified_y_train,10)),\n",
    "        (new_stratified_x_val, to_categorical(new_stratified_y_val,10)),\n",
    "        m,\n",
    "        new_model_path=f\"{model_name}_{adv_sample_name}-SP\")\n",
    "\n",
    "# Reload models since above specialization may affect the loaded original models.\n",
    "model_dict = {}\n",
    "for f_name in sorted(os.listdir(\"./data/models/\")):\n",
    "    if 'original' not in f_name and f_name.endswith('keras'):\n",
    "        print(f_name)\n",
    "        m = load_model(f\"./data/models/{f_name}\")\n",
    "        model_dict[f_name] = m\n",
    "\n",
    "SPs_GLOB = [\n",
    "    \"./data/specialized_models/*.keras\"\n",
    "]\n",
    "\n",
    "U1_GLOB = U0_GLOB + SPs_GLOB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a6765",
   "metadata": {},
   "source": [
    "## Generate more adversarial samples\n",
    "\n",
    "Generate \n",
    "- strong against $U^{(0)}$\n",
    "- weak / strong against $U^{(1)}$\n",
    "- weak / strong against SPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f3239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gen_for_ensemble(\"U0\", u0_paths, [APGD_SETTINGS['strong']], splits, APGD_OUT)\n",
    "merge_train_chunks(\"U0\", [APGD_SETTINGS['strong']], APGD_OUT)\n",
    "SPs_paths = collect_model_paths(SPs_GLOB)\n",
    "u1_paths = collect_model_paths(U1_GLOB)\n",
    "\n",
    "for apgd_settings in APGD_SETTINGS.values():\n",
    "    apgd_settings = [apgd_settings]\n",
    "    gen_for_ensemble(\"SPs\", SPs_paths, apgd_settings, splits, APGD_OUT)\n",
    "    merge_train_chunks(\"SPs\", apgd_settings, APGD_OUT)\n",
    "\n",
    "    gen_for_ensemble(\"U1\", u1_paths, apgd_settings, splits, APGD_OUT)\n",
    "    merge_train_chunks(\"U1\", apgd_settings, APGD_OUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
