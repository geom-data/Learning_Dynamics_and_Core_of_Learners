{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "\n",
    "- Start with a single model trained on sample (0-9)\n",
    "- Take adversarial attack of certain type, get new adversarial samples (10-19).\n",
    "- Make a filter to distinguish the two samples. Also migrate to get a model for the adversarial samples.\n",
    "- Take a different type of attack (on the original model). Get another set of adversrial samples.\n",
    "- Take the normalized dot product between the two set of adversarial samples. If it is close to negative, then label them differently (20-29).\n",
    "- If the dot product is big (angle is small), then compare the lengths of the two perturbations. If they are largely different, then still make different labels.\n",
    "- Train new filter to distinguish the three. Also migrate.\n",
    "- Keep repeating. The new adversarial sample is compared with the different old samples. If all dot products are close to negative, then make new labels.\n",
    "- Such dot product measures the C^1 distance between different models.\n",
    "\n",
    "Idea is ...\n",
    "\n",
    "Suppose we have models $M_i$, $i = 0, 1, 2, \\ldots$. Each has its own fuzziness, and adversarial attacks are generated based on the fuzziness (Fast Gradient Method, Projective gradient method, CW method, DeepFool method etc.). $\\textrm{dist}_{C_0}(M_i, M_j)$ on a set of features $X$ is distance between function values (between fuzziness) and $\\textrm{dist}_{C_1}(M_i, M_j)$ will be the distance between gradients at each features, which can be represented by adversarial attacks.\n",
    "\n",
    "-> Similar models behave similarly upto $C_1$ distance, which can be verified via adversarial attacks. And different models shows different fuzziness. $C_0$ distance may not work in this way because models provide similar answer if they perform well.\n",
    "\n",
    "What we need?\n",
    "\n",
    "Similar models, different models, adversarial attacks.\n",
    "\n",
    "Models :\n",
    "ResNet20v1, ResNet20v2, ResNet56v1, ResNet56v2, VGG11, VGG13, VGG16, VGG19, 3 of each, labeled as 0, 1, 2\n",
    "\n",
    "adversarial attacks dimensions :\n",
    "\n",
    "Generating models: ResNet56v1, VGG16\n",
    "\n",
    "Attack types: PGD (relatively large perturbation. **what should be the epsilon?  0.376 ~ 96/255**) and CWL2 (Low perturbation, model specified)\n",
    "\n",
    "Attack directions : Targeted, Untargeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import cleverhans\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "cifar10_dataset = cifar10.load_data()\n",
    "training, test = cifar10_dataset\n",
    "x_tr, x_v, y_tr, y_v = train_test_split(training[0], training[1], test_size=0.2, random_state=42)\n",
    "x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)\n",
    "x_v = x_v.reshape(x_v.shape[0],32,32,3)\n",
    "x_v = x_v.astype('float32')\n",
    "x_tr = x_tr.astype('float32')\n",
    "x_v /= 255\n",
    "x_tr /= 255\n",
    "y_tr = keras.utils.to_categorical(y_tr, 10)\n",
    "y_v = keras.utils.to_categorical(y_v,10)\n",
    "x_test, y_test = test\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255 \n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'n_9_v1_cifar10_1.keras'# ResNet56. 0.85M number of parameters.\n",
    "GENmodel = load_model(f'CIFAR10models/{model_name}') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGD method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Adversarial Examples using PGD method\n",
    "\n",
    "# from cleverhans.tf2.attacks import projected_gradient_descent as pgd\n",
    "\n",
    "'''\n",
    "eps = 216/255 # value ranges between 0 - 255. allow to perturbe 216 at most.\n",
    "\n",
    "eps_iters = [9/255,27/255,48/255,96/255]\n",
    "\n",
    "nb_iter = 8\n",
    "norm = 2\n",
    "targeted = False\n",
    "\n",
    "'''\n",
    "nb_iter = 8\n",
    "norm = 2\n",
    "\n",
    "eps = 216/255\n",
    "eps_iter = 96/255\n",
    "\n",
    "label = np.round(eps_iter,3)\n",
    "print(f'epsilon = {eps_iter}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targeted = False\n",
    "# advs_x =[]\n",
    "# for i in range(4):\n",
    "#     print(f'{2500*i} - {2500*(i+1)}', end = ' ')\n",
    "#     adv = pgd.projected_gradient_descent(GENmodel, x_test[2500*i:2500*(i+1)],eps,eps_iter,nb_iter,norm,y=tf.argmax(y_tr[2500*i:2500*(i+1)],1))\n",
    "#     advs_x.append(adv)\n",
    "# advs_x = np.concatenate(advs_x, axis=0)\n",
    "# print(f\"advs_x shape: {advs_x.shape}\")\n",
    "# np.save(f'adversarial_examples/pgd_{label}_x_test_untarget_gen_by_{model_name}.npy', advs_x)\n",
    "\n",
    "\n",
    "# logits = GENmodel.predict(x_test, batch_size=2000)\n",
    "# least_likely = tf.argmin(logits,axis=-1)\n",
    "# y= least_likely\n",
    "\n",
    "# targeted = True\n",
    "# advs_x =[]\n",
    "# for i in range(4):\n",
    "#     print(f'{2500*i} - {2500*(i+1)}', end = ' ')\n",
    "#     adv = pgd.projected_gradient_descent(GENmodel,x_test[2500*i:2500*(i+1)],eps,eps_iter,nb_iter,norm,y=y[2500*i:2500*(i+1)],targeted=targeted)\n",
    "#     advs_x.append(adv) \n",
    "# advs_x = np.concatenate(advs_x, axis=0)\n",
    "# print(f\"advs_x_test shape: {advs_x.shape}\")\n",
    "# np.save(f'adversarial_examples/pgd_{label}_x_test_target_to_ll_gen_by_{model_name}.npy', advs_x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CWL2 method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CarliniWagnerL2\n",
    "# from cleverhans.tf2.attacks import carlini_wagner_l2 as cw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x_test\n",
    "# y = y_test\n",
    "# y = tf.argmax(y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'n_9_v1_cifar10.keras'# ResNet56. 0.85M number of parameters.\n",
    "# GENmodel = load_model(f'CIFAR10models/{model_name}') \n",
    "\n",
    "# logits = GENmodel(x_test)\n",
    "# least_likely = tf.argmin(logits,axis=-1)\n",
    "# y= least_likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# advs_x=[]\n",
    "# adv_cwl2= cw.CarliniWagnerL2(GENmodel,max_iterations=100,binary_search_steps=5)\n",
    "# merge_list_untargeted = []\n",
    "# for j in range(10000):\n",
    "#     adv_x = adv_cwl2.attack(x[j:j+1])\n",
    "#     advs_x.append(adv_x)\n",
    "#     if j == 0:\n",
    "#         continue\n",
    "#         # 0 ~ 1000, 1001 numbers\n",
    "#         # 1001 ~ 2000 , ... , 39001 ~ 39999, 1000 numbers each\n",
    "#     elif j%1000==0:\n",
    "#         k = j//1000\n",
    "#         adv = np.concatenate(advs_x, axis=0)\n",
    "\n",
    "#         print(f\"We are at {j}th adversarials. advs_x shape: {adv.shape}\")\n",
    "#         np.save(f'adversarial_examples/cwl2_x_test_untargeted_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy', adv)\n",
    "#         merge_list_untargeted.append(f'adversarial_examples/cwl2_x_test_untargeted_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy')\n",
    "#         print(f'saved to adversarial_examples with file name \"cwl2_x_test_untargeted_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy\" ')\n",
    "#         advs_x=[]\n",
    "#     elif j == 9999:\n",
    "#         k = 10\n",
    "#         adv = np.concatenate(advs_x, axis=0)\n",
    "#         print(f\"We are at {j}th adversarials. advs_x shape: {adv.shape}\")\n",
    "#         np.save(f'adversarial_examples/cwl2_x_test_untargeted_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy', adv)\n",
    "#         merge_list_untargeted.append(f'adversarial_examples/cwl2_x_test_untargeted_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy')\n",
    "#         print(f'saved to adversarial_examples with file name \"cwl2_x_test_untargeted_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy\" ')\n",
    "\n",
    "# advs_x=[]     \n",
    "# merge_list_targeted_to_ll = []\n",
    "# for j in range(10000):\n",
    "#     adv_cwl2= cw.CarliniWagnerL2(GENmodel,max_iterations=100,binary_search_steps=5,y=y[j:j+1],targeted=True)\n",
    "#     adv_x = adv_cwl2.attack(x[j:j+1])\n",
    "#     advs_x.append(adv_x)\n",
    "#     if j == 0:\n",
    "#         continue\n",
    "#         # 0 ~ 1000, 1001 numbers\n",
    "#         # 1001 ~ 2000 , ... , 39001 ~ 39999, 1000 numbers each\n",
    "#     elif j%1000==0:\n",
    "#         k = j//1000\n",
    "#         adv = np.concatenate(advs_x, axis=0)\n",
    "\n",
    "#         print(f\"We are at {j}th adversarials. advs_x shape: {adv.shape}\")\n",
    "#         np.save(f'adversarial_examples/cwl2_x_test_targeted_to_ll_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy', adv)\n",
    "#         merge_list_targeted_to_ll.append(f'adversarial_examples/cwl2_x_test_targeted_to_ll_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy')\n",
    "#         print(f'saved to adversarial_examples with file name \"cwl2_x_test_targeted_to_ll_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy\" ')\n",
    "#         advs_x=[]\n",
    "#     elif j == 9999:\n",
    "#         k = 10\n",
    "#         adv = np.concatenate(advs_x, axis=0)\n",
    "#         print(f\"We are at {j}th adversarials. advs_x shape: {adv.shape}\")\n",
    "#         np.save(f'adversarial_examples/cwl2_x_test_targeted_to_ll_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy', adv)\n",
    "#         merge_list_targeted_to_ll.append(f'adversarial_examples/cwl2_x_test_targeted_to_ll_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy')\n",
    "#         print(f'saved to adversarial_examples with file name \"cwl2_x_test_targeted_to_ll_{(k-1)*1000}to{k*1000}_gen_by_{model_name}.npy\" ')\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models I have:\n",
    "\n",
    "ResNet20v1 * 8, ResNet20v2 * 4, ResNet56v1 * 4, ResNet56v2 * 4\n",
    "\n",
    "VGG11 * 4, VGG13 * 4, VGG16 * 4. VGG19 * 4\n",
    "\n",
    "Adversarial Examples I have: (Only testing dataset)\n",
    "\n",
    "PGD method, 96/255 ($\\simeq 0.376$), generated by each model, untargeted or targeted to least likely class\n",
    "\n",
    "CWL2 method, two examples, generated by ResNet56v1 (without label)\n",
    "\n",
    "**Would it be better to have adversarial example from validation dataset?**\n",
    "\n",
    "\n",
    "## Experiment 1 design\n",
    "\n",
    "Hypothesis:\n",
    "\n",
    "Resnet models share similar structure (and some of them are exactly the same), but possibly different weights. They behave similary to each adversarial attacks. Bad performance to adversarial examples generated by ResNet20v1 models, and high dot-product average for each adversaries.\n",
    "\n",
    "That should be the same as for VGG models.\n",
    "\n",
    "However, since CWL2 is very model specific attack with low perturbation yet effective, the dot product method to determine whether given models are similar would be not promising."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 21:32:58.049177: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import sys, os\n",
    "print(tf.__version__)\n",
    "sys.path.append(\"/Users/inkeejung/Library/CloudStorage/Dropbox-BOSTONUNIVERSITY/Inkee Jung/Inkee Jung’s files/Interpretability/AdvLogifold/computer/modules\")\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.datasets import cifar10\n",
    "import logifoldv1_4 as logifold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from resnet import ResNet\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras import layers\n",
    "import pickle\n",
    "import pandas as pd\n",
    "print('Modules are loaded. (local)')\n",
    "\n",
    "dropbox_path = \"/Users/inkeejung/Library/CloudStorage/Dropbox-BOSTONUNIVERSITY/Inkee Jung/Inkee Jung’s files/Interpretability/AdvLogifold/computer/\"\n",
    "base_models_path = dropbox_path + 'Base_Models/'\n",
    "adversarial_examples_path = dropbox_path + 'Adversarial_Examples/'\n",
    "adversarial_models_path = dropbox_path + 'Adversarial_Models/'\n",
    "\n",
    "# test_logifold_path = dropbox_path + 'testfolder/logifold_test'+ date + '/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original dataset loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset has been loaded.\n",
      "Hashtable 'original_dataset_table'. \n",
      " original_dataset_table[train/val/test] = (X,Y)\n"
     ]
    }
   ],
   "source": [
    "(x, y), (x_test, y_test)= cifar10.load_data()\n",
    "x_tr, x_v, y_tr, y_v = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)\n",
    "x_v = x_v.reshape(x_v.shape[0],32,32,3)\n",
    "x_v = x_v.astype('float32')\n",
    "x_tr = x_tr.astype('float32')\n",
    "x_v /= 255\n",
    "x_tr /= 255\n",
    "x_train, x_val, y_train, y_val = x_tr,x_v,y_tr,y_v\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "original_dataset_table = {'train':(x_tr,y_tr)\n",
    "                         ,'val':(x_val,y_val)\n",
    "                         ,'test':(x_test,y_test)\n",
    "                         } \n",
    "print('original dataset has been loaded.')\n",
    "print(\"Hashtable 'original_dataset_table'. \\n original_dataset_table[train/val/test] = (X,Y)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial examples loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversarial dataset has been loaded.\n",
      "CWL2(untargeted) and PGD(untargeted, targeted to least likely class). Training, validation, and testing data\n",
      "adversarial dataset generated by VGG16 has been loaded.\n",
      "PGD(untargeted, targeted to least likely class). Training, validation, and testing data\n"
     ]
    }
   ],
   "source": [
    "adv_x_tr = np.load(adversarial_examples_path + 'by_ResNet56/' + \"pgd_0.376_x_untarget.npy\")\n",
    "adv_x_val = np.load(adversarial_examples_path + 'by_ResNet56/' + \"pgd_0.376_x_val_untarget.npy\")\n",
    "adv_x_test = np.load(adversarial_examples_path + 'by_ResNet56/'+\"pgd_0.376_x_test_untarget.npy\")\n",
    "adv_ll_x_tr = np.load(adversarial_examples_path + 'by_ResNet56/'+\"pgd_0.376_x_target_to_ll.npy\")\n",
    "adv_ll_x_v = np.load(adversarial_examples_path + 'by_ResNet56/'+\"pgd_0.376_x_val_target_to_ll.npy\")\n",
    "adv_ll_x_test = np.load(adversarial_examples_path + 'by_ResNet56/'+\"pgd_0.376_x_test_target_to_ll.npy\")\n",
    "adv_2nd_x_tr = np.load(adversarial_examples_path + 'by_ResNet56/'+\"pgd_0.376_x_target_to_second.npy\")\n",
    "adv_2nd_x_v = np.load(adversarial_examples_path + 'by_ResNet56/'+\"pgd_0.376_x_val_target_to_second.npy\")\n",
    "adv_2nd_x_test = np.load(adversarial_examples_path + 'by_ResNet56/'+\"pgd_0.376_x_test_target_to_second.npy\")\n",
    "adv_cwl2_x_tr = np.load(adversarial_examples_path + 'by_ResNet56/'+\"cwl2_x_tr_untargeted.npy\")\n",
    "adv_cwl2_x_v = np.load(adversarial_examples_path + 'by_ResNet56/'+\"cwl2_x_v_untargeted.npy\")\n",
    "adv_cwl2_x_test = np.load(adversarial_examples_path + 'by_ResNet56/'+\"cwl2_x_test_untargeted.npy\")\n",
    "adv_cwl2_ll_x_test = np.load(adversarial_examples_path+'by_ResNet56/'+\"cwl2_x_test_targeted_to_ll.npy\")\n",
    "print('adversarial dataset has been loaded.')\n",
    "print('CWL2(untargeted) and PGD(untargeted, targeted to least likely class). Training, validation, and testing data')\n",
    "VGG_adv_x_tr = np.load(adversarial_examples_path + 'by_VGG16/' + \"pgd_0.376_x_untarget.npy\")\n",
    "VGG_adv_x_val = np.load(adversarial_examples_path + 'by_VGG16/' + \"pgd_0.376_x_val_untarget.npy\")\n",
    "VGG_adv_x_test = np.load(adversarial_examples_path + 'by_VGG16/'+\"pgd_0.376_x_test_untarget.npy\")\n",
    "VGG_adv_ll_x_tr = np.load(adversarial_examples_path + 'by_VGG16/'+\"pgd_0.376_x_target_to_ll.npy\")\n",
    "VGG_adv_ll_x_v = np.load(adversarial_examples_path + 'by_VGG16/'+\"pgd_0.376_x_val_target_to_ll.npy\")\n",
    "VGG_adv_ll_x_test = np.load(adversarial_examples_path + 'by_VGG16/'+\"pgd_0.376_x_test_target_to_ll.npy\")\n",
    "\n",
    "print('adversarial dataset generated by VGG16 has been loaded.')\n",
    "print('PGD(untargeted, targeted to least likely class). Training, validation, and testing data')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial dataset hash table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_name(resnet):\n",
    "    if resnet == '31':\n",
    "        return 'ResNet20v1'\n",
    "    elif resnet == '32':\n",
    "        return 'ResNet20v2'\n",
    "    elif resnet == '91':\n",
    "        return 'ResNet56v1'\n",
    "    elif resnet == '92':\n",
    "        return 'ResNet56v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_dataset_table = {}\n",
    "adv_dataset_table['ResNet'] = {}\n",
    "adv_dataset_table['VGG'] = {}\n",
    "for vgg in ['11','13','16','19']:\n",
    "    adv_dataset_table['VGG'][vgg] = {}\n",
    "    adv_dataset_table['VGG'][vgg]['untargeted'] = []\n",
    "    adv_dataset_table['VGG'][vgg]['targeted'] = []\n",
    "    for directory in os.listdir(adversarial_examples_path+'by_VGG'):\n",
    "        if vgg in directory:\n",
    "            if 'untarget' in directory:\n",
    "                if len(directory) == 38:\n",
    "                    adv_dataset_table['VGG'][vgg]['untargeted'].append(('0',np.load(adversarial_examples_path + 'by_VGG/' + directory)))\n",
    "                else:\n",
    "                    adv_dataset_table['VGG'][vgg]['untargeted'].append((str(int(directory[-5])+1),np.load(adversarial_examples_path + 'by_VGG/' + directory)))\n",
    "            else:\n",
    "                if len(directory) == 42:\n",
    "                    adv_dataset_table['VGG'][vgg]['targeted'].append(('0',np.load(adversarial_examples_path + 'by_VGG/' + directory)))\n",
    "                else:\n",
    "                    \n",
    "                    adv_dataset_table['VGG'][vgg]['targeted'].append((str(int(directory[-5])+1),np.load(adversarial_examples_path + 'by_VGG/' + directory)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adv_dataset_table['VGG']['16']['untargeted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resnet in ['31','32','91','92']:\n",
    "    name = convert_name(resnet)\n",
    "    adv_dataset_table['ResNet'][name] = {}\n",
    "    adv_dataset_table['ResNet'][name]['untargeted'] = []\n",
    "    adv_dataset_table['ResNet'][name]['targeted'] = []\n",
    "    for directory in os.listdir(adversarial_examples_path+'by_ResNet'):\n",
    "        \n",
    "        if 'pgd' in directory and 'test' in directory and 'gen_by' in directory:\n",
    "            \n",
    "            if 'untarget' in directory:\n",
    "                which_it_is = directory[35] + directory[38]\n",
    "                if resnet == which_it_is:\n",
    "                    if len(directory) == 57:\n",
    "                        adv_dataset_table['ResNet'][name]['untargeted'].append(('0',np.load(adversarial_examples_path + 'by_ResNet/' + directory)))\n",
    "                    else:\n",
    "                        adv_dataset_table['ResNet'][name]['untargeted'].append((directory[-11],np.load(adversarial_examples_path + 'by_ResNet/' + directory)))\n",
    "\n",
    "            else:\n",
    "                which_it_is = directory[39] + directory[42]\n",
    "                if resnet == which_it_is:\n",
    "                    if len(directory) == 61:\n",
    "                        adv_dataset_table['ResNet'][name]['targeted'].append(('0',np.load(adversarial_examples_path + 'by_ResNet/' + directory)))\n",
    "                    else:\n",
    "                        adv_dataset_table['ResNet'][name]['targeted'].append((directory[-11],np.load(adversarial_examples_path + 'by_ResNet/' + directory)))\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dot product def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x,y,application_pt):\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    p = application_pt.flatten()\n",
    "    pert_x = x - p\n",
    "    pert_y = y - p\n",
    "    size_of_pert_x = np.dot(pert_x,pert_x)**(0.5)\n",
    "    size_of_pert_y = np.dot(pert_y,pert_y)**(0.5)\n",
    "    if size_of_pert_x == 0 or size_of_pert_y == 0:\n",
    "        return 2\n",
    "    return np.dot(pert_x/size_of_pert_x,pert_y/size_of_pert_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000 \n",
    "indices = np.arange(num_samples)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1-1\n",
    "\n",
    "Compare VGG, PGD, Untargeted with ResNet, PGD, Untargeted adversarials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n",
      "4\n",
      "2\n",
      "7\n",
      "0\n",
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for data in adv_dataset_table['ResNet']['ResNet20v1']['untargeted']:\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(modeltype1, modelname1,modeltype2, modelname2, adversarial_direction1, adversarial_direction2, label1, label2):\n",
    "    dot_products = {\n",
    "    \"test\": [],\n",
    "    \"average_test\" : [],\n",
    "    \n",
    "    }\n",
    "    cnt = 0\n",
    "\n",
    "\n",
    "    for dataset in dot_products.keys():\n",
    "        if dataset[:2] == 'av':\n",
    "            continue\n",
    "        for i in range(num_samples):\n",
    "            app_pt = original_dataset_table[dataset][0][i] \n",
    "            dot_product_value = dot_product(adv_dataset_table[f'{modeltype1}'][f'{modelname1}'][f'{adversarial_direction1}'][label1][1][i], \n",
    "                            adv_dataset_table[f'{modeltype2}'][f'{modelname2}'][f'{adversarial_direction2}'][label2][1][i], \n",
    "                            app_pt)\n",
    "            if dot_product_value == 2:\n",
    "                cnt += 1\n",
    "                dot_product_value = 0\n",
    "            dot_products[dataset].append(\n",
    "                dot_product_value\n",
    "                )\n",
    "\n",
    "    average_test = np.sum(dot_products['test'])/num_samples \n",
    "\n",
    "    dot_products['average_test'] = [average_test for _ in range(num_samples)]\n",
    "\n",
    "    # plt.figure(figsize=(8, 2))\n",
    "    # for label, values in dot_products.items():\n",
    "    #     if label[-2:] == 'in':\n",
    "    #         color = 'blue'\n",
    "    #     elif label[-2:] == 'al':\n",
    "    #         color = 'green'\n",
    "    #     else:\n",
    "    #         color = 'red'\n",
    "    #     if label[:2] == 'av':\n",
    "    #         plt.scatter(indices, values, alpha=1, s=0.01, color = color)\n",
    "    #     else:\n",
    "    #         plt.scatter(indices, values, label=label, alpha=0.6, s=0.1,color = color)\n",
    "\n",
    "    # plt.xlabel(f\"Average = {average_test}\\n and there are {cnt} number of non-perturbed adversarial (which induce ZeroDivisionError)\")\n",
    "    # plt.ylabel(\"dot product\")\n",
    "    # plt.title(f\"Dot Product Behavior Across Adversarial Examples\\n {modelname1, adv_dataset_table[f'{modeltype1}'][f'{modelname1}'][f'{adversarial_direction1}'][label1][0]} - {modelname2, adv_dataset_table[f'{modeltype2}'][f'{modelname1}'][f'{adversarial_direction1}'][label2][0]} (PGD, {adversarial_direction1})\")\n",
    "    # plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "    # plt.ylim(-1, 1)\n",
    "    # plt.grid(False)\n",
    "\n",
    "    # plt.show()\n",
    "    return average_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1       2       3\n",
      "0  1.0000  0.1021 -0.0506  0.1023\n",
      "1  0.1021  1.0000 -0.0520  0.1005\n",
      "2 -0.0506 -0.0520  1.0000 -0.0509\n",
      "3  0.1023  0.1005 -0.0509  0.9999\n"
     ]
    }
   ],
   "source": [
    "modeltype1 = 'ResNet'\n",
    "modeltype2 = 'ResNet'\n",
    "modelname1 = 'ResNet56v1'\n",
    "modelname2 = 'ResNet56v1'\n",
    "adversarial_direction1 = 'untargeted'\n",
    "adversarial_direction2 = 'untargeted'\n",
    "values = {}\n",
    "for label1 in range(4):\n",
    "    for label2 in range(4):\n",
    "        values[(label1,label2)] = round(function(modeltype1,modelname1,modeltype2,modelname2,adversarial_direction1,adversarial_direction2,label1,label2)\n",
    "                                        ,4)\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame to represent the table\n",
    "table = pd.DataFrame(np.nan, index=range(4), columns=range(4))  # Initialize with NaN\n",
    "\n",
    "# Fill in the values\n",
    "for (x, y), val in values.items():\n",
    "    table.loc[y, x] = val\n",
    "    \n",
    "print(table)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet 20 v1 , v2, ResNet56 v1, v2  4 number of models\n",
    "VGG 11, 13 , 16, 19 3 number of models\n",
    "\n",
    "PGD type adversarial examples, targeted or untargeted 28 examples\n",
    "\n",
    "CWL2 , PGD 200/255 : cap of perturbation, 96/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      " ResNet20v1, untargeted \n",
      "           0          1          2         3\n",
      "0  9.997697   1.270610   1.284378  1.263122\n",
      "1  1.270610  10.000000   1.269944  1.248033\n",
      "2  1.284378   1.269944  10.000000  1.264265\n",
      "3  1.263122   1.248033   1.264265  9.997697 \n",
      " average =  0.2667253898881082 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ResNet20v1, targeted \n",
      "           0         1         2         3\n",
      "0  9.997698  1.052775  1.052395  1.053828\n",
      "1  1.052775  9.997698  1.057413  1.061182\n",
      "2  1.052395  1.057413  9.997698  1.060418\n",
      "3  1.053828  1.061182  1.060418  9.997698 \n",
      " average =  0.056335181065390226 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ResNet20v2, untargeted \n",
      "            0          1          2          3\n",
      "0  10.000000   1.269701   1.245731   1.255812\n",
      "1   1.269701  10.000000   1.256640   1.252047\n",
      "2   1.245731   1.256640  10.000000   1.239623\n",
      "3   1.255812   1.252047   1.239623  10.000000 \n",
      " average =  0.25325891469132217 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ResNet20v2, targeted \n",
      "            0          1          2          3\n",
      "0  10.000000   1.060261   1.060048   1.066750\n",
      "1   1.060261  10.000000   1.062508   1.063032\n",
      "2   1.060048   1.062508  10.000000   1.062883\n",
      "3   1.066750   1.063032   1.062883  10.000000 \n",
      " average =  0.06258034089005919 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ResNet56v1, untargeted \n",
      "            0          1          2         3\n",
      "0  10.000000   1.265012   0.890047  1.265574\n",
      "1   1.265012  10.000000   0.887120  1.260448\n",
      "2   0.890047   0.887120  10.000000  0.889372\n",
      "3   1.265574   1.260448   0.889372  9.997697 \n",
      " average =  0.07626226833353145 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ResNet56v1, targeted \n",
      "           0          1         2          3\n",
      "0  9.997698   1.063518  1.060469   1.060831\n",
      "1  1.063518  10.000000  1.062123   1.061395\n",
      "2  1.060469   1.062123  9.997698   1.059339\n",
      "3  1.060831   1.061395  1.059339  10.000000 \n",
      " average =  0.06127908403839407 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ResNet56v2, untargeted \n",
      "            0          1         2          3\n",
      "0  10.000000   1.241975  1.251818   1.252767\n",
      "1   1.241975  10.000000  1.247793   1.245089\n",
      "2   1.251818   1.247793  9.997697   1.256543\n",
      "3   1.252767   1.245089  1.256543  10.000000 \n",
      " average =  0.2493307284047417 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ResNet56v2, targeted \n",
      "           0          1          2          3\n",
      "0  9.997698   1.059600   1.061942   1.065197\n",
      "1  1.059600  10.000000   1.060261   1.059062\n",
      "2  1.061942   1.060261  10.000000   1.061257\n",
      "3  1.065197   1.059062   1.061257  10.000000 \n",
      " average =  0.06121977298717148 \n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for modeltype in ['ResNet20v1','ResNet20v2','ResNet56v1', 'ResNet56v2']:\n",
    "    modeltype1 = modeltype2 = 'ResNet'\n",
    "    modelname1 = modelname2 = modeltype\n",
    "    for adversarial_direction in ['untargeted', 'targeted']:\n",
    "        adversarial_direction1 = adversarial_direction2 = adversarial_direction\n",
    "        values = {}\n",
    "        for label1 in range(4):\n",
    "            for label2 in range(4):\n",
    "                values[(label1,label2)] = function(modeltype1,modelname1,modeltype2,modelname2,adversarial_direction1,adversarial_direction2,label1,label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Create a DataFrame to represent the table\n",
    "        table = pd.DataFrame(np.nan, index=range(4), columns=range(4))  # Initialize with NaN\n",
    "\n",
    "        # Fill in the values\n",
    "        for (x, y), val in values.items():\n",
    "            table.loc[y, x] = 10**val\n",
    "        \n",
    "        av = 0\n",
    "        for label1 in range(4):\n",
    "            for label2 in range(4):\n",
    "                if label1 > label2:\n",
    "                    av += 10**values[(label1,label2)]-1\n",
    "        av = (av)/6\n",
    "        \n",
    "        print('------------------------------------------------------------------\\n',f'{modeltype}, {adversarial_direction}','\\n', table,'\\n', 'average = ', av,'\\n------------------------------------------------------------------\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x^* - x$\n",
    "\n",
    "$f, g$ \n",
    "\n",
    "$f(x) - g(x)$\n",
    "\n",
    "$f(x^*) - f(x) ,g(x^*)-g(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      " VGG11, untargeted \n",
      "           0         1         2\n",
      "0  9.970111  1.554128  1.531339\n",
      "1  1.554128  9.876430  1.524588\n",
      "2  1.531339  1.524588  9.960932 \n",
      " average =  0.5366849963271966 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " VGG11, targeted \n",
      "           0         1         2\n",
      "0  9.908320  1.210229  1.194050\n",
      "1  1.210229  9.871883  1.191703\n",
      "2  1.194050  1.191703  9.954054 \n",
      " average =  0.19866071881528913 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " VGG13, untargeted \n",
      "           0         1         2\n",
      "0  9.767873  1.676182  1.696624\n",
      "1  1.676182  9.781377  1.705147\n",
      "2  1.696624  1.705147  9.736435 \n",
      " average =  0.6926507275206912 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " VGG13, targeted \n",
      "           0         1         2\n",
      "0  9.602847  1.210328  1.197932\n",
      "1  1.210328  9.727472  1.208886\n",
      "2  1.197932  1.208886  9.749896 \n",
      " average =  0.20571512136533424 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " VGG16, untargeted \n",
      "           0         1         2\n",
      "0  9.660604  1.666720  1.643573\n",
      "1  1.666720  9.482793  1.629625\n",
      "2  1.643573  1.629625  9.896918 \n",
      " average =  0.6466390961987892 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " VGG16, targeted \n",
      "           0         1         2\n",
      "0  9.497420  1.164013  1.160620\n",
      "1  1.164013  9.878705  1.181755\n",
      "2  1.160620  1.181755  9.647267 \n",
      " average =  0.16879591280286066 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " VGG19, untargeted \n",
      "           0         1         2\n",
      "0  9.858254  1.506600  1.479804\n",
      "1  1.506600  9.831052  1.600484\n",
      "2  1.479804  1.600484  9.972407 \n",
      " average =  0.5289625761729866 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " VGG19, targeted \n",
      "           0         1         2\n",
      "0  9.965521  1.205905  1.192852\n",
      "1  1.205905  9.869610  1.206853\n",
      "2  1.192852  1.206853  9.817479 \n",
      " average =  0.20186987524036878 \n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for modeltype in ['VGG11','VGG13','VGG16', 'VGG19']:\n",
    "    modeltype1 = modeltype2 = 'VGG'\n",
    "    modelname1 = modelname2 = modeltype[-2:]\n",
    "    for adversarial_direction in ['untargeted', 'targeted']:\n",
    "        adversarial_direction1 = adversarial_direction2 = adversarial_direction\n",
    "        values = {}\n",
    "        for label1 in range(3):\n",
    "            for label2 in range(3):\n",
    "                values[(label1,label2)] = function(modeltype1,modelname1,modeltype2,modelname2,adversarial_direction1,adversarial_direction2,label1,label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Create a DataFrame to represent the table\n",
    "        table = pd.DataFrame(np.nan, index=range(3), columns=range(3))  # Initialize with NaN\n",
    "\n",
    "        # Fill in the values\n",
    "        for (x, y), val in values.items():\n",
    "            table.loc[y, x] = 10**val\n",
    "        \n",
    "        av = 0\n",
    "        for label1 in range(3):\n",
    "            for label2 in range(3):\n",
    "                if label1 > label2:\n",
    "                    av += 10**values[(label1,label2)]-1\n",
    "        av = av/3\n",
    "        \n",
    "        print('------------------------------------------------------------------\\n',f'{modeltype}, {adversarial_direction}','\\n', table,'\\n', 'average = ', av,'\\n------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      " ('VGG', '11') and ('ResNet', 'ResNet20v1'), untargeted \n",
      " average =  0.10725363658277 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '11') and ('ResNet', 'ResNet20v1'), targeted \n",
      " average =  0.0292808256659276 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '11') and ('ResNet', 'ResNet20v2'), untargeted \n",
      " average =  0.09912972351456852 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '11') and ('ResNet', 'ResNet20v2'), targeted \n",
      " average =  0.024285991651180856 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '11') and ('ResNet', 'ResNet56v1'), untargeted \n",
      " average =  0.06266967142723025 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '11') and ('ResNet', 'ResNet56v1'), targeted \n",
      " average =  0.027033404213838635 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '11') and ('ResNet', 'ResNet56v2'), untargeted \n",
      " average =  0.09109676074507428 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '11') and ('ResNet', 'ResNet56v2'), targeted \n",
      " average =  0.02103403345653765 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13') and ('ResNet', 'ResNet20v1'), untargeted \n",
      " average =  0.20243016768959823 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13') and ('ResNet', 'ResNet20v1'), targeted \n",
      " average =  0.04884264335949062 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13') and ('ResNet', 'ResNet20v2'), untargeted \n",
      " average =  0.16994574945478683 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13') and ('ResNet', 'ResNet20v2'), targeted \n",
      " average =  0.041020331023875554 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13') and ('ResNet', 'ResNet56v1'), untargeted \n",
      " average =  0.12412225222203145 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13') and ('ResNet', 'ResNet56v1'), targeted \n",
      " average =  0.04640485665185875 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13') and ('ResNet', 'ResNet56v2'), untargeted \n",
      " average =  0.15629946331135575 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13') and ('ResNet', 'ResNet56v2'), targeted \n",
      " average =  0.03634373565134306 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16') and ('ResNet', 'ResNet20v1'), untargeted \n",
      " average =  0.2010743999733429 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16') and ('ResNet', 'ResNet20v1'), targeted \n",
      " average =  0.04584810096407208 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16') and ('ResNet', 'ResNet20v2'), untargeted \n",
      " average =  0.17185431834719997 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16') and ('ResNet', 'ResNet20v2'), targeted \n",
      " average =  0.03922440358058412 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16') and ('ResNet', 'ResNet56v1'), untargeted \n",
      " average =  0.12392907285063202 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16') and ('ResNet', 'ResNet56v1'), targeted \n",
      " average =  0.04373308237849788 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16') and ('ResNet', 'ResNet56v2'), untargeted \n",
      " average =  0.15792878728621365 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16') and ('ResNet', 'ResNet56v2'), targeted \n",
      " average =  0.033787652128598335 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19') and ('ResNet', 'ResNet20v1'), untargeted \n",
      " average =  0.18250204653834082 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19') and ('ResNet', 'ResNet20v1'), targeted \n",
      " average =  0.05048307517468157 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19') and ('ResNet', 'ResNet20v2'), untargeted \n",
      " average =  0.1588078608525993 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19') and ('ResNet', 'ResNet20v2'), targeted \n",
      " average =  0.04296409664426204 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19') and ('ResNet', 'ResNet56v1'), untargeted \n",
      " average =  0.11350905751008593 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19') and ('ResNet', 'ResNet56v1'), targeted \n",
      " average =  0.04824361451826124 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19') and ('ResNet', 'ResNet56v2'), untargeted \n",
      " average =  0.14399857432539367 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19') and ('ResNet', 'ResNet56v2'), targeted \n",
      " average =  0.03755111728341561 \n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for modeltype in ['VGG11','VGG13','VGG16', 'VGG19']:\n",
    "    modeltype1 = 'VGG'\n",
    "    modelname1 = modeltype[-2:]\n",
    "    for modeltype in ['ResNet20v1','ResNet20v2','ResNet56v1', 'ResNet56v2']:\n",
    "        modeltype2 = 'ResNet'\n",
    "        modelname2 = modeltype\n",
    "        for adversarial_direction in ['untargeted', 'targeted']:\n",
    "            adversarial_direction1 = adversarial_direction2 = adversarial_direction\n",
    "            values = {}\n",
    "            for label1 in range(3):\n",
    "                for label2 in range(4):\n",
    "                    values[(label1,label2)] = function(modeltype1,modelname1,modeltype2,modelname2,adversarial_direction1,adversarial_direction2,label1,label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Create a DataFrame to represent the table\n",
    "            table = pd.DataFrame(np.nan, index=range(3), columns=range(3)) \n",
    "            # Fill in the values\n",
    "            for (x, y), val in values.items():\n",
    "                table.loc[y, x] = val\n",
    "            \n",
    "            av = 0\n",
    "            for label1 in range(3):\n",
    "                for label2 in range(4):\n",
    "                    if label1 != label2:\n",
    "                        av += 10**values[(label1,label2)]-1\n",
    "            av = av/12\n",
    "            \n",
    "            print('------------------------------------------------------------------\\n',\n",
    "                  f'{modeltype1, modelname1} and {modeltype2, modelname2}, {adversarial_direction}','\\n', \n",
    "                #   table,'\\n', \n",
    "                  'average = ', av,'\\n------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      " VGG11, targeted vs untargeted  \n",
      "           0         1         2\n",
      "0 -0.091176 -0.092717 -0.086082\n",
      "1 -0.091023 -0.417757 -0.083761\n",
      "2 -0.089296 -0.089314 -0.402873 \n",
      " average =  -0.12314057316789546 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " VGG13, targeted vs untargeted  \n",
      "           0         1         2\n",
      "0 -0.101370 -0.102338 -0.392049\n",
      "1 -0.103295 -0.102279 -0.098092\n",
      "2 -0.105765 -0.388785 -0.102004 \n",
      " average =  -0.22510542487426802 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " VGG16, targeted vs untargeted  \n",
      "           0         1         2\n",
      "0 -0.089668 -0.096429 -0.356016\n",
      "1 -0.090286 -0.092445 -0.092628\n",
      "2 -0.086901 -0.343667 -0.092016 \n",
      " average =  -0.20738378233904695 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " VGG19, targeted vs untargeted  \n",
      "           0         1         2\n",
      "0 -0.075865 -0.085672 -0.076302\n",
      "1 -0.096635 -0.104453 -0.380486\n",
      "2 -0.387128 -0.097748 -0.090915 \n",
      " average =  -0.21274443871311272 \n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for modeltype in ['VGG11','VGG13','VGG16', 'VGG19']:\n",
    "    modeltype1 = modeltype2 = 'VGG'\n",
    "    modelname1 = modelname2 = modeltype[-2:]\n",
    "    adversarial_direction1= 'targeted'\n",
    "    adversarial_direction2 = 'untargeted'\n",
    "\n",
    "    values = {}\n",
    "    for label1 in range(3):\n",
    "        for label2 in range(3):\n",
    "            values[(label1,label2)] = function(modeltype1,modelname1,modeltype2,modelname2,adversarial_direction1,adversarial_direction2,label1,label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Create a DataFrame to represent the table\n",
    "    table = pd.DataFrame(np.nan, index=range(3), columns=range(3))  # Initialize with NaN\n",
    "\n",
    "    # Fill in the values\n",
    "    for (x, y), val in values.items():\n",
    "        table.loc[y, x] = val\n",
    "    \n",
    "    av = 0\n",
    "    for label1 in range(3):\n",
    "        for label2 in range(3):\n",
    "            if label1 > label2:\n",
    "                av += 10**values[(label1,label2)]-1\n",
    "    av = av/9\n",
    "    \n",
    "    print('------------------------------------------------------------------\\n',f'{modeltype}, {adversarial_direction1} vs {adversarial_direction2} ','\\n', table,'\\n', 'average = ', av,'\\n------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      " ResNet20v1, targeted vs untargeted  \n",
      "           0         1         2         3\n",
      "0 -0.033329 -0.037570 -0.035756 -0.276788\n",
      "1 -0.033649 -0.036564 -0.034849 -0.038322\n",
      "2 -0.035641 -0.037021 -0.037464 -0.040476\n",
      "3 -0.031743 -0.036378 -0.033863 -0.037260 \n",
      " average =  -0.08404103423522183 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ResNet20v2, targeted vs untargeted  \n",
      "           0         1         2         3\n",
      "0 -0.035140 -0.034728 -0.246032 -0.037597\n",
      "1 -0.036561 -0.034409 -0.036496 -0.251973\n",
      "2 -0.250291 -0.032939 -0.034084 -0.036675\n",
      "3 -0.034003 -0.231369 -0.035331 -0.035992 \n",
      " average =  -0.14702068308807834 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ResNet56v1, targeted vs untargeted  \n",
      "           0         1         2         3\n",
      "0 -0.037315 -0.271877 -0.037241 -0.035324\n",
      "1 -0.036525 -0.036666 -0.036980 -0.278776\n",
      "2  0.025199  0.025547  0.062387  0.024616\n",
      "3 -0.278196 -0.036283 -0.035758 -0.035534 \n",
      " average =  -0.10719534683925305 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ResNet56v2, targeted vs untargeted  \n",
      "           0         1         2         3\n",
      "0 -0.034095 -0.033203 -0.248351 -0.032006\n",
      "1 -0.035647 -0.032651 -0.034497 -0.240759\n",
      "2 -0.247052 -0.032851 -0.035276 -0.033992\n",
      "3 -0.036007 -0.229240 -0.036358 -0.033911 \n",
      " average =  -0.1445536186065012 \n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for modeltype in ['ResNet20v1','ResNet20v2','ResNet56v1', 'ResNet56v2']:\n",
    "    modeltype1 = modeltype2 = 'ResNet'\n",
    "    modelname1 = modelname2 = modeltype\n",
    "    adversarial_direction1 = 'targeted'\n",
    "    adversarial_direction2 = 'untargeted'\n",
    "    values = {}\n",
    "    for label1 in range(4):\n",
    "        for label2 in range(4):\n",
    "            values[(label1,label2)] = function(modeltype1,modelname1,modeltype2,modelname2,adversarial_direction1,adversarial_direction2,label1,label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Create a DataFrame to represent the table\n",
    "    table = pd.DataFrame(np.nan, index=range(4), columns=range(4))  # Initialize with NaN\n",
    "\n",
    "    # Fill in the values\n",
    "    for (x, y), val in values.items():\n",
    "        table.loc[y, x] = val\n",
    "    \n",
    "    av = 0\n",
    "    for label1 in range(4):\n",
    "        for label2 in range(4):\n",
    "            if label1 != label2:\n",
    "                av += 10**values[(label1,label2)]-1\n",
    "    av = av/16\n",
    "    \n",
    "    print('------------------------------------------------------------------\\n',f'{modeltype}, {adversarial_direction1} vs {adversarial_direction2} ','\\n', table,'\\n', 'average = ', av,'\\n------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      " ('VGG', '11', 'untargeted') and ('ResNet', 'ResNet20v1', 'targeted') \n",
      " average =  -0.03503888139526693 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '11', 'untargeted') and ('ResNet', 'ResNet20v2', 'targeted') \n",
      " average =  -0.03091077572598024 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '11', 'untargeted') and ('ResNet', 'ResNet56v1', 'targeted') \n",
      " average =  -0.03213812351429383 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '11', 'untargeted') and ('ResNet', 'ResNet56v2', 'targeted') \n",
      " average =  -0.02686232816667559 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13', 'untargeted') and ('ResNet', 'ResNet20v1', 'targeted') \n",
      " average =  -0.061250700849152434 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13', 'untargeted') and ('ResNet', 'ResNet20v2', 'targeted') \n",
      " average =  -0.0526206870838995 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13', 'untargeted') and ('ResNet', 'ResNet56v1', 'targeted') \n",
      " average =  -0.05810760140926673 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '13', 'untargeted') and ('ResNet', 'ResNet56v2', 'targeted') \n",
      " average =  -0.04689469425362122 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16', 'untargeted') and ('ResNet', 'ResNet20v1', 'targeted') \n",
      " average =  -0.06321606602868267 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16', 'untargeted') and ('ResNet', 'ResNet20v2', 'targeted') \n",
      " average =  -0.05388761405057113 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16', 'untargeted') and ('ResNet', 'ResNet56v1', 'targeted') \n",
      " average =  -0.05893078022599141 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '16', 'untargeted') and ('ResNet', 'ResNet56v2', 'targeted') \n",
      " average =  -0.04748753047991378 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19', 'untargeted') and ('ResNet', 'ResNet20v1', 'targeted') \n",
      " average =  -0.057229529391477046 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19', 'untargeted') and ('ResNet', 'ResNet20v2', 'targeted') \n",
      " average =  -0.04861927718420076 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19', 'untargeted') and ('ResNet', 'ResNet56v1', 'targeted') \n",
      " average =  -0.054432904747285855 \n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      " ('VGG', '19', 'untargeted') and ('ResNet', 'ResNet56v2', 'targeted') \n",
      " average =  -0.04332686761583358 \n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for modeltype in ['VGG11','VGG13','VGG16', 'VGG19']:\n",
    "    modeltype1 = 'VGG'\n",
    "    modelname1 = modeltype[-2:]\n",
    "    for modeltype in ['ResNet20v1','ResNet20v2','ResNet56v1', 'ResNet56v2']:\n",
    "        modeltype2 = 'ResNet'\n",
    "        modelname2 = modeltype\n",
    "    \n",
    "        adversarial_direction1 = 'untargeted'\n",
    "        adversarial_direction2 = 'targeted'\n",
    "        values = {}\n",
    "        for label1 in range(3):\n",
    "            for label2 in range(4):\n",
    "                values[(label1,label2)] = function(modeltype1,modelname1,modeltype2,modelname2,adversarial_direction1,adversarial_direction2,label1,label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Create a DataFrame to represent the table\n",
    "        table = pd.DataFrame(np.nan, index=range(3), columns=range(3)) \n",
    "        # Fill in the values\n",
    "        for (x, y), val in values.items():\n",
    "            table.loc[y, x] = val\n",
    "        \n",
    "        av = 0\n",
    "        for label1 in range(3):\n",
    "            for label2 in range(4):\n",
    "                if label1 != label2:\n",
    "                    av += 10**values[(label1,label2)]-1\n",
    "        av = av/12\n",
    "        \n",
    "        print('------------------------------------------------------------------\\n',\n",
    "              f'{modeltype1, modelname1, adversarial_direction1} and {modeltype2, modelname2, adversarial_direction2}','\\n', \n",
    "            #   table,'\\n', \n",
    "              'average = ', av,'\\n------------------------------------------------------------------\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 result.\n",
    "\n",
    "Perhaps due to the high dimensionanlity, perturbed example is nearly orthogonal to the original regardless of the attack types and directions.\n",
    "Thankfully, there were tendencies. To see the difference more saliently, we take power of 10, and subtract 1 because if it was negative, then it would be better to have negative after taking power.\n",
    "\n",
    ".|average dot product |\n",
    "--- | --- |\n",
    "Untargeted, same model(ResNet) | 0.2 - 0.25 (One exception, which is about 0.07) |\n",
    "Targeted, same model(ResNet) | 0.05 - 0.07 |\n",
    "Untargeted, same model(VGG) | 0.5 - 0.7 |\n",
    "Targeted, same model(VGG) | 0.15 - 0.2|\n",
    "Untargeted, diff model | 0.06 - 0.2 |\n",
    "Targeted, diff model | 0.02 - 0.05 |\n",
    "Targeted vs Untargeted, same model(VGG) | $-0.12$ - $-0.22$|\n",
    "Targeted vs Untargeted, same model(ResNet) | $-0.08$ - $-0.14$|\n",
    "Different directions, different model | $-0.03$ - $-0.06$|\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "\n",
    "Adversarial examples generated by other model won't be effective when domain is restricted to certain part."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing dataset -> prediction via model A -> take maximum , cut off by certainty threshold\n",
    "\n",
    "$x_1, x_2, x_3$ -> 0.9, 0.6, 0.8, threshold = 0.9 -> x_1 \n",
    "\n",
    "\n",
    "$x^*_1, x^*_2, x^*_3$ -> 0.6, 0.9, 0.8, threhold = 0.9 -> x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 56s 172ms/step\n",
      "313/313 [==============================] - 53s 166ms/step\n",
      "313/313 [==============================] - 55s 176ms/step\n",
      "313/313 [==============================] - 53s 170ms/step\n",
      "313/313 [==============================] - 54s 172ms/step\n",
      "313/313 [==============================] - 54s 172ms/step\n",
      "A to original 0.8355 B to original 0.8065 A to advA 0.2025 B to advA 0.4037 A to advB 0.5301 B to advB 0.206\n",
      "average dot 0.0656876316957633 # of non-perturbation 0\n",
      "240/240 [==============================] - 42s 173ms/step\n",
      "A to advA, cert 0.164\n",
      "240/240 [==============================] - 42s 175ms/step\n",
      "A to advB, cert 0.4711\n",
      "230/230 [==============================] - 42s 184ms/step\n",
      "B to advA, cert 0.3604\n",
      "230/230 [==============================] - 44s 191ms/step\n",
      "B to advB, cert 0.165\n",
      "size of common cert 6384 average dot 0.07718825990023648\n",
      "summary: A to advB  \n",
      "0.5301 -> 0.6135712425110705,\n",
      "summary: B to advA  \n",
      "0.4037 -> 0.4897404538660144,\n"
     ]
    }
   ],
   "source": [
    "# Original dataset : testing dataset\n",
    "cifar10_dataset = cifar10.load_data()\n",
    "training, test = cifar10_dataset\n",
    "x_tr, x_v, y_tr, y_v = train_test_split(training[0], training[1], test_size=0.2, random_state=42)\n",
    "x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)\n",
    "x_v = x_v.reshape(x_v.shape[0],32,32,3)\n",
    "x_v = x_v.astype('float32')\n",
    "x_tr = x_tr.astype('float32')\n",
    "x_v /= 255\n",
    "x_tr /= 255\n",
    "y_tr = keras.utils.to_categorical(y_tr, 10)\n",
    "y_v = keras.utils.to_categorical(y_v,10)\n",
    "x_test, y_test = test\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255 \n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "dropbox_path = \"/Users/inkeejung/Library/CloudStorage/Dropbox-BOSTONUNIVERSITY/Inkee Jung/Inkee Jung’s files/Interpretability/AdvLogifold/computer/\"\n",
    "base_models_path = dropbox_path + 'Base_Models/'\n",
    "adversarial_examples_path = dropbox_path + 'Adversarial_Examples/'\n",
    "# load model A and adversarial testing dataset generated by model A\n",
    "model_name = 'ResNet/n_9_v2_cifar10_1.keras'\n",
    "modelA = load_model(base_models_path + f'CIFAR10models/{model_name}') \n",
    "adv_A = np.load(adversarial_examples_path+\n",
    "                'by_ResNet/'+\n",
    "                'pgd_0.376_x_test_target_to_ll_gen_by_n_9_v2_cifar10_1.keras.npy')\n",
    "# load model B and adversarial testing dataset generated by model B\n",
    "model_name = 'ResNet/n_9_v2_cifar10_2.keras'\n",
    "modelB = load_model(base_models_path + f'CIFAR10models/{model_name}') \n",
    "adv_B = np.load(adversarial_examples_path+\n",
    "                'by_ResNet/'+\n",
    "                'pgd_0.376_x_test_target_to_ll_gen_by_n_9_v2_cifar10_2.keras.npy')\n",
    "# See the accuracy of each one.\n",
    "prediction_A_to_original = modelA.predict(x_test)\n",
    "prediction_B_to_original = modelB.predict(x_test)\n",
    "prediction_A_to_adv_A = modelA.predict(adv_A)\n",
    "prediction_B_to_adv_A = modelB.predict(adv_A)\n",
    "prediction_A_to_adv_B = modelA.predict(adv_B)\n",
    "prediction_B_to_adv_B = modelB.predict(adv_B)\n",
    "right_answer =np.argmax(y_test,axis=-1)\n",
    "print(\n",
    "    'A to original',np.sum(np.argmax(prediction_A_to_original,axis=-1) == right_answer)/10000,\n",
    "    'B to original',np.sum(np.argmax(prediction_B_to_original,axis=-1) == right_answer)/10000,\n",
    "    'A to advA',np.sum(np.argmax(prediction_A_to_adv_A,axis=-1) == right_answer)/10000,\n",
    "    'B to advA',np.sum(np.argmax(prediction_B_to_adv_A,axis=-1) == right_answer)/10000,\n",
    "    'A to advB',np.sum(np.argmax(prediction_A_to_adv_B,axis=-1) == right_answer)/10000,\n",
    "    'B to advB',np.sum(np.argmax(prediction_B_to_adv_B,axis=-1) == right_answer)/10000,\n",
    "    \n",
    ")\n",
    "# Check the dot product average\n",
    "\n",
    "def dot_product(x,y,application_pt):\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    p = application_pt.flatten()\n",
    "    pert_x = x - p\n",
    "    pert_y = y - p\n",
    "    size_of_pert_x = np.dot(pert_x,pert_x)**(0.5)\n",
    "    size_of_pert_y = np.dot(pert_y,pert_y)**(0.5)\n",
    "    if size_of_pert_x == 0 or size_of_pert_y == 0:\n",
    "        return 2\n",
    "    return np.dot(pert_x/size_of_pert_x,pert_y/size_of_pert_y)\n",
    "\n",
    "cnt = 0\n",
    "dot_product_value  = 0\n",
    "for i in range(10000):\n",
    "    dot_product_value += dot_product(\n",
    "        adv_A[i],\n",
    "        adv_B[i],\n",
    "        x_test[i])\n",
    "    if dot_product_value == 2: # it's 2 if there is zero perturbation at least one adversarial\n",
    "        cnt += 1\n",
    "        dot_product_value += 0\n",
    "    \n",
    "average_dot_product = dot_product_value/10000\n",
    "average_dot_product = 10**average_dot_product - 1 # It makes range into (-0.9, 10).\n",
    "print('average dot', average_dot_product,'# of non-perturbation',cnt)\n",
    "# Find certain part of A and B in the testing dataset.\n",
    "\n",
    "def find_cert_part(x, alpha):\n",
    "    return np.where(np.max(x,axis=-1)>alpha)[0]\n",
    "    \n",
    "alpha = 0.9\n",
    "cert_A = find_cert_part(prediction_A_to_original, alpha)\n",
    "cert_B = find_cert_part(prediction_B_to_original, alpha)\n",
    "\n",
    "\n",
    "# compute the accuracy on the certain part for each dataset.\n",
    "\n",
    "prediction_on_cert_modelA_to_adv_A = modelA.predict(adv_A[cert_A])\n",
    "print('A to advA, cert',np.sum(np.argmax(prediction_on_cert_modelA_to_adv_A,axis=-1) == right_answer[cert_A])/10000)\n",
    "prediction_on_cert_modelA_to_adv_B = modelA.predict(adv_B[cert_A])\n",
    "print('A to advB, cert',np.sum(np.argmax(prediction_on_cert_modelA_to_adv_B,axis=-1) == right_answer[cert_A])/10000)\n",
    "prediction_on_cert_modelB_to_adv_A = modelB.predict(adv_A[cert_B])\n",
    "print('B to advA, cert',np.sum(np.argmax(prediction_on_cert_modelB_to_adv_A,axis=-1) == right_answer[cert_B])/10000)\n",
    "prediction_on_cert_modelB_to_adv_B = modelB.predict(adv_B[cert_B])\n",
    "print('B to advB, cert',np.sum(np.argmax(prediction_on_cert_modelB_to_adv_B,axis=-1) == right_answer[cert_B])/10000)\n",
    "# Check the dot product average on the common certain part.\n",
    "\n",
    "\n",
    "common_cert = np.where(np.prod([np.max(prediction_A_to_original,axis=-1)>alpha,np.max(prediction_B_to_original,axis=-1)>alpha],axis=0)==1)[0]\n",
    "\n",
    "cnt = 0\n",
    "dot_product_value  = 0\n",
    "for i in common_cert:\n",
    "    dot_product_value += dot_product(\n",
    "        adv_A[i],\n",
    "        adv_B[i],\n",
    "        x_test[i])\n",
    "    if dot_product_value == 2: # it's 2 if there is zero perturbation at least one adversarial\n",
    "        cnt += 1\n",
    "        dot_product_value += 0\n",
    "    \n",
    "average_dot_product = dot_product_value/len(common_cert)\n",
    "average_dot_product = 10**average_dot_product - 1 # It makes range into (-0.9, 10).\n",
    "print('size of common cert', len(common_cert),'average dot', average_dot_product)\n",
    "\n",
    "\n",
    "\n",
    "print(f'summary: A to advB  \\n{np.sum(np.argmax(prediction_A_to_adv_B,axis=-1) == right_answer)/10000} -> {np.sum(np.argmax(prediction_on_cert_modelA_to_adv_B,axis=-1) == right_answer[cert_A])/len(cert_A)},')\n",
    "print(f'summary: B to advA  \\n{np.sum(np.argmax(prediction_B_to_adv_A,axis=-1) == right_answer)/10000} -> {np.sum(np.argmax(prediction_on_cert_modelB_to_adv_A,axis=-1) == right_answer[cert_B])/len(cert_B)},')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 67s 213ms/step\n",
      "313/313 [==============================] - 97s 306ms/step\n",
      "313/313 [==============================] - 62s 199ms/step\n",
      "313/313 [==============================] - 58s 187ms/step\n",
      "313/313 [==============================] - 59s 187ms/step\n",
      "313/313 [==============================] - 59s 190ms/step\n",
      "A to original 0.8355 B to original 0.8065 A to advA 0.2025 B to advA 0.4037 A to advB 0.5301 B to advB 0.206\n",
      "average dot 0.0656876316957633 # of non-perturbation 0\n",
      "54/54 [==============================] - 10s 190ms/step\n",
      "A to advA, cert 0.0474\n",
      "54/54 [==============================] - 10s 190ms/step\n",
      "A to advB, cert 0.1456\n",
      "44/44 [==============================] - 8s 189ms/step\n",
      "B to advA, cert 0.1091\n",
      "44/44 [==============================] - 8s 189ms/step\n",
      "B to advB, cert 0.0388\n",
      "size of common cert 953 average dot 0.1000952576630274\n",
      "summary: A to advB  \n",
      "0.5301 -> 0.8529584065612185,\n",
      "summary: B to advA  \n",
      "0.4037 -> 0.787725631768953,\n"
     ]
    }
   ],
   "source": [
    "# Original dataset : testing dataset\n",
    "cifar10_dataset = cifar10.load_data()\n",
    "training, test = cifar10_dataset\n",
    "x_tr, x_v, y_tr, y_v = train_test_split(training[0], training[1], test_size=0.2, random_state=42)\n",
    "x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)\n",
    "x_v = x_v.reshape(x_v.shape[0],32,32,3)\n",
    "x_v = x_v.astype('float32')\n",
    "x_tr = x_tr.astype('float32')\n",
    "x_v /= 255\n",
    "x_tr /= 255\n",
    "y_tr = keras.utils.to_categorical(y_tr, 10)\n",
    "y_v = keras.utils.to_categorical(y_v,10)\n",
    "x_test, y_test = test\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255 \n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "dropbox_path = \"/Users/inkeejung/Library/CloudStorage/Dropbox-BOSTONUNIVERSITY/Inkee Jung/Inkee Jung’s files/Interpretability/AdvLogifold/computer/\"\n",
    "base_models_path = dropbox_path + 'Base_Models/'\n",
    "adversarial_examples_path = dropbox_path + 'Adversarial_Examples/'\n",
    "# load model A and adversarial testing dataset generated by model A\n",
    "model_name = 'ResNet/n_9_v2_cifar10_1.keras'\n",
    "modelA = load_model(base_models_path + f'CIFAR10models/{model_name}') \n",
    "adv_A = np.load(adversarial_examples_path+\n",
    "                'by_ResNet/'+\n",
    "                'pgd_0.376_x_test_target_to_ll_gen_by_n_9_v2_cifar10_1.keras.npy')\n",
    "# load model B and adversarial testing dataset generated by model B\n",
    "model_name = 'ResNet/n_9_v2_cifar10_2.keras'\n",
    "modelB = load_model(base_models_path + f'CIFAR10models/{model_name}') \n",
    "adv_B = np.load(adversarial_examples_path+\n",
    "                'by_ResNet/'+\n",
    "                'pgd_0.376_x_test_target_to_ll_gen_by_n_9_v2_cifar10_2.keras.npy')\n",
    "# See the accuracy of each one.\n",
    "prediction_A_to_original = modelA.predict(x_test)\n",
    "prediction_B_to_original = modelB.predict(x_test)\n",
    "prediction_A_to_adv_A = modelA.predict(adv_A)\n",
    "prediction_B_to_adv_A = modelB.predict(adv_A)\n",
    "prediction_A_to_adv_B = modelA.predict(adv_B)\n",
    "prediction_B_to_adv_B = modelB.predict(adv_B)\n",
    "right_answer =np.argmax(y_test,axis=-1)\n",
    "print(\n",
    "    'A to original',np.sum(np.argmax(prediction_A_to_original,axis=-1) == right_answer)/10000,\n",
    "    'B to original',np.sum(np.argmax(prediction_B_to_original,axis=-1) == right_answer)/10000,\n",
    "    'A to advA',np.sum(np.argmax(prediction_A_to_adv_A,axis=-1) == right_answer)/10000,\n",
    "    'B to advA',np.sum(np.argmax(prediction_B_to_adv_A,axis=-1) == right_answer)/10000,\n",
    "    'A to advB',np.sum(np.argmax(prediction_A_to_adv_B,axis=-1) == right_answer)/10000,\n",
    "    'B to advB',np.sum(np.argmax(prediction_B_to_adv_B,axis=-1) == right_answer)/10000,\n",
    "    \n",
    ")\n",
    "# Check the dot product average\n",
    "\n",
    "def dot_product(x,y,application_pt):\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    p = application_pt.flatten()\n",
    "    pert_x = x - p\n",
    "    pert_y = y - p\n",
    "    size_of_pert_x = np.dot(pert_x,pert_x)**(0.5)\n",
    "    size_of_pert_y = np.dot(pert_y,pert_y)**(0.5)\n",
    "    if size_of_pert_x == 0 or size_of_pert_y == 0:\n",
    "        return 2\n",
    "    return np.dot(pert_x/size_of_pert_x,pert_y/size_of_pert_y)\n",
    "\n",
    "cnt = 0\n",
    "dot_product_value  = 0\n",
    "for i in range(10000):\n",
    "    dot_product_value += dot_product(\n",
    "        adv_A[i],\n",
    "        adv_B[i],\n",
    "        x_test[i])\n",
    "    if dot_product_value == 2: # it's 2 if there is zero perturbation at least one adversarial\n",
    "        cnt += 1\n",
    "        dot_product_value += 0\n",
    "    \n",
    "average_dot_product = dot_product_value/10000\n",
    "average_dot_product = 10**average_dot_product - 1 # It makes range into (-0.9, 10).\n",
    "print('average dot', average_dot_product,'# of non-perturbation',cnt)\n",
    "# Find certain part of A and B in the testing dataset.\n",
    "\n",
    "def find_cert_part(x, alpha):\n",
    "    return np.where(np.max(x,axis=-1)>alpha)[0]\n",
    "    \n",
    "alpha = 0.99999\n",
    "cert_A = find_cert_part(prediction_A_to_original, alpha)\n",
    "cert_B = find_cert_part(prediction_B_to_original, alpha)\n",
    "\n",
    "\n",
    "# compute the accuracy on the certain part for each dataset.\n",
    "\n",
    "prediction_on_cert_modelA_to_adv_A = modelA.predict(adv_A[cert_A])\n",
    "print('A to advA, cert',np.sum(np.argmax(prediction_on_cert_modelA_to_adv_A,axis=-1) == right_answer[cert_A])/10000)\n",
    "prediction_on_cert_modelA_to_adv_B = modelA.predict(adv_B[cert_A])\n",
    "print('A to advB, cert',np.sum(np.argmax(prediction_on_cert_modelA_to_adv_B,axis=-1) == right_answer[cert_A])/10000)\n",
    "prediction_on_cert_modelB_to_adv_A = modelB.predict(adv_A[cert_B])\n",
    "print('B to advA, cert',np.sum(np.argmax(prediction_on_cert_modelB_to_adv_A,axis=-1) == right_answer[cert_B])/10000)\n",
    "prediction_on_cert_modelB_to_adv_B = modelB.predict(adv_B[cert_B])\n",
    "print('B to advB, cert',np.sum(np.argmax(prediction_on_cert_modelB_to_adv_B,axis=-1) == right_answer[cert_B])/10000)\n",
    "# Check the dot product average on the common certain part.\n",
    "\n",
    "\n",
    "common_cert = np.where(np.prod([np.max(prediction_A_to_original,axis=-1)>alpha,np.max(prediction_B_to_original,axis=-1)>alpha],axis=0)==1)[0]\n",
    "\n",
    "cnt = 0\n",
    "dot_product_value  = 0\n",
    "for i in common_cert:\n",
    "    dot_product_value += dot_product(\n",
    "        adv_A[i],\n",
    "        adv_B[i],\n",
    "        x_test[i])\n",
    "    if dot_product_value == 2: # it's 2 if there is zero perturbation at least one adversarial\n",
    "        cnt += 1\n",
    "        dot_product_value += 0\n",
    "    \n",
    "average_dot_product = dot_product_value/len(common_cert)\n",
    "average_dot_product = 10**average_dot_product - 1 # It makes range into (-0.9, 10).\n",
    "print('size of common cert', len(common_cert),'average dot', average_dot_product)\n",
    "\n",
    "\n",
    "\n",
    "print(f'summary: A to advB  \\n{np.sum(np.argmax(prediction_A_to_adv_B,axis=-1) == right_answer)/10000} -> {np.sum(np.argmax(prediction_on_cert_modelA_to_adv_B,axis=-1) == right_answer[cert_A])/len(cert_A)},')\n",
    "print(f'summary: B to advA  \\n{np.sum(np.argmax(prediction_B_to_adv_A,axis=-1) == right_answer)/10000} -> {np.sum(np.argmax(prediction_on_cert_modelB_to_adv_A,axis=-1) == right_answer[cert_B])/len(cert_B)},')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 63s 197ms/step\n",
      "313/313 [==============================] - 65s 205ms/step\n",
      "313/313 [==============================] - 56s 180ms/step\n",
      "313/313 [==============================] - 53s 171ms/step\n",
      "313/313 [==============================] - 52s 167ms/step\n",
      "313/313 [==============================] - 52s 167ms/step\n",
      "A to original 0.8355 B to original 0.8065 A to advA 0.2025 B to advA 0.4037 A to advB 0.5301 B to advB 0.206\n",
      "average dot 0.0656876316957633 # of non-perturbation 0\n",
      "221/221 [==============================] - 37s 167ms/step\n",
      "A to advA, cert 0.1544\n",
      "221/221 [==============================] - 37s 169ms/step\n",
      "A to advB, cert 0.4502\n",
      "210/210 [==============================] - 35s 169ms/step\n",
      "B to advA, cert 0.3466\n",
      "210/210 [==============================] - 36s 170ms/step\n",
      "B to advB, cert 0.1545\n",
      "size of common cert 5689 average dot 0.07862220366659756\n",
      "size of cert part of A [   0    1    2 ... 9997 9998 9999],size of cert part of B [   0    2    4 ... 9997 9998 9999]\n",
      "summary: A to advB  \n",
      "0.5301 -> 0.4502,\n",
      "summary: B to advA  \n",
      "0.4037 -> 0.3466,\n"
     ]
    }
   ],
   "source": [
    "# Original dataset : testing dataset\n",
    "cifar10_dataset = cifar10.load_data()\n",
    "training, test = cifar10_dataset\n",
    "x_tr, x_v, y_tr, y_v = train_test_split(training[0], training[1], test_size=0.2, random_state=42)\n",
    "x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)\n",
    "x_v = x_v.reshape(x_v.shape[0],32,32,3)\n",
    "x_v = x_v.astype('float32')\n",
    "x_tr = x_tr.astype('float32')\n",
    "x_v /= 255\n",
    "x_tr /= 255\n",
    "y_tr = keras.utils.to_categorical(y_tr, 10)\n",
    "y_v = keras.utils.to_categorical(y_v,10)\n",
    "x_test, y_test = test\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255 \n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "dropbox_path = \"/Users/inkeejung/Library/CloudStorage/Dropbox-BOSTONUNIVERSITY/Inkee Jung/Inkee Jung’s files/Interpretability/AdvLogifold/computer/\"\n",
    "base_models_path = dropbox_path + 'Base_Models/'\n",
    "adversarial_examples_path = dropbox_path + 'Adversarial_Examples/'\n",
    "# load model A and adversarial testing dataset generated by model A\n",
    "model_name = 'ResNet/n_9_v2_cifar10_1.keras'\n",
    "modelA = load_model(base_models_path + f'CIFAR10models/{model_name}') \n",
    "adv_A = np.load(adversarial_examples_path+\n",
    "                'by_ResNet/'+\n",
    "                'pgd_0.376_x_test_target_to_ll_gen_by_n_9_v2_cifar10_1.keras.npy')\n",
    "# load model B and adversarial testing dataset generated by model B\n",
    "model_name = 'ResNet/n_9_v2_cifar10_2.keras'\n",
    "modelB = load_model(base_models_path + f'CIFAR10models/{model_name}') \n",
    "adv_B = np.load(adversarial_examples_path+\n",
    "                'by_ResNet/'+\n",
    "                'pgd_0.376_x_test_target_to_ll_gen_by_n_9_v2_cifar10_2.keras.npy')\n",
    "# See the accuracy of each one.\n",
    "prediction_A_to_original = modelA.predict(x_test)\n",
    "prediction_B_to_original = modelB.predict(x_test)\n",
    "prediction_A_to_adv_A = modelA.predict(adv_A)\n",
    "prediction_B_to_adv_A = modelB.predict(adv_A)\n",
    "prediction_A_to_adv_B = modelA.predict(adv_B)\n",
    "prediction_B_to_adv_B = modelB.predict(adv_B)\n",
    "right_answer =np.argmax(y_test,axis=-1)\n",
    "print(\n",
    "    'A to original',np.sum(np.argmax(prediction_A_to_original,axis=-1) == right_answer)/10000,\n",
    "    'B to original',np.sum(np.argmax(prediction_B_to_original,axis=-1) == right_answer)/10000,\n",
    "    'A to advA',np.sum(np.argmax(prediction_A_to_adv_A,axis=-1) == right_answer)/10000,\n",
    "    'B to advA',np.sum(np.argmax(prediction_B_to_adv_A,axis=-1) == right_answer)/10000,\n",
    "    'A to advB',np.sum(np.argmax(prediction_A_to_adv_B,axis=-1) == right_answer)/10000,\n",
    "    'B to advB',np.sum(np.argmax(prediction_B_to_adv_B,axis=-1) == right_answer)/10000,\n",
    "    \n",
    ")\n",
    "# Check the dot product average\n",
    "\n",
    "def dot_product(x,y,application_pt):\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    p = application_pt.flatten()\n",
    "    pert_x = x - p\n",
    "    pert_y = y - p\n",
    "    size_of_pert_x = np.dot(pert_x,pert_x)**(0.5)\n",
    "    size_of_pert_y = np.dot(pert_y,pert_y)**(0.5)\n",
    "    if size_of_pert_x == 0 or size_of_pert_y == 0:\n",
    "        return 2\n",
    "    return np.dot(pert_x/size_of_pert_x,pert_y/size_of_pert_y)\n",
    "\n",
    "cnt = 0\n",
    "dot_product_value  = 0\n",
    "for i in range(10000):\n",
    "    dot_product_value += dot_product(\n",
    "        adv_A[i],\n",
    "        adv_B[i],\n",
    "        x_test[i])\n",
    "    if dot_product_value == 2: # it's 2 if there is zero perturbation at least one adversarial\n",
    "        cnt += 1\n",
    "        dot_product_value += 0\n",
    "    \n",
    "average_dot_product = dot_product_value/10000\n",
    "average_dot_product = 10**average_dot_product - 1 # It makes range into (-0.9, 10).\n",
    "print('average dot', average_dot_product,'# of non-perturbation',cnt)\n",
    "# Find certain part of A and B in the testing dataset.\n",
    "\n",
    "def find_cert_part(x, alpha):\n",
    "    return np.where(np.max(x,axis=-1)>alpha)[0]\n",
    "    \n",
    "alpha = 0.95\n",
    "cert_A = find_cert_part(prediction_A_to_original, alpha)\n",
    "cert_B = find_cert_part(prediction_B_to_original, alpha)\n",
    "\n",
    "\n",
    "# compute the accuracy on the certain part for each dataset.\n",
    "\n",
    "prediction_on_cert_modelA_to_adv_A = modelA.predict(adv_A[cert_A])\n",
    "print('A to advA, cert',np.sum(np.argmax(prediction_on_cert_modelA_to_adv_A,axis=-1) == right_answer[cert_A])/10000)\n",
    "prediction_on_cert_modelA_to_adv_B = modelA.predict(adv_B[cert_A])\n",
    "print('A to advB, cert',np.sum(np.argmax(prediction_on_cert_modelA_to_adv_B,axis=-1) == right_answer[cert_A])/10000)\n",
    "prediction_on_cert_modelB_to_adv_A = modelB.predict(adv_A[cert_B])\n",
    "print('B to advA, cert',np.sum(np.argmax(prediction_on_cert_modelB_to_adv_A,axis=-1) == right_answer[cert_B])/10000)\n",
    "prediction_on_cert_modelB_to_adv_B = modelB.predict(adv_B[cert_B])\n",
    "print('B to advB, cert',np.sum(np.argmax(prediction_on_cert_modelB_to_adv_B,axis=-1) == right_answer[cert_B])/10000)\n",
    "# Check the dot product average on the common certain part.\n",
    "\n",
    "\n",
    "common_cert = np.where(np.prod([np.max(prediction_A_to_original,axis=-1)>alpha,np.max(prediction_B_to_original,axis=-1)>alpha],axis=0)==1)[0]\n",
    "\n",
    "cnt = 0\n",
    "dot_product_value  = 0\n",
    "for i in common_cert:\n",
    "    dot_product_value += dot_product(\n",
    "        adv_A[i],\n",
    "        adv_B[i],\n",
    "        x_test[i])\n",
    "    if dot_product_value == 2: # it's 2 if there is zero perturbation at least one adversarial\n",
    "        cnt += 1\n",
    "        dot_product_value += 0\n",
    "    \n",
    "average_dot_product = dot_product_value/len(common_cert)\n",
    "average_dot_product = 10**average_dot_product - 1 # It makes range into (-0.9, 10).\n",
    "print('size of common cert', len(common_cert),'average dot', average_dot_product)\n",
    "\n",
    "print(f'size of cert part of A {len(cert_A)},size of cert part of B {len(cert_B)}')\n",
    "print(f'summary: A to advB  \\n{np.sum(np.argmax(prediction_A_to_adv_B,axis=-1) == right_answer)/10000} -> {np.sum(np.argmax(prediction_on_cert_modelA_to_adv_B,axis=-1) == right_answer[cert_A])/10000},')\n",
    "print(f'summary: B to advA  \\n{np.sum(np.argmax(prediction_B_to_adv_A,axis=-1) == right_answer)/10000} -> {np.sum(np.argmax(prediction_on_cert_modelB_to_adv_A,axis=-1) == right_answer[cert_B])/10000},')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_1 -> (0.9, 0.1)$\n",
    "$x_1^* -> (0.1, 0.9)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "\n",
    "1. Train a filter that distinguish certain parts and those that aren't.\n",
    "2. Train a model only with low certainty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[195], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m model \u001b[39m=\u001b[39m load_model(base_models_path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCIFAR10models/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[39m# Find certain part\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m prediction_train \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(x_tr,verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     30\u001b[0m prediction_val \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_v,verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     31\u001b[0m prediction_test \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   2252\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   2254\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2255\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Original dataset \n",
    "cifar10_dataset = cifar10.load_data()\n",
    "training, test = cifar10_dataset\n",
    "x_tr, x_v, y_tr, y_v = train_test_split(training[0], training[1], test_size=0.2, random_state=42)\n",
    "x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)\n",
    "x_v = x_v.reshape(x_v.shape[0],32,32,3)\n",
    "x_v = x_v.astype('float32')\n",
    "x_tr = x_tr.astype('float32')\n",
    "x_v /= 255\n",
    "x_tr /= 255\n",
    "# y_tr = keras.utils.to_categorical(y_tr, 10)\n",
    "# y_v = keras.utils.to_categorical(y_v,10)\n",
    "x_test, y_test = test\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255 \n",
    "# y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "dropbox_path = \"/Users/inkeejung/Library/CloudStorage/Dropbox-BOSTONUNIVERSITY/Inkee Jung/Inkee Jung’s files/Interpretability/AdvLogifold/computer/\"\n",
    "base_models_path = dropbox_path + 'Base_Models/'\n",
    "adversarial_examples_path = dropbox_path + 'Adversarial_Examples/'\n",
    "\n",
    "# Fix certainty threshold\n",
    "alpha = 0.85\n",
    "# Load a model\n",
    "model_name = 'ResNet/n_9_v1_cifar10.keras'\n",
    "model = load_model(base_models_path + f'CIFAR10models/{model_name}')\n",
    "# Find certain part\n",
    "prediction_train = model.predict(x_tr,verbose = 0)\n",
    "prediction_val = model.predict(x_v,verbose=0)\n",
    "prediction_test = model.predict(x_test)\n",
    "cert_train = np.max(prediction_train,axis=-1)>alpha\n",
    "cert_val = np.max(prediction_val,axis=-1)>alpha\n",
    "cert_test = np.max(prediction_test,axis=-1)>alpha\n",
    "cert_train, uncert_train = np.where(cert_train)[0], np.where(~cert_train)[0]\n",
    "cert_val, uncert_val = np.where(cert_val)[0], np.where(~cert_val)[0]\n",
    "cert_test, uncert_test = np.where(cert_test)[0], np.where(~cert_test)[0]\n",
    "\n",
    "# Train Filter that distinguish given data is classified as 'certain' or not.\n",
    "\n",
    "y_tr[uncert_train] += 10\n",
    "y_v[uncert_val] += 10\n",
    "y_test[uncert_test] += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2]), array([1]))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([3,1,2])>1\n",
    "np.where(x)[0], np.where(~x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  1, 12])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([3,1,2])\n",
    "y[np.where(x)[0]] += 10\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
