{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17c881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model\n",
    "import os, glob\n",
    "import resnet_modified # modified to have zero verbosity, deperacated several printing step, lr -> learning_rate in calling adam.\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from resnet_modified import ResNet\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784c430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d066e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_v, y_train, y_v = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac97055",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_val = x_v.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train_categorical_10 = to_categorical(y_train,10)\n",
    "y_val_categorical_10 = to_categorical(y_v,10)\n",
    "y_test_categorical_10 = to_categorical(y_test,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7abf8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_x_tr_pgd_by_resnet56v1_0_untarget = np.load(\"adversarial_examples/gen_by_ResNet/pgd_0.376_x_untarget.npy\")\n",
    "adv_x_val_pgd_by_resnet56v1_0_untarget = np.load(\"adversarial_examples/gen_by_ResNet/pgd_0.376_x_val_untarget.npy\")\n",
    "\n",
    "adv_x_tr_pgd_by_resnet56v1_0_target_to_ll = np.load(\"adversarial_examples/gen_by_ResNet/pgd_0.376_x_target_to_ll.npy\")\n",
    "adv_x_val_pgd_by_resnet56v1_0_target_to_ll = np.load(\"adversarial_examples/gen_by_ResNet/pgd_0.376_x_val_target_to_ll.npy\")\n",
    "\n",
    "adv_x_tr_cw_by_resnet56v1_0_untarget = np.load(\"adversarial_examples/gen_by_ResNet/cwl2_x_tr_untargeted.npy\")\n",
    "adv_x_val_cw_by_resnet56v1_0_untarget = np.load(\"adversarial_examples/gen_by_ResNet/cwl2_x_v_untargeted.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fdbc8",
   "metadata": {},
   "source": [
    "\n",
    "nb_iter = 8\n",
    "norm = 2\n",
    "\n",
    "eps = 216/255\n",
    "eps_iter = 96/255\n",
    "These are parameters for PGD.\n",
    "L2 norm, big perturbation (~ 0.83) for pgd\n",
    "\n",
    "typical parameter for succesful pgd attack : for L2, 1/255 - 3/255, and for L infinite (norm = np.inf), 8/255\n",
    "\n",
    "max iteration = 100 for cwl2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fcf14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {(3,1) : 'ResNet20v1',\n",
    "        (3,2) : 'ResNet20v2',\n",
    "        (9,1): 'ResNet56v1',\n",
    "        (9,2): 'ResNet56v2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cb7af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom turn specialist function\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 5, 10, 15, 18 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 18:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 15:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 10:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 5:\n",
    "        lr *= 1e-1\n",
    "#     print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "def turn_specialist(model : Model, path : str,\n",
    "        x_tr: np.ndarray | None = None,\n",
    "        y_tr: np.ndarray | None = None,\n",
    "        x_v: np.ndarray | None = None,\n",
    "        y_v: np.ndarray | None = None,\n",
    "        epochs: int = 21,\n",
    "        learning_rate : float = 1e-3,\n",
    "        batch_size: int = 128,\n",
    "        save_each: bool = False,\n",
    "        save_bests: int | None = None,\n",
    "        verbose: int = 1,\n",
    "    ):\n",
    "        \n",
    "        # build specialist network\n",
    "        base = Model(inputs = model.inputs, outputs = model.layers[-2].output, name=\"base\")\n",
    "        x    = keras.Input(shape=base.input_shape[1:], name=\"in\")\n",
    "        y    = Dense(10, name=\"dense\")(base(x)) # 10 can be changed to len(newtarget)\n",
    "        z    = layers.Softmax(name=\"softmax\")(y)\n",
    "        specialist = Model(inputs = x, outputs = z)\n",
    "        specialist.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "        \n",
    "        opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # callbacks\n",
    "        callbacks = [ModelCheckpoint(path, monitor=\"val_accuracy\",\n",
    "                                    save_best_only=True, verbose=verbose)]\n",
    "        \n",
    "        callbacks += [LearningRateScheduler(lr_schedule),\n",
    "                        ReduceLROnPlateau(factor=np.sqrt(0.1), patience=5, min_lr=5e-7)]\n",
    "\n",
    "        # fit \n",
    "        hist = specialist.fit(x_tr, y_tr, batch_size=batch_size,\n",
    "                        validation_data=(x_v, y_v),\n",
    "                        epochs=epochs, callbacks=callbacks, verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "        # ---------- summary ----------\n",
    "        metric = \"val_accuracy\"\n",
    "        best = np.max(hist.history[metric])\n",
    "        first = hist.history[metric][0]\n",
    "        print(f\"best {metric} {best:.3f} (first {first:.3f})\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e3d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_y_long=np.concatenate([y_train,y_train],axis=0)\n",
    "training_y_long = keras.utils.to_categorical(training_y_long,20)\n",
    "validating_y_long=np.concatenate([y_v,y_v],axis=0)\n",
    "validating_y_long = keras.utils.to_categorical(validating_y_long,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400da4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit starts ResNet56v2_naive_cw.keras\n",
      "Epoch 1/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 2.2697 - acc: 0.4899\n",
      "Epoch 1: val_acc improved from -inf to 0.56970, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 56s 30ms/step - loss: 2.2697 - acc: 0.4899 - val_loss: 1.7143 - val_acc: 0.5697 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.4873 - acc: 0.6322\n",
      "Epoch 2: val_acc improved from 0.56970 to 0.60835, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.4873 - acc: 0.6322 - val_loss: 1.4979 - val_acc: 0.6083 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.2552 - acc: 0.6956\n",
      "Epoch 3: val_acc did not improve from 0.60835\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2552 - acc: 0.6956 - val_loss: 2.0523 - val_acc: 0.5008 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.1296 - acc: 0.7261\n",
      "Epoch 4: val_acc improved from 0.60835 to 0.67180, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.1296 - acc: 0.7261 - val_loss: 1.2805 - val_acc: 0.6718 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.0450 - acc: 0.7509\n",
      "Epoch 5: val_acc improved from 0.67180 to 0.71160, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.0450 - acc: 0.7509 - val_loss: 1.1440 - val_acc: 0.7116 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.9729 - acc: 0.7693\n",
      "Epoch 6: val_acc did not improve from 0.71160\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.9729 - acc: 0.7693 - val_loss: 1.2439 - val_acc: 0.6809 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.9257 - acc: 0.7843\n",
      "Epoch 7: val_acc did not improve from 0.71160\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.9257 - acc: 0.7843 - val_loss: 1.3366 - val_acc: 0.6874 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8841 - acc: 0.7956\n",
      "Epoch 8: val_acc improved from 0.71160 to 0.73920, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.8841 - acc: 0.7956 - val_loss: 1.0903 - val_acc: 0.7392 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8524 - acc: 0.8029\n",
      "Epoch 9: val_acc did not improve from 0.73920\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.8524 - acc: 0.8029 - val_loss: 1.1287 - val_acc: 0.7308 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8265 - acc: 0.8103\n",
      "Epoch 10: val_acc improved from 0.73920 to 0.75915, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.8265 - acc: 0.8103 - val_loss: 1.0006 - val_acc: 0.7592 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7952 - acc: 0.8211\n",
      "Epoch 11: val_acc did not improve from 0.75915\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7952 - acc: 0.8211 - val_loss: 1.0027 - val_acc: 0.7512 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7751 - acc: 0.8244\n",
      "Epoch 12: val_acc improved from 0.75915 to 0.76205, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7751 - acc: 0.8244 - val_loss: 1.0263 - val_acc: 0.7620 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7532 - acc: 0.8312\n",
      "Epoch 13: val_acc did not improve from 0.76205\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7532 - acc: 0.8312 - val_loss: 1.1278 - val_acc: 0.7415 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7348 - acc: 0.8353\n",
      "Epoch 14: val_acc did not improve from 0.76205\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7348 - acc: 0.8353 - val_loss: 1.1012 - val_acc: 0.7376 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7156 - acc: 0.8415\n",
      "Epoch 15: val_acc improved from 0.76205 to 0.79285, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7156 - acc: 0.8415 - val_loss: 0.8937 - val_acc: 0.7929 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7080 - acc: 0.8422\n",
      "Epoch 16: val_acc did not improve from 0.79285\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7080 - acc: 0.8422 - val_loss: 0.9333 - val_acc: 0.7826 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6880 - acc: 0.8501\n",
      "Epoch 17: val_acc improved from 0.79285 to 0.81470, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6880 - acc: 0.8501 - val_loss: 0.8103 - val_acc: 0.8147 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6774 - acc: 0.8508\n",
      "Epoch 18: val_acc did not improve from 0.81470\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6774 - acc: 0.8508 - val_loss: 0.9917 - val_acc: 0.7649 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6675 - acc: 0.8555\n",
      "Epoch 19: val_acc did not improve from 0.81470\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6675 - acc: 0.8555 - val_loss: 0.9103 - val_acc: 0.7701 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6577 - acc: 0.8573\n",
      "Epoch 20: val_acc did not improve from 0.81470\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6577 - acc: 0.8573 - val_loss: 1.1945 - val_acc: 0.7102 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6475 - acc: 0.8604\n",
      "Epoch 21: val_acc improved from 0.81470 to 0.82720, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6475 - acc: 0.8604 - val_loss: 0.7612 - val_acc: 0.8272 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6350 - acc: 0.8655\n",
      "Epoch 22: val_acc did not improve from 0.82720\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6350 - acc: 0.8655 - val_loss: 1.1069 - val_acc: 0.7420 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6297 - acc: 0.8649\n",
      "Epoch 23: val_acc did not improve from 0.82720\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6297 - acc: 0.8649 - val_loss: 0.8233 - val_acc: 0.8032 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6192 - acc: 0.8681\n",
      "Epoch 24: val_acc did not improve from 0.82720\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6192 - acc: 0.8681 - val_loss: 0.7724 - val_acc: 0.8199 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6132 - acc: 0.8714\n",
      "Epoch 25: val_acc did not improve from 0.82720\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6132 - acc: 0.8714 - val_loss: 0.8889 - val_acc: 0.7985 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6083 - acc: 0.8732\n",
      "Epoch 26: val_acc improved from 0.82720 to 0.83185, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6083 - acc: 0.8732 - val_loss: 0.7337 - val_acc: 0.8318 - lr: 0.0010\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6010 - acc: 0.8742\n",
      "Epoch 27: val_acc did not improve from 0.83185\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6010 - acc: 0.8742 - val_loss: 0.8294 - val_acc: 0.8105 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5969 - acc: 0.8764\n",
      "Epoch 28: val_acc did not improve from 0.83185\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5969 - acc: 0.8764 - val_loss: 0.8464 - val_acc: 0.8155 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5943 - acc: 0.8747\n",
      "Epoch 29: val_acc improved from 0.83185 to 0.83455, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5943 - acc: 0.8747 - val_loss: 0.7215 - val_acc: 0.8346 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5822 - acc: 0.8795\n",
      "Epoch 30: val_acc did not improve from 0.83455\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5822 - acc: 0.8795 - val_loss: 0.9219 - val_acc: 0.7835 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5828 - acc: 0.8788\n",
      "Epoch 31: val_acc did not improve from 0.83455\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5829 - acc: 0.8788 - val_loss: 0.9030 - val_acc: 0.7898 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5732 - acc: 0.8820\n",
      "Epoch 32: val_acc did not improve from 0.83455\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5732 - acc: 0.8820 - val_loss: 1.0931 - val_acc: 0.7509 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5704 - acc: 0.8821\n",
      "Epoch 33: val_acc did not improve from 0.83455\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5703 - acc: 0.8822 - val_loss: 0.9766 - val_acc: 0.7762 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5715 - acc: 0.8818\n",
      "Epoch 34: val_acc did not improve from 0.83455\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5715 - acc: 0.8818 - val_loss: 0.8546 - val_acc: 0.8114 - lr: 3.1623e-04\n",
      "Epoch 35/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5633 - acc: 0.8863\n",
      "Epoch 35: val_acc did not improve from 0.83455\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5633 - acc: 0.8863 - val_loss: 1.0388 - val_acc: 0.7790 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5570 - acc: 0.8862\n",
      "Epoch 36: val_acc did not improve from 0.83455\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5570 - acc: 0.8862 - val_loss: 1.0222 - val_acc: 0.7583 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5542 - acc: 0.8868\n",
      "Epoch 37: val_acc improved from 0.83455 to 0.84570, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5542 - acc: 0.8868 - val_loss: 0.7096 - val_acc: 0.8457 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5507 - acc: 0.8888\n",
      "Epoch 38: val_acc did not improve from 0.84570\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5509 - acc: 0.8887 - val_loss: 0.8725 - val_acc: 0.8027 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5455 - acc: 0.8915\n",
      "Epoch 39: val_acc improved from 0.84570 to 0.84610, saving model to adversarial_models/naive_method/ResNet56v2_naive_cw.keras\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5455 - acc: 0.8915 - val_loss: 0.6915 - val_acc: 0.8461 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5414 - acc: 0.8918\n",
      "Epoch 40: val_acc did not improve from 0.84610\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5414 - acc: 0.8918 - val_loss: 0.7247 - val_acc: 0.8394 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5401 - acc: 0.8916\n",
      "Epoch 41: val_acc did not improve from 0.84610\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5401 - acc: 0.8916 - val_loss: 0.7185 - val_acc: 0.8377 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5378 - acc: 0.8926\n",
      "Epoch 42: val_acc did not improve from 0.84610\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5378 - acc: 0.8926 - val_loss: 0.9366 - val_acc: 0.7917 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5407 - acc: 0.8905\n",
      "Epoch 43: val_acc did not improve from 0.84610\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5407 - acc: 0.8905 - val_loss: 0.7257 - val_acc: 0.8388 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5301 - acc: 0.8946\n",
      "Epoch 44: val_acc did not improve from 0.84610\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5301 - acc: 0.8946 - val_loss: 0.7681 - val_acc: 0.8244 - lr: 3.1623e-04\n",
      "Epoch 45/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5264 - acc: 0.8972\n",
      "Epoch 45: val_acc did not improve from 0.84610\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5264 - acc: 0.8972 - val_loss: 0.7754 - val_acc: 0.8256 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5259 - acc: 0.8969\n",
      "Epoch 46: val_acc did not improve from 0.84610\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5259 - acc: 0.8969 - val_loss: 0.6957 - val_acc: 0.8459 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5208 - acc: 0.8965\n",
      "Epoch 47: val_acc did not improve from 0.84610\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5208 - acc: 0.8965 - val_loss: 0.7571 - val_acc: 0.8231 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "1469/1563 [===========================>..] - ETA: 2s - loss: 0.5191 - acc: 0.8974"
     ]
    }
   ],
   "source": [
    "## Structure varies, adversarial is from ResNet56v1, PGD method, untargeted , L2 norm, 216/255 epsilon perturbation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "n = 9\n",
    "v = 2\n",
    "# ##\n",
    "# training_y_long=np.concatenate([y_train,y_train],axis=0)\n",
    "# training_y_long = keras.utils.to_categorical(training_y_long,10)\n",
    "validating_y_long=np.concatenate([y_v,y_v],axis=0)\n",
    "validating_y_long = keras.utils.to_categorical(validating_y_long,10)\n",
    "# ##\n",
    "# training_x = np.concatenate([x_train,adv_x_tr_pgd_by_resnet56v1_0_untarget],axis=0)\n",
    "# validating_x = np.concatenate([x_val,adv_x_val_pgd_by_resnet56v1_0_untarget],axis=0)\n",
    "\n",
    "# ##\n",
    "# path = f'adversarial_models/naive_method/{label_dict[(n,v)]}_naive_untargeted.keras'\n",
    "# print(f'fit starts {label_dict[(n,v)]}_naive_untargeted.keras')\n",
    "# resnet_model = ResNet(path,training_x,training_y_long,validating_x,validating_y_long,n=n,version=v)\n",
    "# resnet_model.train(save_best_only=True,epochs=200)\n",
    "# ##\n",
    "# print(f'fit ends. Fine tunning.')\n",
    "# specialist = turn_specialist(load_model(path),\n",
    "#     f'adversarial_models/naive_method/{label_dict[(n,v)]}_naive_untargeted_fine.keras', \n",
    "#     x_train, y_train_categorical_10, \n",
    "#     x_val, y_val_categorical_10)\n",
    "# #         ##\n",
    "# #         print('more epochs on naive one')\n",
    "\n",
    "# #         naive_one = load_model(path)\n",
    "# #         datagen = ImageDataGenerator(  \n",
    "# #         width_shift_range=0.1,\n",
    "# #         height_shift_range=0.1,\n",
    "# #         horizontal_flip=True\n",
    "# #     )\n",
    "# #         datagen.fit(training_x)\n",
    "\n",
    "# #         batch_size = 128\n",
    "# #         steps_per_epoch = len(training_x) // batch_size\n",
    "\n",
    "# #         ##\n",
    "# #         checkpoint_21 = ModelCheckpoint(\n",
    "# #             filepath=f'adversarial_models/naive_method/{label_dict[(n,v)]}_naive_untargeted_21best.keras',\n",
    "# #             monitor='val_accuracy',\n",
    "# #             save_best_only=True,\n",
    "# #             verbose=1\n",
    "# #         )\n",
    "\n",
    "# #         ##\n",
    "# #         naive_one.fit(\n",
    "# #                     x=datagen.flow(training_x, training_y_long, batch_size=batch_size),\n",
    "# #                     epochs=21,\n",
    "# #                     validation_data=(validating_x, validating_y_long),\n",
    "# #                     steps_per_epoch=steps_per_epoch,\n",
    "# #                     verbose=1,\n",
    "# #                     callbacks=[checkpoint_21]\n",
    "# #                     )\n",
    "\n",
    "# ##\n",
    "# training_x = np.concatenate([x_train,adv_x_tr_pgd_by_resnet56v1_0_target_to_ll],axis=0)\n",
    "# validating_x = np.concatenate([x_val,adv_x_val_pgd_by_resnet56v1_0_target_to_ll],axis=0)\n",
    "\n",
    "# ##\n",
    "# path = f'adversarial_models/naive_method/{label_dict[(n,v)]}_naive_targeted.keras'\n",
    "# print(f'fit starts {label_dict[(n,v)]}_naive_targeted.keras')\n",
    "# resnet_model = ResNet(path,training_x,training_y_long,validating_x,validating_y_long,n=n,version=v)\n",
    "# resnet_model.train(save_best_only=True,epochs=200)\n",
    "# ##\n",
    "# print(f'fit ends. Fine tunning.')\n",
    "# specialist = turn_specialist(load_model(path),\n",
    "#     f'adversarial_models/naive_method/{label_dict[(n,v)]}_naive_targeted_fine.keras', \n",
    "#     x_train, y_train_categorical_10, \n",
    "#     x_val, y_val_categorical_10)\n",
    "# #         ##\n",
    "# #         print('more epochs on naive one')\n",
    "\n",
    "# #         naive_one = load_model(path)\n",
    "# #         datagen = ImageDataGenerator(  \n",
    "# #         width_shift_range=0.1,\n",
    "# #         height_shift_range=0.1,\n",
    "# #         horizontal_flip=True\n",
    "# #     )\n",
    "# #         datagen.fit(training_x)\n",
    "\n",
    "# #         batch_size = 128\n",
    "# #         steps_per_epoch = len(training_x) // batch_size\n",
    "# #         ##\n",
    "# #         checkpoint_21 = ModelCheckpoint(\n",
    "# #             filepath=f'adversarial_models/naive_method/{label_dict[(n,v)]}_naive_targeted_21best.keras',\n",
    "# #             monitor='val_accuracy',\n",
    "# #             save_best_only=True,\n",
    "# #             verbose=1\n",
    "# #         )\n",
    "# #         ##\n",
    "# #         naive_one.fit(\n",
    "# #         x=datagen.flow(training_x, training_y_long, batch_size=batch_size),\n",
    "# #         epochs=21,\n",
    "# #         validation_data=(validating_x, validating_y_long),\n",
    "# #         steps_per_epoch=steps_per_epoch,\n",
    "# #         verbose=1,\n",
    "# #         callbacks=[checkpoint_21]\n",
    "# #     )\n",
    "# ##\n",
    "training_y_long=np.concatenate([y_train,y_train[:10001]],axis=0)\n",
    "training_y_long = keras.utils.to_categorical(training_y_long,10)\n",
    "\n",
    "##\n",
    "training_x = np.concatenate([x_train,adv_x_tr_cw_by_resnet56v1_0_untarget],axis=0)\n",
    "validating_x = np.concatenate([x_val,adv_x_val_cw_by_resnet56v1_0_untarget],axis=0)\n",
    "##\n",
    "path = f'adversarial_models/naive_method/{label_dict[(n,v)]}_naive_cw.keras'\n",
    "print(f'fit starts {label_dict[(n,v)]}_naive_cw.keras')\n",
    "resnet_model = ResNet(path,training_x,training_y_long,validating_x,validating_y_long,n=n,version=v)\n",
    "resnet_model.train(save_best_only=True,epochs=200)\n",
    "##\n",
    "print(f'fit ends. Fine tunning.')\n",
    "specialist = turn_specialist(load_model(path),\n",
    "    f'adversarial_models/naive_method/{label_dict[(n,v)]}_naive_cw_fine.keras', \n",
    "    x_train, y_train_categorical_10, \n",
    "    x_val, y_val_categorical_10)\n",
    "#         ##\n",
    "#         print('more epochs on naive one')\n",
    "\n",
    "#         naive_one = load_model(path)\n",
    "#         datagen = ImageDataGenerator(  \n",
    "#         width_shift_range=0.1,\n",
    "#         height_shift_range=0.1,\n",
    "#         horizontal_flip=True\n",
    "#     )\n",
    "#         datagen.fit(training_x)\n",
    "\n",
    "#         batch_size = 128\n",
    "#         steps_per_epoch = len(training_x) // batch_size\n",
    "\n",
    "#         ##\n",
    "#         checkpoint_21 = ModelCheckpoint(\n",
    "#             filepath=f'adversarial_models/naive_method/{label_dict[(n,v)]}_naive_cw_21best.keras',\n",
    "#             monitor='val_accuracy',\n",
    "#             save_best_only=True,\n",
    "#             verbose=1\n",
    "#         )\n",
    "\n",
    "#         ##\n",
    "#         naive_one.fit(\n",
    "#         x=datagen.flow(training_x, training_y_long, batch_size=batch_size),\n",
    "#         epochs=21,\n",
    "#         validation_data=(validating_x, validating_y_long),\n",
    "#         steps_per_epoch=steps_per_epoch,\n",
    "#         verbose=1,\n",
    "#         callbacks=[checkpoint_21]\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9706c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit starts ResNet56v1_ff_targeted-adv_1.keras\n"
     ]
    }
   ],
   "source": [
    "## PGD method, targeted to least likely logit\n",
    "\n",
    "training_x = np.concatenate([x_train,adv_x_tr_pgd_by_resnet56v1_0_target_to_ll],axis=0)\n",
    "validating_x = np.concatenate([x_val,adv_x_val_pgd_by_resnet56v1_0_target_to_ll],axis=0)\n",
    "\n",
    "for n in [9]:\n",
    "    for v in [1]:\n",
    "        for label in [1,2,3]:\n",
    "#         for label in [0,1,2,3]:\n",
    "            path = f'adversarial_models/full_and_fine/{label_dict[(n,v)]}_ff_targeted-adv_{label}.keras'\n",
    "            print(f'fit starts {label_dict[(n,v)]}_ff_targeted-adv_{label}.keras')\n",
    "\n",
    "            # Train full + fine model (will use all visible GPUs)\n",
    "            resnet_model = ResNet(\n",
    "                path,\n",
    "                training_x, training_y_long,\n",
    "                validating_x, validating_y_long,\n",
    "                n=n, version=v\n",
    "            )\n",
    "            resnet_model.train(save_best_only=True, epochs=200)\n",
    "\n",
    "            print(f'fit ends. Turn into specialist on original only')\n",
    "\n",
    "            # Load best model and train specialist on original data\n",
    "            specialist = turn_specialist(\n",
    "                load_model(path),\n",
    "                f'adversarial_models/specialized_from_full_and_fine/classifying_original_from_{label_dict[(n,v)]}_ff_targeted-adv_{label}.keras',\n",
    "                x_train, y_train_categorical_10,\n",
    "                x_val, y_val_categorical_10\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load pre-trained CIFAR10 ResNet models\n",
    "folder = 'CIFAR10models/ResNet/'\n",
    "pattern = os.path.join(folder, '*.keras')\n",
    "file_list = sorted(glob.glob(pattern))\n",
    "loaded_models= {os.path.basename(f): load_model(f) for f in file_list}\n",
    "\n",
    "\n",
    "for f, model_ in loaded_models.items():\n",
    "    base = f.replace('.keras','')\n",
    "    parts = base.split('_')\n",
    "    structure = label_dict[(int(parts[1]), int(parts[2][-1]))]\n",
    "    idx = parts[-1][-1]\n",
    "    \n",
    "\n",
    "    path = f'CIFAR10models/more_tunned/{structure}_more_specialized_{idx}.keras'\n",
    "    specialist = turn_specialist(\n",
    "        model_,\n",
    "        path,\n",
    "        x_train, y_train_categorical_10,    \n",
    "        x_val, y_val_categorical_10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit starts ResNet20v1_ff_targeted-adv_0.keras\n",
      "fit ends. Turn into specialist on original only\n",
      "best val_accuracy 0.903 (first 0.844)\n",
      "fit starts ResNet20v1_ff_targeted-adv_1.keras\n",
      "fit ends. Turn into specialist on original only\n",
      "best val_accuracy 0.904 (first 0.822)\n",
      "fit starts ResNet20v1_ff_targeted-adv_2.keras\n",
      "fit ends. Turn into specialist on original only\n",
      "best val_accuracy 0.902 (first 0.800)\n",
      "fit starts ResNet20v1_ff_targeted-adv_3.keras\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_x = np.concatenate([x_train,adv_x_tr_pgd_by_resnet56v1_0_target_to_ll],axis=0)\n",
    "validating_x = np.concatenate([x_val,adv_x_val_pgd_by_resnet56v1_0_target_to_ll],axis=0)\n",
    "\n",
    "for n in [3,9]:\n",
    "    for v in [1,2]:\n",
    "        for label in [0,1,2,3]:\n",
    "            path = f'adversarial_models/full_and_fine/{label_dict[(n,v)]}_ff_targeted-adv_{label}.keras'\n",
    "            print(f'fit starts {label_dict[(n,v)]}_ff_targeted-adv_{label}.keras')\n",
    "            resnet_model = ResNet(path,training_x,training_y_long,validating_x,validating_y_long,n=n,version=v)\n",
    "            resnet_model.train(save_best_only=True,epochs=200)\n",
    "            print(f'fit ends. Turn into specialist on original only')\n",
    "            specialist = turn_specialist(load_model(path),\n",
    "                f'adversarial_models/specialized_from_full_and_fine/classifying_original_from_{label_dict[(n,v)]}_ff_targeted-adv_{label}.keras', \n",
    "                x_train, y_train_categorical_10, \n",
    "                x_val, y_val_categorical_10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f323a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now adversarial is CWL2, max iteration = 100\n",
    "training_x = np.concatenate([x_train,adv_x_tr_cw_by_resnet56v1_0_untarget],axis=0)\n",
    "validating_x = np.concatenate([x_val,adv_x_val_cw_by_resnet56v1_0_untarget],axis=0)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    for n in [3,9]:\n",
    "        for v in [1,2]:\n",
    "            for label in [0,1,2,3]:\n",
    "                path = f'adversarial_models/full_and_fine/{label_dict[(n,v)]}_ff_cw-adv_{label}.keras'\n",
    "                print(f'fit starts {label_dict[(n,v)]}_ff_cw-adv_{label}.keras')\n",
    "                resnet_model = ResNet(path,training_x,training_y_long,validating_x,validating_y_long,n=n,version=v)\n",
    "                resnet_model.train(save_best_only=True,epochs=200)\n",
    "                print(f'fit ends. Turn into specialist on original only')\n",
    "                specialist = turn_specialist(load_model(path),\n",
    "                    f'adversarial_models/specialized_from_full_and_fine/classifying_original_from_{label_dict[(n,v)]}_ff_cw-adv_{label}.keras', \n",
    "                    x_train, y_train_categorical_10, \n",
    "                    x_val, y_val_categorical_10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea97e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'adversarial_models/full_and_fine/'\n",
    "pattern = os.path.join(folder, '*untargeted*.keras')\n",
    "file_list = sorted(glob.glob(pattern))\n",
    "loaded_models= {os.path.basename(f): load_model(f) for f in file_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b04c7014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ResNet20v1_ff_untargeted-adv_0.keras', 'ResNet20v1_ff_untargeted-adv_1.keras', 'ResNet20v1_ff_untargeted-adv_2.keras', 'ResNet20v1_ff_untargeted-adv_3.keras', 'ResNet20v2_ff_untargeted-adv_0.keras', 'ResNet20v2_ff_untargeted-adv_1.keras', 'ResNet20v2_ff_untargeted-adv_2.keras', 'ResNet20v2_ff_untargeted-adv_3.keras', 'ResNet56v1_ff_untargeted-adv_0.keras', 'ResNet56v1_ff_untargeted-adv_1.keras', 'ResNet56v1_ff_untargeted-adv_2.keras', 'ResNet56v1_ff_untargeted-adv_3.keras', 'ResNet56v2_ff_untargeted-adv_0.keras', 'ResNet56v2_ff_untargeted-adv_1.keras'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a48977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            model   acc_0   acc_1   acc_2   acc_3    acc_av\n",
      "0  ResNet20v1, untargeted-adv_pgd  0.8556  0.8384  0.8760  0.8520  0.855500\n",
      "1  ResNet20v2, untargeted-adv_pgd  0.7979  0.7940  0.8147  0.8118  0.804600\n",
      "2  ResNet56v1, untargeted-adv_pgd  0.8509  0.8291  0.8410  0.8339  0.838725\n",
      "3  ResNet56v2, untargeted-adv_pgd  0.7930  0.8064     NaN     NaN  0.799700\n"
     ]
    }
   ],
   "source": [
    "results = {}  # structure: {(structure, attack type): [acc_0, acc_1, acc_2, acc_3]}\n",
    "\n",
    "for filename, model in loaded_models.items():\n",
    "    # Example filename: 'ResNet20v1_ff_untargeted-adv_0.keras'\n",
    "    # Extract family and index\n",
    "    base = filename.replace('.keras','')\n",
    "    parts = base.split('_')\n",
    "    structure = parts[0]  # ResNet20v1, etc.\n",
    "    attack_type = parts[2] + '_ff_pgd'  # untargeted\n",
    "    idx = int(parts[-1].split('-')[-1])  # last digit after -adv_\n",
    "\n",
    "    key = (structure, attack_type)\n",
    "    prediction = model.predict(x_test, verbose = 0)\n",
    "    acc = np.sum(np.argmax(prediction,axis=-1) == y_test.reshape(-1)) / len(x_test)\n",
    "\n",
    "    if key not in results:\n",
    "        results[key] = {}\n",
    "    results[key][f'acc_{idx}'] = acc\n",
    "\n",
    "\n",
    "rows = []\n",
    "for (structure, attack_type), acc_dict in results.items():\n",
    "    accs = [acc_dict.get(f'acc_{i}', np.nan) for i in range(4)]\n",
    "    acc_av = np.nanmean(accs)\n",
    "    row = [f'{structure}, {attack_type}'] + accs + [acc_av]\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['model', 'acc_0', 'acc_1', 'acc_2', 'acc_3', 'acc_av'])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6b454e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['classifying_original_from_ResNet20v1_ff_untargeted-adv_0.keras', 'classifying_original_from_ResNet20v1_ff_untargeted-adv_1.keras', 'classifying_original_from_ResNet20v1_ff_untargeted-adv_2.keras', 'classifying_original_from_ResNet20v1_ff_untargeted-adv_3.keras', 'classifying_original_from_ResNet20v2_ff_untargeted-adv_0.keras', 'classifying_original_from_ResNet20v2_ff_untargeted-adv_1.keras', 'classifying_original_from_ResNet20v2_ff_untargeted-adv_2.keras', 'classifying_original_from_ResNet20v2_ff_untargeted-adv_3.keras', 'classifying_original_from_ResNet56v1_ff_untargeted-adv_0.keras', 'classifying_original_from_ResNet56v1_ff_untargeted-adv_1.keras', 'classifying_original_from_ResNet56v1_ff_untargeted-adv_2.keras', 'classifying_original_from_ResNet56v1_ff_untargeted-adv_3.keras', 'classifying_original_from_ResNet56v2_ff_untargeted-adv_0.keras'])\n"
     ]
    }
   ],
   "source": [
    "folder = 'adversarial_models/specialized_from_full_and_fine/'\n",
    "pattern = os.path.join(folder, '*untargeted*.keras')\n",
    "file_list = sorted(glob.glob(pattern))\n",
    "loaded_models= {os.path.basename(f): load_model(f) for f in file_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4c25649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            model   acc_0   acc_1   acc_2   acc_3    acc_av\n",
      "0  ResNet20v1, untargeted-adv_pgd  0.9029  0.8992  0.9010  0.9033  0.901600\n",
      "1  ResNet20v2, untargeted-adv_pgd  0.9101  0.9060  0.9058  0.9052  0.906775\n",
      "2  ResNet56v1, untargeted-adv_pgd  0.9095  0.9097  0.9079  0.9123  0.909850\n",
      "3  ResNet56v2, untargeted-adv_pgd  0.9102     NaN     NaN     NaN  0.910200\n"
     ]
    }
   ],
   "source": [
    "results = {}  # structure: {(structure, attack type): [acc_0, acc_1, acc_2, acc_3]}\n",
    "\n",
    "for filename, model in loaded_models.items():\n",
    "    # Example filename: 'classifying_original_from_ResNet20v1_ff_untargeted-adv_0.keras'\n",
    "    # Extract family and index\n",
    "    base = filename.replace('.keras','')\n",
    "    parts = base.split('_')\n",
    "    structure = parts[3]  # ResNet20v1, etc.\n",
    "    attack_type = parts[5] + '_original_pgd'  # untargeted\n",
    "    idx = int(parts[-1].split('-')[-1])  # last digit after -adv_\n",
    "\n",
    "    key = (structure, attack_type)\n",
    "    prediction = model.predict(x_test, verbose = 0)\n",
    "    acc = np.sum(np.argmax(prediction,axis=-1) == y_test.reshape(-1)) / len(x_test)\n",
    "\n",
    "    if key not in results:\n",
    "        results[key] = {}\n",
    "    results[key][f'acc_{idx}'] = acc\n",
    "\n",
    "\n",
    "rows = []\n",
    "for (structure, attack_type), acc_dict in results.items():\n",
    "    accs = [acc_dict.get(f'acc_{i}', np.nan) for i in range(4)]\n",
    "    acc_av = np.nanmean(accs)\n",
    "    row = [f'{structure}, {attack_type}'] + accs + [acc_av]\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['model', 'acc_0', 'acc_1', 'acc_2', 'acc_3', 'acc_av'])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626db79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
