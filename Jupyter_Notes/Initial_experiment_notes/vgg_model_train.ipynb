{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56a21688",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "VGG11/13/16/19 in TensorFlow2.\n",
    "\n",
    "Reference:\n",
    "[1] Simonyan, Karen, and Andrew Zisserman. \n",
    "    \"Very deep convolutional networks for large-scale image recognition.\" \n",
    "    arXiv preprint arXiv:1409.1556 (2014).\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input\n",
    "from tensorflow.keras.layers import Flatten, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "config = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "def build_vgg_functional(vgg_name, num_classes):\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    x = inputs\n",
    "    for l in config[vgg_name]:\n",
    "        if l == 'M':\n",
    "            x = layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "        else:\n",
    "            x = layers.Conv2D(l, kernel_size=3, padding='same')(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.AveragePooling2D(pool_size=1, strides=1)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    \n",
    "    return lr\n",
    "\n",
    "class trainer():\n",
    "    def __init__(self, path, x_tr, y_tr, x_v, y_v, model_name,num_classes,subtract_pixel_mean = True,):\n",
    "        assert len(y_tr.shape)==2\n",
    "        assert len(y_v.shape)==2\n",
    "        assert len(x_tr.shape)==4\n",
    "        assert len(x_v.shape)==4\n",
    "        \n",
    "        self.path = path #\"path_of_folder/\" for saving and loading\n",
    "        \n",
    "        # if subtract pixel mean is enabled\n",
    "        if subtract_pixel_mean:\n",
    "            x_train_mean = np.mean(x_tr, axis=0)\n",
    "            x_tr -= x_train_mean\n",
    "            x_v -= x_train_mean          \n",
    "        \n",
    "        self.x_tr = x_tr\n",
    "        self.y_tr = y_tr\n",
    "        self.x_v = x_v\n",
    "        self.y_v = y_v\n",
    "        self.subtract_pixel_mean = subtract_pixel_mean\n",
    "        self.model = build_vgg_functional(model_name, num_classes=num_classes)\n",
    "        self.model.save(path)\n",
    "    def train(self, batch_size = 32, epochs = 200, \n",
    "              data_augmentation = True, optimizer=None,loss='categorical_crossentropy', \n",
    "              save_best_only=False,save_weights_only=False):\n",
    "              \n",
    "        if optimizer is None:\n",
    "              optimizer=Adam(learning_rate=lr_schedule(0))\n",
    "              \n",
    "        self.optimizer = optimizer\n",
    "        self.model.compile(loss=loss,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['acc'])\n",
    "              \n",
    "        # prepare callbacks for model saving and for learning rate adjustment.\n",
    "        checkpoint = ModelCheckpoint(filepath=self.path,\n",
    "                                     monitor='val_acc',\n",
    "                                     verbose=1,\n",
    "                                     save_best_only=save_best_only, save_weights_only=save_weights_only)\n",
    "\n",
    "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "        lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                                       cooldown=0,\n",
    "                                       patience=5,\n",
    "                                       min_lr=0.5e-6)\n",
    "\n",
    "        callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "        # run training, with or without data augmentation.\n",
    "        if not data_augmentation:\n",
    "            print('Not using data augmentation.')\n",
    "            self.model.fit(self.x_tr, self.y_tr,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(self.x_v, self.y_v),\n",
    "                      shuffle=True,\n",
    "                      callbacks=callbacks)\n",
    "        else:\n",
    "            print('Using real-time data augmentation.')\n",
    "            # this will do preprocessing and realtime data augmentation:\n",
    "            datagen = ImageDataGenerator(\n",
    "                # set input mean to 0 over the dataset\n",
    "                featurewise_center=False,\n",
    "                # set each sample mean to 0\n",
    "                samplewise_center=False,\n",
    "                # divide inputs by std of dataset\n",
    "                featurewise_std_normalization=False,\n",
    "                # divide each input by its std\n",
    "                samplewise_std_normalization=False,\n",
    "                # apply ZCA whitening\n",
    "                zca_whitening=False,\n",
    "                # randomly rotate images in the range (deg 0 to 180)\n",
    "                rotation_range=0,\n",
    "                # randomly shift images horizontally\n",
    "                width_shift_range=0.1,\n",
    "                # randomly shift images vertically\n",
    "                height_shift_range=0.1,\n",
    "                # randomly flip images\n",
    "                horizontal_flip=True,\n",
    "                # randomly flip images\n",
    "                vertical_flip=False)\n",
    "\n",
    "            # compute quantities required for featurewise normalization\n",
    "            # (std, mean, and principal components if ZCA whitening is applied).\n",
    "            datagen.fit(self.x_tr)\n",
    "\n",
    "            steps_per_epoch =  math.ceil(len(self.x_tr) / batch_size)\n",
    "            # fit the model on the batches generated by datagen.flow().\n",
    "            self.model.fit(x=datagen.flow(self.x_tr, self.y_tr, batch_size=batch_size),\n",
    "                      verbose=0,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(self.x_v, self.y_v),\n",
    "                      steps_per_epoch=steps_per_epoch,\n",
    "                      callbacks=callbacks)\n",
    "        return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a74b403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "import keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# # building the input vector from the 32x32 pixels\n",
    "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "input_shape = (32,32,3)\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99315bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b61fb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_190 (Conv2D)         (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_190 (Ba  (None, 32, 32, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_190 (ReLU)            (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_191 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_191 (Ba  (None, 16, 16, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_191 (ReLU)            (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_76 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_192 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_192 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_192 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_193 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_193 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_193 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_77 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_194 (Conv2D)         (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_194 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_194 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_195 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_195 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_195 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPoolin  (None, 2, 2, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_196 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_196 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_196 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_197 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_197 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_197 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_79 (MaxPoolin  (None, 1, 1, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " average_pooling2d_15 (Avera  (None, 1, 1, 512)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,236,618\n",
      "Trainable params: 9,231,114\n",
      "Non-trainable params: 5,504\n",
      "_________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.49310, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 2: val_acc improved from 0.49310 to 0.58670, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 3: val_acc improved from 0.58670 to 0.75470, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 4: val_acc improved from 0.75470 to 0.76310, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 5: val_acc did not improve from 0.76310\n",
      "\n",
      "Epoch 6: val_acc improved from 0.76310 to 0.77940, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 7: val_acc improved from 0.77940 to 0.79000, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 8: val_acc improved from 0.79000 to 0.79170, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 9: val_acc improved from 0.79170 to 0.80450, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 10: val_acc improved from 0.80450 to 0.82950, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 11: val_acc improved from 0.82950 to 0.83490, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 12: val_acc improved from 0.83490 to 0.85140, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 13: val_acc did not improve from 0.85140\n",
      "\n",
      "Epoch 14: val_acc did not improve from 0.85140\n",
      "\n",
      "Epoch 15: val_acc did not improve from 0.85140\n",
      "\n",
      "Epoch 16: val_acc improved from 0.85140 to 0.85190, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 17: val_acc improved from 0.85190 to 0.86270, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 18: val_acc did not improve from 0.86270\n",
      "\n",
      "Epoch 19: val_acc did not improve from 0.86270\n",
      "\n",
      "Epoch 20: val_acc improved from 0.86270 to 0.86310, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 21: val_acc improved from 0.86310 to 0.87000, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 22: val_acc did not improve from 0.87000\n",
      "\n",
      "Epoch 23: val_acc did not improve from 0.87000\n",
      "\n",
      "Epoch 24: val_acc did not improve from 0.87000\n",
      "\n",
      "Epoch 25: val_acc improved from 0.87000 to 0.87160, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 26: val_acc improved from 0.87160 to 0.87230, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 27: val_acc did not improve from 0.87230\n",
      "\n",
      "Epoch 28: val_acc improved from 0.87230 to 0.87480, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 29: val_acc improved from 0.87480 to 0.87780, saving model to models/CIFAR10_vgg11.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: val_acc did not improve from 0.87780\n",
      "\n",
      "Epoch 31: val_acc did not improve from 0.87780\n",
      "\n",
      "Epoch 32: val_acc did not improve from 0.87780\n",
      "\n",
      "Epoch 33: val_acc did not improve from 0.87780\n",
      "\n",
      "Epoch 34: val_acc did not improve from 0.87780\n",
      "\n",
      "Epoch 35: val_acc did not improve from 0.87780\n",
      "\n",
      "Epoch 36: val_acc improved from 0.87780 to 0.87810, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 37: val_acc did not improve from 0.87810\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.87810\n",
      "\n",
      "Epoch 39: val_acc improved from 0.87810 to 0.88310, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 40: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 41: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 42: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 43: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 44: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 45: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 46: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 47: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 48: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 49: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 50: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 51: val_acc did not improve from 0.88310\n",
      "\n",
      "Epoch 52: val_acc improved from 0.88310 to 0.88320, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 53: val_acc did not improve from 0.88320\n",
      "\n",
      "Epoch 54: val_acc did not improve from 0.88320\n",
      "\n",
      "Epoch 55: val_acc did not improve from 0.88320\n",
      "\n",
      "Epoch 56: val_acc did not improve from 0.88320\n",
      "\n",
      "Epoch 57: val_acc improved from 0.88320 to 0.88410, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 58: val_acc did not improve from 0.88410\n",
      "\n",
      "Epoch 59: val_acc did not improve from 0.88410\n",
      "\n",
      "Epoch 60: val_acc did not improve from 0.88410\n",
      "\n",
      "Epoch 61: val_acc did not improve from 0.88410\n",
      "\n",
      "Epoch 62: val_acc improved from 0.88410 to 0.88600, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 63: val_acc did not improve from 0.88600\n",
      "\n",
      "Epoch 64: val_acc improved from 0.88600 to 0.88610, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 65: val_acc did not improve from 0.88610\n",
      "\n",
      "Epoch 66: val_acc improved from 0.88610 to 0.88760, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 67: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 68: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 69: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 70: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 71: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 72: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 73: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 74: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 75: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 76: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 77: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 78: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 79: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 80: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 81: val_acc did not improve from 0.88760\n",
      "\n",
      "Epoch 82: val_acc improved from 0.88760 to 0.89510, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 83: val_acc improved from 0.89510 to 0.89640, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 84: val_acc improved from 0.89640 to 0.89660, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 85: val_acc improved from 0.89660 to 0.89830, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 86: val_acc improved from 0.89830 to 0.89860, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 87: val_acc did not improve from 0.89860\n",
      "\n",
      "Epoch 88: val_acc improved from 0.89860 to 0.90090, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 89: val_acc did not improve from 0.90090\n",
      "\n",
      "Epoch 90: val_acc did not improve from 0.90090\n",
      "\n",
      "Epoch 91: val_acc did not improve from 0.90090\n",
      "\n",
      "Epoch 92: val_acc improved from 0.90090 to 0.90130, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 93: val_acc did not improve from 0.90130\n",
      "\n",
      "Epoch 94: val_acc did not improve from 0.90130\n",
      "\n",
      "Epoch 95: val_acc did not improve from 0.90130\n",
      "\n",
      "Epoch 96: val_acc did not improve from 0.90130\n",
      "\n",
      "Epoch 97: val_acc did not improve from 0.90130\n",
      "\n",
      "Epoch 98: val_acc did not improve from 0.90130\n",
      "\n",
      "Epoch 99: val_acc did not improve from 0.90130\n",
      "\n",
      "Epoch 100: val_acc improved from 0.90130 to 0.90200, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 101: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 102: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 103: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 104: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 105: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 106: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 107: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 108: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 109: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 110: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 111: val_acc did not improve from 0.90200\n",
      "\n",
      "Epoch 112: val_acc improved from 0.90200 to 0.90270, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 113: val_acc did not improve from 0.90270\n",
      "\n",
      "Epoch 114: val_acc improved from 0.90270 to 0.90370, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 115: val_acc did not improve from 0.90370\n",
      "\n",
      "Epoch 116: val_acc did not improve from 0.90370\n",
      "\n",
      "Epoch 117: val_acc did not improve from 0.90370\n",
      "\n",
      "Epoch 118: val_acc did not improve from 0.90370\n",
      "\n",
      "Epoch 119: val_acc did not improve from 0.90370\n",
      "\n",
      "Epoch 120: val_acc did not improve from 0.90370\n",
      "\n",
      "Epoch 121: val_acc did not improve from 0.90370\n",
      "\n",
      "Epoch 122: val_acc did not improve from 0.90370\n",
      "\n",
      "Epoch 123: val_acc did not improve from 0.90370\n",
      "\n",
      "Epoch 124: val_acc did not improve from 0.90370\n",
      "\n",
      "Epoch 125: val_acc improved from 0.90370 to 0.90380, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 126: val_acc did not improve from 0.90380\n",
      "\n",
      "Epoch 127: val_acc improved from 0.90380 to 0.90390, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 128: val_acc did not improve from 0.90390\n",
      "\n",
      "Epoch 129: val_acc did not improve from 0.90390\n",
      "\n",
      "Epoch 130: val_acc did not improve from 0.90390\n",
      "\n",
      "Epoch 131: val_acc did not improve from 0.90390\n",
      "\n",
      "Epoch 132: val_acc improved from 0.90390 to 0.90460, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 133: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 134: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 135: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 136: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 137: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 138: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 139: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 140: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 141: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 142: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 143: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 144: val_acc did not improve from 0.90460\n",
      "\n",
      "Epoch 145: val_acc improved from 0.90460 to 0.90480, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 146: val_acc did not improve from 0.90480\n",
      "\n",
      "Epoch 147: val_acc did not improve from 0.90480\n",
      "\n",
      "Epoch 148: val_acc did not improve from 0.90480\n",
      "\n",
      "Epoch 149: val_acc did not improve from 0.90480\n",
      "\n",
      "Epoch 150: val_acc did not improve from 0.90480\n",
      "\n",
      "Epoch 151: val_acc did not improve from 0.90480\n",
      "\n",
      "Epoch 152: val_acc did not improve from 0.90480\n",
      "\n",
      "Epoch 153: val_acc did not improve from 0.90480\n",
      "\n",
      "Epoch 154: val_acc improved from 0.90480 to 0.90500, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 155: val_acc improved from 0.90500 to 0.90540, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 156: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 157: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 158: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 159: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 160: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 161: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 162: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 163: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 164: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 165: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 166: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 167: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 168: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 169: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 170: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 171: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 172: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 173: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 174: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 175: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 176: val_acc did not improve from 0.90540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 177: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 178: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 179: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 180: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 181: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 182: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 183: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 184: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 185: val_acc did not improve from 0.90540\n",
      "\n",
      "Epoch 186: val_acc improved from 0.90540 to 0.90580, saving model to models/CIFAR10_vgg11.keras\n",
      "\n",
      "Epoch 187: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 188: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 189: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 190: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 191: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 192: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 193: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 194: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 195: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 196: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 197: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 198: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 199: val_acc did not improve from 0.90580\n",
      "\n",
      "Epoch 200: val_acc did not improve from 0.90580\n",
      "313/313 [==============================] - 0s 951us/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_208 (Conv2D)         (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_208 (Ba  (None, 32, 32, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_208 (ReLU)            (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_209 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_209 (Ba  (None, 32, 32, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_209 (ReLU)            (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_85 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_210 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_210 (Ba  (None, 16, 16, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_210 (ReLU)            (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_211 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_211 (Ba  (None, 16, 16, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_211 (ReLU)            (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_86 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_212 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_212 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_212 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_213 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_213 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_213 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_87 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_214 (Conv2D)         (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_214 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_214 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_215 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_215 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_215 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_88 (MaxPoolin  (None, 2, 2, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_216 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_216 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_216 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_217 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_217 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_217 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_89 (MaxPoolin  (None, 1, 1, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " average_pooling2d_17 (Avera  (None, 1, 1, 512)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,421,898\n",
      "Trainable params: 9,416,010\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.60430, saving model to models/CIFAR10_vgg13.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_acc improved from 0.60430 to 0.71380, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 3: val_acc did not improve from 0.71380\n",
      "\n",
      "Epoch 4: val_acc improved from 0.71380 to 0.76000, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 5: val_acc did not improve from 0.76000\n",
      "\n",
      "Epoch 6: val_acc improved from 0.76000 to 0.78550, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 7: val_acc improved from 0.78550 to 0.80860, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 8: val_acc improved from 0.80860 to 0.83080, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 9: val_acc improved from 0.83080 to 0.84840, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 10: val_acc did not improve from 0.84840\n",
      "\n",
      "Epoch 11: val_acc did not improve from 0.84840\n",
      "\n",
      "Epoch 12: val_acc did not improve from 0.84840\n",
      "\n",
      "Epoch 13: val_acc did not improve from 0.84840\n",
      "\n",
      "Epoch 14: val_acc did not improve from 0.84840\n",
      "\n",
      "Epoch 15: val_acc improved from 0.84840 to 0.87010, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 16: val_acc did not improve from 0.87010\n",
      "\n",
      "Epoch 17: val_acc improved from 0.87010 to 0.87970, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 18: val_acc improved from 0.87970 to 0.88170, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 19: val_acc did not improve from 0.88170\n",
      "\n",
      "Epoch 20: val_acc did not improve from 0.88170\n",
      "\n",
      "Epoch 21: val_acc improved from 0.88170 to 0.88230, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 22: val_acc did not improve from 0.88230\n",
      "\n",
      "Epoch 23: val_acc improved from 0.88230 to 0.88340, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 24: val_acc did not improve from 0.88340\n",
      "\n",
      "Epoch 25: val_acc did not improve from 0.88340\n",
      "\n",
      "Epoch 26: val_acc improved from 0.88340 to 0.89010, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 27: val_acc did not improve from 0.89010\n",
      "\n",
      "Epoch 28: val_acc did not improve from 0.89010\n",
      "\n",
      "Epoch 29: val_acc did not improve from 0.89010\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.89010\n",
      "\n",
      "Epoch 31: val_acc did not improve from 0.89010\n",
      "\n",
      "Epoch 32: val_acc did not improve from 0.89010\n",
      "\n",
      "Epoch 33: val_acc did not improve from 0.89010\n",
      "\n",
      "Epoch 34: val_acc improved from 0.89010 to 0.89380, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 35: val_acc did not improve from 0.89380\n",
      "\n",
      "Epoch 36: val_acc did not improve from 0.89380\n",
      "\n",
      "Epoch 37: val_acc did not improve from 0.89380\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.89380\n",
      "\n",
      "Epoch 39: val_acc did not improve from 0.89380\n",
      "\n",
      "Epoch 40: val_acc did not improve from 0.89380\n",
      "\n",
      "Epoch 41: val_acc did not improve from 0.89380\n",
      "\n",
      "Epoch 42: val_acc did not improve from 0.89380\n",
      "\n",
      "Epoch 43: val_acc did not improve from 0.89380\n",
      "\n",
      "Epoch 44: val_acc did not improve from 0.89380\n",
      "\n",
      "Epoch 45: val_acc improved from 0.89380 to 0.89390, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 46: val_acc improved from 0.89390 to 0.89540, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 47: val_acc did not improve from 0.89540\n",
      "\n",
      "Epoch 48: val_acc did not improve from 0.89540\n",
      "\n",
      "Epoch 49: val_acc did not improve from 0.89540\n",
      "\n",
      "Epoch 50: val_acc did not improve from 0.89540\n",
      "\n",
      "Epoch 51: val_acc did not improve from 0.89540\n",
      "\n",
      "Epoch 52: val_acc did not improve from 0.89540\n",
      "\n",
      "Epoch 53: val_acc improved from 0.89540 to 0.89920, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 54: val_acc did not improve from 0.89920\n",
      "\n",
      "Epoch 55: val_acc did not improve from 0.89920\n",
      "\n",
      "Epoch 56: val_acc did not improve from 0.89920\n",
      "\n",
      "Epoch 57: val_acc improved from 0.89920 to 0.90180, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 58: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 59: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 60: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 61: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 62: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 63: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 64: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 65: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 66: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 67: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 68: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 69: val_acc did not improve from 0.90180\n",
      "\n",
      "Epoch 70: val_acc improved from 0.90180 to 0.90610, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 71: val_acc did not improve from 0.90610\n",
      "\n",
      "Epoch 72: val_acc did not improve from 0.90610\n",
      "\n",
      "Epoch 73: val_acc did not improve from 0.90610\n",
      "\n",
      "Epoch 74: val_acc did not improve from 0.90610\n",
      "\n",
      "Epoch 75: val_acc did not improve from 0.90610\n",
      "\n",
      "Epoch 76: val_acc did not improve from 0.90610\n",
      "\n",
      "Epoch 77: val_acc did not improve from 0.90610\n",
      "\n",
      "Epoch 78: val_acc improved from 0.90610 to 0.90810, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 79: val_acc did not improve from 0.90810\n",
      "\n",
      "Epoch 80: val_acc did not improve from 0.90810\n",
      "\n",
      "Epoch 81: val_acc did not improve from 0.90810\n",
      "\n",
      "Epoch 82: val_acc improved from 0.90810 to 0.91490, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 83: val_acc improved from 0.91490 to 0.91670, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 84: val_acc did not improve from 0.91670\n",
      "\n",
      "Epoch 85: val_acc did not improve from 0.91670\n",
      "\n",
      "Epoch 86: val_acc improved from 0.91670 to 0.91740, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 87: val_acc improved from 0.91740 to 0.91960, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 88: val_acc did not improve from 0.91960\n",
      "\n",
      "Epoch 89: val_acc did not improve from 0.91960\n",
      "\n",
      "Epoch 90: val_acc did not improve from 0.91960\n",
      "\n",
      "Epoch 91: val_acc did not improve from 0.91960\n",
      "\n",
      "Epoch 92: val_acc improved from 0.91960 to 0.92080, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 93: val_acc did not improve from 0.92080\n",
      "\n",
      "Epoch 94: val_acc did not improve from 0.92080\n",
      "\n",
      "Epoch 95: val_acc did not improve from 0.92080\n",
      "\n",
      "Epoch 96: val_acc improved from 0.92080 to 0.92110, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 97: val_acc did not improve from 0.92110\n",
      "\n",
      "Epoch 98: val_acc did not improve from 0.92110\n",
      "\n",
      "Epoch 99: val_acc did not improve from 0.92110\n",
      "\n",
      "Epoch 100: val_acc improved from 0.92110 to 0.92180, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 101: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 102: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 103: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 104: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 105: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 106: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 107: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 108: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 109: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 110: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 111: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 112: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 113: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 114: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 115: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 116: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 117: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 118: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 119: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 120: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 121: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 122: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 123: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 124: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 125: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 126: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 127: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 128: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 129: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 130: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 131: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 132: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 133: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 134: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 135: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 136: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 137: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 138: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 139: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 140: val_acc did not improve from 0.92180\n",
      "\n",
      "Epoch 141: val_acc improved from 0.92180 to 0.92190, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 142: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 143: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 144: val_acc did not improve from 0.92190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 145: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 146: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 147: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 148: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 149: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 150: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 151: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 152: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 153: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 154: val_acc improved from 0.92190 to 0.92220, saving model to models/CIFAR10_vgg13.keras\n",
      "\n",
      "Epoch 155: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 156: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 157: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 158: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 159: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 160: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 161: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 162: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 163: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 164: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 165: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 166: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 167: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 168: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 169: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 170: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 171: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 172: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 173: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 174: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 175: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 176: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 177: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 178: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 179: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 180: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 181: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 182: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 183: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 184: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 185: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 186: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 187: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 188: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 189: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 190: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 191: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 192: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 193: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 194: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 195: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 196: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 197: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 198: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 199: val_acc did not improve from 0.92220\n",
      "\n",
      "Epoch 200: val_acc did not improve from 0.92220\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_231 (Conv2D)         (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_231 (Ba  (None, 32, 32, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_231 (ReLU)            (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_232 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_232 (Ba  (None, 32, 32, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_232 (ReLU)            (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_95 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_233 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_233 (Ba  (None, 16, 16, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_233 (ReLU)            (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_234 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_234 (Ba  (None, 16, 16, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_234 (ReLU)            (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_96 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_235 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_235 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_235 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_236 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_236 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_236 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_237 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_237 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_237 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_97 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_238 (Conv2D)         (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_238 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_238 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_239 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_239 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_239 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_240 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_240 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_240 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_98 (MaxPoolin  (None, 2, 2, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_241 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_241 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_241 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_242 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_242 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_242 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_243 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_243 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_243 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_99 (MaxPoolin  (None, 1, 1, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " average_pooling2d_19 (Avera  (None, 1, 1, 512)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,736,714\n",
      "Trainable params: 14,728,266\n",
      "Non-trainable params: 8,448\n",
      "_________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.45880, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 2: val_acc improved from 0.45880 to 0.57210, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 3: val_acc improved from 0.57210 to 0.67840, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 4: val_acc improved from 0.67840 to 0.68390, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 5: val_acc improved from 0.68390 to 0.71470, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 6: val_acc improved from 0.71470 to 0.72740, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 7: val_acc improved from 0.72740 to 0.78840, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 8: val_acc improved from 0.78840 to 0.80580, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 9: val_acc improved from 0.80580 to 0.83380, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 10: val_acc improved from 0.83380 to 0.83890, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 11: val_acc did not improve from 0.83890\n",
      "\n",
      "Epoch 12: val_acc did not improve from 0.83890\n",
      "\n",
      "Epoch 13: val_acc improved from 0.83890 to 0.84850, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 14: val_acc did not improve from 0.84850\n",
      "\n",
      "Epoch 15: val_acc improved from 0.84850 to 0.85900, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 16: val_acc did not improve from 0.85900\n",
      "\n",
      "Epoch 17: val_acc improved from 0.85900 to 0.86840, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 18: val_acc did not improve from 0.86840\n",
      "\n",
      "Epoch 19: val_acc did not improve from 0.86840\n",
      "\n",
      "Epoch 20: val_acc improved from 0.86840 to 0.87770, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 21: val_acc did not improve from 0.87770\n",
      "\n",
      "Epoch 22: val_acc did not improve from 0.87770\n",
      "\n",
      "Epoch 23: val_acc did not improve from 0.87770\n",
      "\n",
      "Epoch 24: val_acc did not improve from 0.87770\n",
      "\n",
      "Epoch 25: val_acc did not improve from 0.87770\n",
      "\n",
      "Epoch 26: val_acc improved from 0.87770 to 0.89080, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 27: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 28: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 29: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 31: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 32: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 33: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 34: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 35: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 36: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 37: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 39: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 40: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 41: val_acc did not improve from 0.89080\n",
      "\n",
      "Epoch 42: val_acc improved from 0.89080 to 0.89330, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 43: val_acc improved from 0.89330 to 0.89580, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 44: val_acc did not improve from 0.89580\n",
      "\n",
      "Epoch 45: val_acc did not improve from 0.89580\n",
      "\n",
      "Epoch 46: val_acc did not improve from 0.89580\n",
      "\n",
      "Epoch 47: val_acc did not improve from 0.89580\n",
      "\n",
      "Epoch 48: val_acc did not improve from 0.89580\n",
      "\n",
      "Epoch 49: val_acc did not improve from 0.89580\n",
      "\n",
      "Epoch 50: val_acc did not improve from 0.89580\n",
      "\n",
      "Epoch 51: val_acc did not improve from 0.89580\n",
      "\n",
      "Epoch 52: val_acc did not improve from 0.89580\n",
      "\n",
      "Epoch 53: val_acc improved from 0.89580 to 0.89800, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 54: val_acc did not improve from 0.89800\n",
      "\n",
      "Epoch 55: val_acc did not improve from 0.89800\n",
      "\n",
      "Epoch 56: val_acc did not improve from 0.89800\n",
      "\n",
      "Epoch 57: val_acc did not improve from 0.89800\n",
      "\n",
      "Epoch 58: val_acc did not improve from 0.89800\n",
      "\n",
      "Epoch 59: val_acc did not improve from 0.89800\n",
      "\n",
      "Epoch 60: val_acc did not improve from 0.89800\n",
      "\n",
      "Epoch 61: val_acc did not improve from 0.89800\n",
      "\n",
      "Epoch 62: val_acc did not improve from 0.89800\n",
      "\n",
      "Epoch 63: val_acc improved from 0.89800 to 0.89890, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 64: val_acc did not improve from 0.89890\n",
      "\n",
      "Epoch 65: val_acc did not improve from 0.89890\n",
      "\n",
      "Epoch 66: val_acc did not improve from 0.89890\n",
      "\n",
      "Epoch 67: val_acc did not improve from 0.89890\n",
      "\n",
      "Epoch 68: val_acc did not improve from 0.89890\n",
      "\n",
      "Epoch 69: val_acc improved from 0.89890 to 0.90170, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 70: val_acc did not improve from 0.90170\n",
      "\n",
      "Epoch 71: val_acc did not improve from 0.90170\n",
      "\n",
      "Epoch 72: val_acc did not improve from 0.90170\n",
      "\n",
      "Epoch 73: val_acc did not improve from 0.90170\n",
      "\n",
      "Epoch 74: val_acc did not improve from 0.90170\n",
      "\n",
      "Epoch 75: val_acc did not improve from 0.90170\n",
      "\n",
      "Epoch 76: val_acc did not improve from 0.90170\n",
      "\n",
      "Epoch 77: val_acc improved from 0.90170 to 0.90430, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 78: val_acc did not improve from 0.90430\n",
      "\n",
      "Epoch 79: val_acc did not improve from 0.90430\n",
      "\n",
      "Epoch 80: val_acc did not improve from 0.90430\n",
      "\n",
      "Epoch 81: val_acc did not improve from 0.90430\n",
      "\n",
      "Epoch 82: val_acc improved from 0.90430 to 0.91180, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 83: val_acc improved from 0.91180 to 0.91340, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 84: val_acc improved from 0.91340 to 0.91490, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 85: val_acc improved from 0.91490 to 0.91520, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 86: val_acc improved from 0.91520 to 0.91660, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 87: val_acc did not improve from 0.91660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88: val_acc did not improve from 0.91660\n",
      "\n",
      "Epoch 89: val_acc improved from 0.91660 to 0.91810, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 90: val_acc did not improve from 0.91810\n",
      "\n",
      "Epoch 91: val_acc did not improve from 0.91810\n",
      "\n",
      "Epoch 92: val_acc did not improve from 0.91810\n",
      "\n",
      "Epoch 93: val_acc did not improve from 0.91810\n",
      "\n",
      "Epoch 94: val_acc did not improve from 0.91810\n",
      "\n",
      "Epoch 95: val_acc improved from 0.91810 to 0.91930, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 96: val_acc did not improve from 0.91930\n",
      "\n",
      "Epoch 97: val_acc did not improve from 0.91930\n",
      "\n",
      "Epoch 98: val_acc improved from 0.91930 to 0.91990, saving model to models/CIFAR10_vgg16.keras\n",
      "\n",
      "Epoch 99: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 100: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 101: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 102: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 103: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 104: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 105: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 106: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 107: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 108: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 109: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 110: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 111: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 112: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 113: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 114: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 115: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 116: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 117: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 118: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 119: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 120: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 121: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 122: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 123: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 124: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 125: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 126: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 127: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 128: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 129: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 130: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 131: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 132: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 133: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 134: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 135: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 136: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 137: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 138: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 139: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 140: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 141: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 142: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 143: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 144: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 145: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 146: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 147: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 148: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 149: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 150: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 151: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 152: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 153: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 154: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 155: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 156: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 157: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 158: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 159: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 160: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 161: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 162: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 163: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 164: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 165: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 166: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 167: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 168: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 169: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 170: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 171: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 172: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 173: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 174: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 175: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 176: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 177: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 178: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 179: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 180: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 181: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 182: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 183: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 184: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 185: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 186: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 187: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 188: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 189: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 190: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 191: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 192: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 193: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 194: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 195: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 196: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 197: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 198: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 199: val_acc did not improve from 0.91990\n",
      "\n",
      "Epoch 200: val_acc did not improve from 0.91990\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_260 (Conv2D)         (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_260 (Ba  (None, 32, 32, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_260 (ReLU)            (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_261 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_261 (Ba  (None, 32, 32, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_261 (ReLU)            (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_105 (MaxPooli  (None, 16, 16, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_262 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_262 (Ba  (None, 16, 16, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_262 (ReLU)            (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_263 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_263 (Ba  (None, 16, 16, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_263 (ReLU)            (None, 16, 16, 128)       0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " max_pooling2d_106 (MaxPooli  (None, 8, 8, 128)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_264 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_264 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_264 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_265 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_265 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_265 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_266 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_266 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_266 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_267 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_267 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_267 (ReLU)            (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_107 (MaxPooli  (None, 4, 4, 256)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_268 (Conv2D)         (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_268 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_268 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_269 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_269 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_269 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_270 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_270 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_270 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_271 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_271 (Ba  (None, 4, 4, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_271 (ReLU)            (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_108 (MaxPooli  (None, 2, 2, 512)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_272 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_272 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_272 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_273 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_273 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_273 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_274 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_274 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_274 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_275 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_275 (Ba  (None, 2, 2, 512)        2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_275 (ReLU)            (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_109 (MaxPooli  (None, 1, 1, 512)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " average_pooling2d_21 (Avera  (None, 1, 1, 512)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,051,530\n",
      "Trainable params: 20,040,522\n",
      "Non-trainable params: 11,008\n",
      "_________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.23670, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 2: val_acc improved from 0.23670 to 0.38490, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 3: val_acc improved from 0.38490 to 0.45910, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 4: val_acc improved from 0.45910 to 0.51790, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 5: val_acc improved from 0.51790 to 0.70100, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 6: val_acc did not improve from 0.70100\n",
      "\n",
      "Epoch 7: val_acc improved from 0.70100 to 0.77680, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 8: val_acc did not improve from 0.77680\n",
      "\n",
      "Epoch 9: val_acc improved from 0.77680 to 0.78480, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 10: val_acc improved from 0.78480 to 0.78960, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 11: val_acc improved from 0.78960 to 0.79760, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 12: val_acc improved from 0.79760 to 0.82170, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 13: val_acc did not improve from 0.82170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: val_acc did not improve from 0.82170\n",
      "\n",
      "Epoch 15: val_acc improved from 0.82170 to 0.84520, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 16: val_acc improved from 0.84520 to 0.85560, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 17: val_acc did not improve from 0.85560\n",
      "\n",
      "Epoch 18: val_acc did not improve from 0.85560\n",
      "\n",
      "Epoch 19: val_acc improved from 0.85560 to 0.85760, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 20: val_acc improved from 0.85760 to 0.87100, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 21: val_acc did not improve from 0.87100\n",
      "\n",
      "Epoch 22: val_acc did not improve from 0.87100\n",
      "\n",
      "Epoch 23: val_acc improved from 0.87100 to 0.87510, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 24: val_acc improved from 0.87510 to 0.87820, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 25: val_acc did not improve from 0.87820\n",
      "\n",
      "Epoch 26: val_acc improved from 0.87820 to 0.87940, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 27: val_acc did not improve from 0.87940\n",
      "\n",
      "Epoch 28: val_acc did not improve from 0.87940\n",
      "\n",
      "Epoch 29: val_acc did not improve from 0.87940\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.87940\n",
      "\n",
      "Epoch 31: val_acc improved from 0.87940 to 0.88350, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 32: val_acc did not improve from 0.88350\n",
      "\n",
      "Epoch 33: val_acc did not improve from 0.88350\n",
      "\n",
      "Epoch 34: val_acc improved from 0.88350 to 0.88640, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 35: val_acc did not improve from 0.88640\n",
      "\n",
      "Epoch 36: val_acc did not improve from 0.88640\n",
      "\n",
      "Epoch 37: val_acc did not improve from 0.88640\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.88640\n",
      "\n",
      "Epoch 39: val_acc did not improve from 0.88640\n",
      "\n",
      "Epoch 40: val_acc did not improve from 0.88640\n",
      "\n",
      "Epoch 41: val_acc did not improve from 0.88640\n",
      "\n",
      "Epoch 42: val_acc did not improve from 0.88640\n",
      "\n",
      "Epoch 43: val_acc improved from 0.88640 to 0.88840, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 44: val_acc did not improve from 0.88840\n",
      "\n",
      "Epoch 45: val_acc improved from 0.88840 to 0.89500, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 46: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 47: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 48: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 49: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 50: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 51: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 52: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 53: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 54: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 55: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 56: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 57: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 58: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 59: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 60: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 61: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 62: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 63: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 64: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 65: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 66: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 67: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 68: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 69: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 70: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 71: val_acc did not improve from 0.89500\n",
      "\n",
      "Epoch 72: val_acc improved from 0.89500 to 0.89620, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 73: val_acc did not improve from 0.89620\n",
      "\n",
      "Epoch 74: val_acc improved from 0.89620 to 0.89740, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 75: val_acc did not improve from 0.89740\n",
      "\n",
      "Epoch 76: val_acc did not improve from 0.89740\n",
      "\n",
      "Epoch 77: val_acc did not improve from 0.89740\n",
      "\n",
      "Epoch 78: val_acc did not improve from 0.89740\n",
      "\n",
      "Epoch 79: val_acc did not improve from 0.89740\n",
      "\n",
      "Epoch 80: val_acc did not improve from 0.89740\n",
      "\n",
      "Epoch 81: val_acc did not improve from 0.89740\n",
      "\n",
      "Epoch 82: val_acc improved from 0.89740 to 0.90550, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 83: val_acc improved from 0.90550 to 0.90870, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 84: val_acc did not improve from 0.90870\n",
      "\n",
      "Epoch 85: val_acc improved from 0.90870 to 0.91180, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 86: val_acc did not improve from 0.91180\n",
      "\n",
      "Epoch 87: val_acc did not improve from 0.91180\n",
      "\n",
      "Epoch 88: val_acc improved from 0.91180 to 0.91360, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 89: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 90: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 91: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 92: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 93: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 94: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 95: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 96: val_acc improved from 0.91360 to 0.91370, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 97: val_acc did not improve from 0.91370\n",
      "\n",
      "Epoch 98: val_acc improved from 0.91370 to 0.91380, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 99: val_acc did not improve from 0.91380\n",
      "\n",
      "Epoch 100: val_acc did not improve from 0.91380\n",
      "\n",
      "Epoch 101: val_acc did not improve from 0.91380\n",
      "\n",
      "Epoch 102: val_acc did not improve from 0.91380\n",
      "\n",
      "Epoch 103: val_acc improved from 0.91380 to 0.91430, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 104: val_acc did not improve from 0.91430\n",
      "\n",
      "Epoch 105: val_acc improved from 0.91430 to 0.91470, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 106: val_acc did not improve from 0.91470\n",
      "\n",
      "Epoch 107: val_acc improved from 0.91470 to 0.91530, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 108: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 109: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 110: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 111: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 112: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 113: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 114: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 115: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 116: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 117: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 118: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 119: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 120: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 121: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 122: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 123: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 124: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 125: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 126: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 127: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 128: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 129: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 130: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 131: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 132: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 133: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 134: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 135: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 136: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 137: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 138: val_acc did not improve from 0.91530\n",
      "\n",
      "Epoch 139: val_acc improved from 0.91530 to 0.91560, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 140: val_acc did not improve from 0.91560\n",
      "\n",
      "Epoch 141: val_acc did not improve from 0.91560\n",
      "\n",
      "Epoch 142: val_acc did not improve from 0.91560\n",
      "\n",
      "Epoch 143: val_acc did not improve from 0.91560\n",
      "\n",
      "Epoch 144: val_acc did not improve from 0.91560\n",
      "\n",
      "Epoch 145: val_acc did not improve from 0.91560\n",
      "\n",
      "Epoch 146: val_acc did not improve from 0.91560\n",
      "\n",
      "Epoch 147: val_acc did not improve from 0.91560\n",
      "\n",
      "Epoch 148: val_acc did not improve from 0.91560\n",
      "\n",
      "Epoch 149: val_acc improved from 0.91560 to 0.91610, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 150: val_acc did not improve from 0.91610\n",
      "\n",
      "Epoch 151: val_acc did not improve from 0.91610\n",
      "\n",
      "Epoch 152: val_acc did not improve from 0.91610\n",
      "\n",
      "Epoch 153: val_acc did not improve from 0.91610\n",
      "\n",
      "Epoch 154: val_acc did not improve from 0.91610\n",
      "\n",
      "Epoch 155: val_acc did not improve from 0.91610\n",
      "\n",
      "Epoch 156: val_acc improved from 0.91610 to 0.91640, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 157: val_acc did not improve from 0.91640\n",
      "\n",
      "Epoch 158: val_acc did not improve from 0.91640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 159: val_acc did not improve from 0.91640\n",
      "\n",
      "Epoch 160: val_acc improved from 0.91640 to 0.91700, saving model to models/CIFAR10_vgg19.keras\n",
      "\n",
      "Epoch 161: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 162: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 163: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 164: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 165: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 166: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 167: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 168: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 169: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 170: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 171: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 172: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 173: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 174: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 175: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 176: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 177: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 178: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 179: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 180: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 181: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 182: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 183: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 184: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 185: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 186: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 187: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 188: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 189: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 190: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 191: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 192: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 193: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 194: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 195: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 196: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 197: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 198: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 199: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 200: val_acc did not improve from 0.91700\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1323"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg = trainer('models/CIFAR10_vgg11.keras',x_train,y_train,x_val,y_val,'vgg11',10)\n",
    "vgg.model.summary()\n",
    "vgg.train(save_best_only=True,save_weights_only = False)\n",
    "model = load_model('models/CIFAR10_vgg11.keras')\n",
    "np.sum(np.argmax(model.predict(x_test),axis=-1) == np.argmax(y_test),axis=-1)/10000\n",
    "vgg = trainer('models/CIFAR10_vgg13.keras',x_train,y_train,x_val,y_val,'vgg13',10)\n",
    "vgg.model.summary()\n",
    "vgg.train(save_best_only=True,save_weights_only = False)\n",
    "model = load_model('models/CIFAR10_vgg13.keras')\n",
    "np.sum(np.argmax(model.predict(x_test),axis=-1) == np.argmax(y_test),axis=-1)/10000\n",
    "vgg = trainer('models/CIFAR10_vgg16.keras',x_train,y_train,x_val,y_val,'vgg16',10)\n",
    "vgg.model.summary()\n",
    "vgg.train(save_best_only=True,save_weights_only = False)\n",
    "model = load_model('models/CIFAR10_vgg16.keras')\n",
    "np.sum(np.argmax(model.predict(x_test),axis=-1) == np.argmax(y_test),axis=-1)/10000\n",
    "vgg = trainer('models/CIFAR10_vgg19.keras',x_train,y_train,x_val,y_val,'vgg19',10)\n",
    "vgg.model.summary()\n",
    "vgg.train(save_best_only=True,save_weights_only = False)\n",
    "model = load_model('models/CIFAR10_vgg19.keras')\n",
    "np.sum(np.argmax(model.predict(x_test),axis=-1) == np.argmax(y_test),axis=-1)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "659c667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 966us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7871"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('models/CIFAR10_vgg11.keras')\n",
    "np.sum(np.argmax(model.predict(x_test),axis=-1) == np.argmax(y_test,axis=-1))/10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10413a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8661"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('models/CIFAR10_vgg13.keras')\n",
    "np.sum(np.argmax(model.predict(x_test),axis=-1) == np.argmax(y_test,axis=-1))/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97442ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8599"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('models/CIFAR10_vgg16.keras')\n",
    "np.sum(np.argmax(model.predict(x_test),axis=-1) == np.argmax(y_test,axis=-1))/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1336dee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8577"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('models/CIFAR10_vgg19.keras')\n",
    "np.sum(np.argmax(model.predict(x_test),axis=-1) == np.argmax(y_test,axis=-1))/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8460e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4732bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/projectnb/nonarch/adversarial_experiment/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0beb35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleverhans\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input\n",
    "from tensorflow.keras.layers import Flatten, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4530f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_experiment_path = '/projectnb/nonarch/adversarial_experiment/'\n",
    "adv_example_path = adv_experiment_path + 'adversarial_examples/gen_by_vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe2284f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a3192a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 38ms/step\n",
      "epsilon = 0.3764705882352941\n",
      "0 - 2500 2500 - 5000 5000 - 7500 7500 - 10000 10000 - 12500 12500 - 15000 15000 - 17500 17500 - 20000 20000 - 22500 22500 - 25000 25000 - 27500 27500 - 30000 30000 - 32500 32500 - 35000 35000 - 37500 37500 - 40000 advs_x shape: (40000, 32, 32, 3)\n",
      "saved to adversarial_examples with file name \"pgd_0.376_x_target_to_ll.npy\" \n"
     ]
    }
   ],
   "source": [
    "GENmodel = load_model('models/CIFAR10_vgg16.keras') \n",
    "cifar10_dataset = cifar10.load_data()\n",
    "training, test = cifar10_dataset\n",
    "x_tr, x_v, y_tr, y_v = train_test_split(training[0], training[1], test_size=0.2, random_state=42)\n",
    "x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)\n",
    "x_v = x_v.reshape(x_v.shape[0],32,32,3)\n",
    "x_v = x_v.astype('float32')\n",
    "x_tr = x_tr.astype('float32')\n",
    "x_v /= 255\n",
    "x_tr /= 255\n",
    "y_tr = keras.utils.to_categorical(y_tr, 10)\n",
    "y_v = keras.utils.to_categorical(y_v,10)\n",
    "x_test, y_test = test\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255 \n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "from cleverhans.tf2.attacks import projected_gradient_descent as pgd\n",
    "\n",
    "eps = 216/255 # value ranges between 0 - 255. \n",
    "nb_iter = 8\n",
    "norm = 2\n",
    "targeted = False\n",
    "eps_iter = 96/255\n",
    "advs_x =[]\n",
    "advs_y =[]\n",
    "label = np.round(eps_iter,3)\n",
    "for i in range(16):\n",
    "    print(f'{2500*i} - {2500*(i+1)}', end = ' ')\n",
    "    adv = pgd.projected_gradient_descent(GENmodel, x_tr[2500*i:2500*(i+1)],eps,eps_iter,nb_iter,norm,y=tf.argmax(y_tr[2500*i:2500*(i+1)],1))\n",
    "    advs_x.append(adv) \n",
    "advs_x = np.concatenate(advs_x, axis=0)\n",
    "print(f\"advs_x shape: {advs_x.shape}\")\n",
    "np.save(f'{adv_example_path}/pgd_{label}_x_untarget.npy', advs_x)\n",
    "print(f'saved to adversarial_examples with file name \"pgd_{label}_x_untarget.npy\" ')\n",
    "    \n",
    "logits = GENmodel.predict(x_tr, batch_size=2000)\n",
    "least_likely = tf.argmin(logits,axis=-1)\n",
    "\n",
    "# Targetted\n",
    "\n",
    "eps = 216/255 # value ranges between 0 - 255. allow to perturbe 216 at most.\n",
    "# eps_iters = [3/255,9/255,27/255,48/255,96/255]\n",
    "eps_iter = 96/255\n",
    "nb_iter = 8\n",
    "norm = 2\n",
    "targeted = True\n",
    "\n",
    "y= least_likely\n",
    "eps_iter = 96/255\n",
    "advs_x =[]\n",
    "advs_y =[]\n",
    "label = np.round(eps_iter,3)\n",
    "print(f'epsilon = {eps_iter}')\n",
    "for i in range(16):\n",
    "    print(f'{2500*i} - {2500*(i+1)}', end = ' ')\n",
    "    adv = pgd.projected_gradient_descent(GENmodel,x_tr[2500*i:2500*(i+1)],eps,eps_iter,nb_iter,norm,y=y[2500*i:2500*(i+1)],targeted=targeted)\n",
    "    advs_x.append(adv) \n",
    "advs_x = np.concatenate(advs_x, axis=0)\n",
    "print(f\"advs_x shape: {advs_x.shape}\")\n",
    "np.save(f'{adv_example_path}/pgd_{label}_x_target_to_ll.npy', advs_x)\n",
    "print(f'saved to adversarial_examples with file name \"pgd_{label}_x_target_to_ll.npy\" ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d065500",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_v, y_tr, y_v = train_test_split(training[0], training[1], test_size=0.2, random_state=42)\n",
    "x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)\n",
    "x_v = x_v.reshape(x_v.shape[0],32,32,3)\n",
    "x_v = x_v.astype('float32')\n",
    "x_tr = x_tr.astype('float32')\n",
    "x_v /= 255\n",
    "x_tr /= 255\n",
    "# y_tr = keras.utils.to_categorical(y_tr, 10)\n",
    "# y_v = keras.utils.to_categorical(y_v,10)\n",
    "x_test, y_test = test\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255 \n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "adv_x_tr = np.load(f\"{adv_experiment_path}adversarial_examples/pgd_0.376_x_untarget.npy\")\n",
    "adv_x_val = np.load(f\"{adv_experiment_path}adversarial_examples/pgd_0.376_x_val_untarget.npy\")\n",
    "# print(f'{adversarial_direction} adversarial dataset has been loaded.')\n",
    "path = f'adversarial_models/untargeted_trained_20targets_vgg16.keras'\n",
    "training_x = np.concatenate([x_tr,adv_x_tr],axis=0)\n",
    "validating_x = np.concatenate([x_v,adv_x_val],axis=0)\n",
    "training_y_long=np.concatenate([y_tr,y_tr+10],axis=0)\n",
    "training_y_long = keras.utils.to_categorical(training_y_long,20)\n",
    "validating_y_long=np.concatenate([y_v,y_v+10],axis=0)\n",
    "validating_y_long = keras.utils.to_categorical(validating_y_long,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7775340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72489fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_26 (ReLU)             (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_27 (ReLU)             (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_28 (ReLU)             (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_29 (ReLU)             (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_30 (ReLU)             (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_31 (ReLU)             (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_32 (ReLU)             (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_33 (ReLU)             (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_34 (ReLU)             (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_35 (ReLU)             (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 2, 2, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_36 (ReLU)             (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_37 (ReLU)             (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_38 (ReLU)             (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 1, 1, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 1, 1, 512)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,741,844\n",
      "Trainable params: 14,733,396\n",
      "Non-trainable params: 8,448\n",
      "_________________________________________________________________\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.30205, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 2: val_acc improved from 0.30205 to 0.33130, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 3: val_acc improved from 0.33130 to 0.38780, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 4: val_acc improved from 0.38780 to 0.38945, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 5: val_acc did not improve from 0.38945\n",
      "\n",
      "Epoch 6: val_acc improved from 0.38945 to 0.42815, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 7: val_acc improved from 0.42815 to 0.43665, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 8: val_acc improved from 0.43665 to 0.45095, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 9: val_acc improved from 0.45095 to 0.77980, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 10: val_acc improved from 0.77980 to 0.83215, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 11: val_acc did not improve from 0.83215\n",
      "\n",
      "Epoch 12: val_acc did not improve from 0.83215\n",
      "\n",
      "Epoch 13: val_acc did not improve from 0.83215\n",
      "\n",
      "Epoch 14: val_acc did not improve from 0.83215\n",
      "\n",
      "Epoch 15: val_acc did not improve from 0.83215\n",
      "\n",
      "Epoch 16: val_acc improved from 0.83215 to 0.85815, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 17: val_acc improved from 0.85815 to 0.86160, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 18: val_acc did not improve from 0.86160\n",
      "\n",
      "Epoch 19: val_acc did not improve from 0.86160\n",
      "\n",
      "Epoch 20: val_acc improved from 0.86160 to 0.86755, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 21: val_acc did not improve from 0.86755\n",
      "\n",
      "Epoch 22: val_acc did not improve from 0.86755\n",
      "\n",
      "Epoch 23: val_acc improved from 0.86755 to 0.87470, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 24: val_acc did not improve from 0.87470\n",
      "\n",
      "Epoch 25: val_acc did not improve from 0.87470\n",
      "\n",
      "Epoch 26: val_acc did not improve from 0.87470\n",
      "\n",
      "Epoch 27: val_acc improved from 0.87470 to 0.87720, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 28: val_acc did not improve from 0.87720\n",
      "\n",
      "Epoch 29: val_acc improved from 0.87720 to 0.88085, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.88085\n",
      "\n",
      "Epoch 31: val_acc did not improve from 0.88085\n",
      "\n",
      "Epoch 32: val_acc did not improve from 0.88085\n",
      "\n",
      "Epoch 33: val_acc did not improve from 0.88085\n",
      "\n",
      "Epoch 34: val_acc did not improve from 0.88085\n",
      "\n",
      "Epoch 35: val_acc did not improve from 0.88085\n",
      "\n",
      "Epoch 36: val_acc did not improve from 0.88085\n",
      "\n",
      "Epoch 37: val_acc did not improve from 0.88085\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.88085\n",
      "\n",
      "Epoch 39: val_acc did not improve from 0.88085\n",
      "\n",
      "Epoch 40: val_acc improved from 0.88085 to 0.88570, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 41: val_acc did not improve from 0.88570\n",
      "\n",
      "Epoch 42: val_acc did not improve from 0.88570\n",
      "\n",
      "Epoch 43: val_acc did not improve from 0.88570\n",
      "\n",
      "Epoch 44: val_acc did not improve from 0.88570\n",
      "\n",
      "Epoch 45: val_acc did not improve from 0.88570\n",
      "\n",
      "Epoch 46: val_acc did not improve from 0.88570\n",
      "\n",
      "Epoch 47: val_acc improved from 0.88570 to 0.88940, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 48: val_acc did not improve from 0.88940\n",
      "\n",
      "Epoch 49: val_acc did not improve from 0.88940\n",
      "\n",
      "Epoch 50: val_acc improved from 0.88940 to 0.89710, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 51: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 52: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 53: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 54: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 55: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 56: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 57: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 58: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 59: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 60: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 61: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 62: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 63: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 64: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 65: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 66: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 67: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 68: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 69: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 70: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 71: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 72: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 73: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 74: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 75: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 76: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 77: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 78: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 79: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 80: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 81: val_acc did not improve from 0.89710\n",
      "\n",
      "Epoch 82: val_acc improved from 0.89710 to 0.90440, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 83: val_acc improved from 0.90440 to 0.90750, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 84: val_acc improved from 0.90750 to 0.90820, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 85: val_acc improved from 0.90820 to 0.90890, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 86: val_acc improved from 0.90890 to 0.90945, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 87: val_acc did not improve from 0.90945\n",
      "\n",
      "Epoch 88: val_acc improved from 0.90945 to 0.91030, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 89: val_acc improved from 0.91030 to 0.91040, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 90: val_acc did not improve from 0.91040\n",
      "\n",
      "Epoch 91: val_acc did not improve from 0.91040\n",
      "\n",
      "Epoch 92: val_acc did not improve from 0.91040\n",
      "\n",
      "Epoch 93: val_acc did not improve from 0.91040\n",
      "\n",
      "Epoch 94: val_acc did not improve from 0.91040\n",
      "\n",
      "Epoch 95: val_acc improved from 0.91040 to 0.91050, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 96: val_acc did not improve from 0.91050\n",
      "\n",
      "Epoch 97: val_acc did not improve from 0.91050\n",
      "\n",
      "Epoch 98: val_acc did not improve from 0.91050\n",
      "\n",
      "Epoch 99: val_acc did not improve from 0.91050\n",
      "\n",
      "Epoch 100: val_acc did not improve from 0.91050\n",
      "\n",
      "Epoch 101: val_acc improved from 0.91050 to 0.91190, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 102: val_acc did not improve from 0.91190\n",
      "\n",
      "Epoch 103: val_acc improved from 0.91190 to 0.91205, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 104: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 105: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 106: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 107: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 108: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 109: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 110: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 111: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 112: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 113: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 114: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 115: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 116: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 117: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 118: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 119: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 120: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 121: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 122: val_acc did not improve from 0.91205\n",
      "\n",
      "Epoch 123: val_acc improved from 0.91205 to 0.91280, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 124: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 125: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 126: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 127: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 128: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 129: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 130: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 131: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 132: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 133: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 134: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 135: val_acc did not improve from 0.91280\n",
      "\n",
      "Epoch 136: val_acc improved from 0.91280 to 0.91310, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 137: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 138: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 139: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 140: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 141: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 142: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 143: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 144: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 145: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 146: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 147: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 148: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 149: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 150: val_acc did not improve from 0.91310\n",
      "\n",
      "Epoch 151: val_acc improved from 0.91310 to 0.91325, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 152: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 153: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 154: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 155: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 156: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 157: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 158: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 159: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 160: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 161: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 162: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 163: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 164: val_acc did not improve from 0.91325\n",
      "\n",
      "Epoch 165: val_acc improved from 0.91325 to 0.91345, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 166: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 167: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 168: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 169: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 170: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 171: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 172: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 173: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 174: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 175: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 176: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 177: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 178: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 179: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 180: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 181: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 182: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 183: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 184: val_acc did not improve from 0.91345\n",
      "\n",
      "Epoch 185: val_acc improved from 0.91345 to 0.91355, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 186: val_acc did not improve from 0.91355\n",
      "\n",
      "Epoch 187: val_acc did not improve from 0.91355\n",
      "\n",
      "Epoch 188: val_acc did not improve from 0.91355\n",
      "\n",
      "Epoch 189: val_acc did not improve from 0.91355\n",
      "\n",
      "Epoch 190: val_acc did not improve from 0.91355\n",
      "\n",
      "Epoch 191: val_acc did not improve from 0.91355\n",
      "\n",
      "Epoch 192: val_acc improved from 0.91355 to 0.91360, saving model to adversarial_models/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 193: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 194: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 195: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 196: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 197: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 198: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 199: val_acc did not improve from 0.91360\n",
      "\n",
      "Epoch 200: val_acc did not improve from 0.91360\n"
     ]
    }
   ],
   "source": [
    "vgg = trainer(path,training_x,training_y_long,validating_x,validating_y_long,'vgg16',20)\n",
    "vgg.model.summary()\n",
    "vgg.train(save_best_only=True,save_weights_only = False)\n",
    "model = load_model(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6c346c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 2500 2500 - 5000 5000 - 7500 7500 - 10000 advs_x_v shape: (10000, 32, 32, 3)\n",
      "saved to adversarial_examples with file name \"pgd_0.376_x_val_untarget.npy\" \n",
      "5/5 [==============================] - 0s 39ms/step\n",
      "epsilon = 0.3764705882352941\n",
      "0 - 2500 2500 - 5000 5000 - 7500 7500 - 10000 advs_x_v shape: (10000, 32, 32, 3)\n",
      "saved to adversarial_examples with file name \"pgd_0.376_x_val_target_to_ll.npy\" \n",
      "0 - 2500 2500 - 5000 5000 - 7500 7500 - 10000 advs_x_test shape: (10000, 32, 32, 3)\n",
      "saved to adversarial_examples with file name \"pgd_0.376_x_test_untarget.npy\" \n",
      "5/5 [==============================] - 0s 39ms/step\n",
      "epsilon = 0.3764705882352941\n",
      "0 - 2500 2500 - 5000 5000 - 7500 7500 - 10000 advs_x_test shape: (10000, 32, 32, 3)\n",
      "saved to adversarial_examples with file name \"pgd_0.376_x_test_target_to_ll.npy\" \n"
     ]
    }
   ],
   "source": [
    "GENmodel = load_model('models/CIFAR10_vgg16.keras') \n",
    "cifar10_dataset = cifar10.load_data()\n",
    "training, test = cifar10_dataset\n",
    "x_tr, x_v, y_tr, y_v = train_test_split(training[0], training[1], test_size=0.2, random_state=42)\n",
    "x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)\n",
    "x_v = x_v.reshape(x_v.shape[0],32,32,3)\n",
    "x_v = x_v.astype('float32')\n",
    "x_tr = x_tr.astype('float32')\n",
    "x_v /= 255\n",
    "x_tr /= 255\n",
    "y_tr = keras.utils.to_categorical(y_tr, 10)\n",
    "y_v = keras.utils.to_categorical(y_v,10)\n",
    "x_test, y_test = test\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255 \n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "from cleverhans.tf2.attacks import projected_gradient_descent as pgd\n",
    "\n",
    "eps = 216/255 # value ranges between 0 - 255. \n",
    "nb_iter = 8\n",
    "norm = 2\n",
    "targeted = False\n",
    "eps_iter = 96/255\n",
    "advs_x =[]\n",
    "advs_y =[]\n",
    "label = np.round(eps_iter,3)\n",
    "for i in range(4):\n",
    "    print(f'{2500*i} - {2500*(i+1)}', end = ' ')\n",
    "    adv = pgd.projected_gradient_descent(GENmodel, x_v[2500*i:2500*(i+1)],eps,eps_iter,nb_iter,norm,y=tf.argmax(y_tr[2500*i:2500*(i+1)],1))\n",
    "    advs_x.append(adv) \n",
    "advs_x = np.concatenate(advs_x, axis=0)\n",
    "print(f\"advs_x_v shape: {advs_x.shape}\")\n",
    "np.save(f'{adv_example_path}/pgd_{label}_x_val_untarget.npy', advs_x)\n",
    "print(f'saved to adversarial_examples with file name \"pgd_{label}_x_val_untarget.npy\" ')\n",
    "    \n",
    "logits = GENmodel.predict(x_v, batch_size=2000)\n",
    "least_likely = tf.argmin(logits,axis=-1)\n",
    "\n",
    "# Targetted\n",
    "\n",
    "eps = 216/255 # value ranges between 0 - 255. allow to perturbe 216 at most.\n",
    "# eps_iters = [3/255,9/255,27/255,48/255,96/255]\n",
    "eps_iter = 96/255\n",
    "nb_iter = 8\n",
    "norm = 2\n",
    "targeted = True\n",
    "\n",
    "y= least_likely\n",
    "eps_iter = 96/255\n",
    "advs_x =[]\n",
    "advs_y =[]\n",
    "label = np.round(eps_iter,3)\n",
    "print(f'epsilon = {eps_iter}')\n",
    "for i in range(4):\n",
    "    print(f'{2500*i} - {2500*(i+1)}', end = ' ')\n",
    "    adv = pgd.projected_gradient_descent(GENmodel,x_v[2500*i:2500*(i+1)],eps,eps_iter,nb_iter,norm,y=y[2500*i:2500*(i+1)],targeted=targeted)\n",
    "    advs_x.append(adv) \n",
    "advs_x = np.concatenate(advs_x, axis=0)\n",
    "print(f\"advs_x_v shape: {advs_x.shape}\")\n",
    "np.save(f'{adv_example_path}/pgd_{label}_x_val_target_to_ll.npy', advs_x)\n",
    "print(f'saved to adversarial_examples with file name \"pgd_{label}_x_val_target_to_ll.npy\" ')\n",
    "\n",
    "\n",
    "eps = 216/255 # value ranges between 0 - 255. \n",
    "nb_iter = 8\n",
    "norm = 2\n",
    "targeted = False\n",
    "eps_iter = 96/255\n",
    "advs_x =[]\n",
    "advs_y =[]\n",
    "label = np.round(eps_iter,3)\n",
    "for i in range(4):\n",
    "    print(f'{2500*i} - {2500*(i+1)}', end = ' ')\n",
    "    adv = pgd.projected_gradient_descent(GENmodel, x_test[2500*i:2500*(i+1)],eps,eps_iter,nb_iter,norm,y=tf.argmax(y_tr[2500*i:2500*(i+1)],1))\n",
    "    advs_x.append(adv) \n",
    "advs_x = np.concatenate(advs_x, axis=0)\n",
    "print(f\"advs_x_test shape: {advs_x.shape}\")\n",
    "np.save(f'{adv_example_path}/pgd_{label}_x_test_untarget.npy', advs_x)\n",
    "print(f'saved to adversarial_examples with file name \"pgd_{label}_x_test_untarget.npy\" ')\n",
    "    \n",
    "logits = GENmodel.predict(x_test, batch_size=2000)\n",
    "least_likely = tf.argmin(logits,axis=-1)\n",
    "\n",
    "# Targetted\n",
    "\n",
    "eps = 216/255 # value ranges between 0 - 255. allow to perturbe 216 at most.\n",
    "# eps_iters = [3/255,9/255,27/255,48/255,96/255]\n",
    "eps_iter = 96/255\n",
    "nb_iter = 8\n",
    "norm = 2\n",
    "targeted = True\n",
    "\n",
    "y= least_likely\n",
    "eps_iter = 96/255\n",
    "advs_x =[]\n",
    "advs_y =[]\n",
    "label = np.round(eps_iter,3)\n",
    "print(f'epsilon = {eps_iter}')\n",
    "for i in range(4):\n",
    "    print(f'{2500*i} - {2500*(i+1)}', end = ' ')\n",
    "    adv = pgd.projected_gradient_descent(GENmodel,x_test[2500*i:2500*(i+1)],eps,eps_iter,nb_iter,norm,y=y[2500*i:2500*(i+1)],targeted=targeted)\n",
    "    advs_x.append(adv) \n",
    "advs_x = np.concatenate(advs_x, axis=0)\n",
    "print(f\"advs_x_test shape: {advs_x.shape}\")\n",
    "np.save(f'{adv_example_path}/pgd_{label}_x_test_target_to_ll.npy', advs_x)\n",
    "print(f'saved to adversarial_examples with file name \"pgd_{label}_x_test_target_to_ll.npy\" ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56688ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_experiment_path = '/projectnb/nonarch/adversarial_experiment/'\n",
    "# adv_example_path = adv_experiment_path + 'adversarial_examples/gen_by_vgg16'\n",
    "\n",
    "x_tr, x_v, y_tr, y_v = train_test_split(training[0], training[1], test_size=0.2, random_state=42)\n",
    "x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)\n",
    "x_v = x_v.reshape(x_v.shape[0],32,32,3)\n",
    "x_v = x_v.astype('float32')\n",
    "x_tr = x_tr.astype('float32')\n",
    "x_v /= 255\n",
    "x_tr /= 255\n",
    "# y_tr = keras.utils.to_categorical(y_tr, 10)\n",
    "# y_v = keras.utils.to_categorical(y_v,10)\n",
    "x_test, y_test = test\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255 \n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "adv_x_tr = np.load(f\"{adv_example_path}/pgd_0.376_x_untarget.npy\")\n",
    "adv_x_val = np.load(f\"{adv_example_path}/pgd_0.376_x_val_untarget.npy\")\n",
    "# print(f'{adversarial_direction} adversarial dataset has been loaded.')\n",
    "path = f'adversarial_models/untargeted_trained_20targets_vgg16.keras'\n",
    "training_x = np.concatenate([x_tr,adv_x_tr],axis=0)\n",
    "validating_x = np.concatenate([x_v,adv_x_val],axis=0)\n",
    "training_y_long=np.concatenate([y_tr,y_tr+10],axis=0)\n",
    "training_y_long = keras.utils.to_categorical(training_y_long,20)\n",
    "validating_y_long=np.concatenate([y_v,y_v+10],axis=0)\n",
    "validating_y_long = keras.utils.to_categorical(validating_y_long,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "accddfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = f'{adv_experiment_path}adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b95e28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_39 (ReLU)             (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_40 (ReLU)             (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_41 (ReLU)             (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_42 (ReLU)             (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_43 (ReLU)             (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_44 (ReLU)             (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_45 (ReLU)             (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_46 (ReLU)             (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_47 (ReLU)             (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_48 (ReLU)             (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 2, 2, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_49 (ReLU)             (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_50 (ReLU)             (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_51 (ReLU)             (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 1, 1, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 1, 1, 512)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,741,844\n",
      "Trainable params: 14,733,396\n",
      "Non-trainable params: 8,448\n",
      "_________________________________________________________________\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.29675, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 2: val_acc improved from 0.29675 to 0.31305, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 3: val_acc improved from 0.31305 to 0.35510, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 4: val_acc improved from 0.35510 to 0.37585, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 5: val_acc improved from 0.37585 to 0.38920, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 6: val_acc improved from 0.38920 to 0.40290, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 7: val_acc improved from 0.40290 to 0.41910, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 8: val_acc did not improve from 0.41910\n",
      "\n",
      "Epoch 9: val_acc improved from 0.41910 to 0.44050, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 10: val_acc improved from 0.44050 to 0.47865, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 11: val_acc improved from 0.47865 to 0.64825, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 12: val_acc improved from 0.64825 to 0.69820, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 13: val_acc improved from 0.69820 to 0.71495, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 14: val_acc did not improve from 0.71495\n",
      "\n",
      "Epoch 15: val_acc did not improve from 0.71495\n",
      "\n",
      "Epoch 16: val_acc did not improve from 0.71495\n",
      "\n",
      "Epoch 17: val_acc did not improve from 0.71495\n",
      "\n",
      "Epoch 18: val_acc did not improve from 0.71495\n",
      "\n",
      "Epoch 19: val_acc did not improve from 0.71495\n",
      "\n",
      "Epoch 20: val_acc did not improve from 0.71495\n",
      "\n",
      "Epoch 21: val_acc did not improve from 0.71495\n",
      "\n",
      "Epoch 22: val_acc improved from 0.71495 to 0.72620, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 23: val_acc improved from 0.72620 to 0.74255, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 24: val_acc did not improve from 0.74255\n",
      "\n",
      "Epoch 25: val_acc did not improve from 0.74255\n",
      "\n",
      "Epoch 26: val_acc did not improve from 0.74255\n",
      "\n",
      "Epoch 27: val_acc did not improve from 0.74255\n",
      "\n",
      "Epoch 28: val_acc improved from 0.74255 to 0.74380, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 29: val_acc did not improve from 0.74380\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.74380\n",
      "\n",
      "Epoch 31: val_acc did not improve from 0.74380\n",
      "\n",
      "Epoch 32: val_acc did not improve from 0.74380\n",
      "\n",
      "Epoch 33: val_acc did not improve from 0.74380\n",
      "\n",
      "Epoch 34: val_acc improved from 0.74380 to 0.75315, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 35: val_acc did not improve from 0.75315\n",
      "\n",
      "Epoch 36: val_acc did not improve from 0.75315\n",
      "\n",
      "Epoch 37: val_acc did not improve from 0.75315\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.75315\n",
      "\n",
      "Epoch 39: val_acc improved from 0.75315 to 0.75340, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 40: val_acc improved from 0.75340 to 0.75810, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 41: val_acc improved from 0.75810 to 0.76580, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 42: val_acc did not improve from 0.76580\n",
      "\n",
      "Epoch 43: val_acc did not improve from 0.76580\n",
      "\n",
      "Epoch 44: val_acc did not improve from 0.76580\n",
      "\n",
      "Epoch 45: val_acc did not improve from 0.76580\n",
      "\n",
      "Epoch 46: val_acc did not improve from 0.76580\n",
      "\n",
      "Epoch 47: val_acc did not improve from 0.76580\n",
      "\n",
      "Epoch 48: val_acc did not improve from 0.76580\n",
      "\n",
      "Epoch 49: val_acc improved from 0.76580 to 0.76890, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 50: val_acc did not improve from 0.76890\n",
      "\n",
      "Epoch 51: val_acc did not improve from 0.76890\n",
      "\n",
      "Epoch 52: val_acc did not improve from 0.76890\n",
      "\n",
      "Epoch 53: val_acc did not improve from 0.76890\n",
      "\n",
      "Epoch 54: val_acc did not improve from 0.76890\n",
      "\n",
      "Epoch 55: val_acc did not improve from 0.76890\n",
      "\n",
      "Epoch 56: val_acc improved from 0.76890 to 0.76990, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 57: val_acc improved from 0.76990 to 0.77000, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 58: val_acc did not improve from 0.77000\n",
      "\n",
      "Epoch 59: val_acc did not improve from 0.77000\n",
      "\n",
      "Epoch 60: val_acc did not improve from 0.77000\n",
      "\n",
      "Epoch 61: val_acc improved from 0.77000 to 0.77270, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 62: val_acc did not improve from 0.77270\n",
      "\n",
      "Epoch 63: val_acc did not improve from 0.77270\n",
      "\n",
      "Epoch 64: val_acc improved from 0.77270 to 0.77545, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 65: val_acc improved from 0.77545 to 0.77970, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 66: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 67: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 68: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 69: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 70: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 71: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 72: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 73: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 74: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 75: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 76: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 77: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 78: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 79: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 80: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 81: val_acc did not improve from 0.77970\n",
      "\n",
      "Epoch 82: val_acc improved from 0.77970 to 0.78250, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 83: val_acc improved from 0.78250 to 0.79240, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 84: val_acc did not improve from 0.79240\n",
      "\n",
      "Epoch 85: val_acc did not improve from 0.79240\n",
      "\n",
      "Epoch 86: val_acc improved from 0.79240 to 0.79625, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 87: val_acc improved from 0.79625 to 0.79750, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 88: val_acc did not improve from 0.79750\n",
      "\n",
      "Epoch 89: val_acc did not improve from 0.79750\n",
      "\n",
      "Epoch 90: val_acc did not improve from 0.79750\n",
      "\n",
      "Epoch 91: val_acc did not improve from 0.79750\n",
      "\n",
      "Epoch 92: val_acc did not improve from 0.79750\n",
      "\n",
      "Epoch 93: val_acc did not improve from 0.79750\n",
      "\n",
      "Epoch 94: val_acc improved from 0.79750 to 0.80120, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 95: val_acc did not improve from 0.80120\n",
      "\n",
      "Epoch 96: val_acc did not improve from 0.80120\n",
      "\n",
      "Epoch 97: val_acc improved from 0.80120 to 0.80395, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 98: val_acc did not improve from 0.80395\n",
      "\n",
      "Epoch 99: val_acc did not improve from 0.80395\n",
      "\n",
      "Epoch 100: val_acc did not improve from 0.80395\n",
      "\n",
      "Epoch 101: val_acc did not improve from 0.80395\n",
      "\n",
      "Epoch 102: val_acc did not improve from 0.80395\n",
      "\n",
      "Epoch 103: val_acc did not improve from 0.80395\n",
      "\n",
      "Epoch 104: val_acc did not improve from 0.80395\n",
      "\n",
      "Epoch 105: val_acc did not improve from 0.80395\n",
      "\n",
      "Epoch 106: val_acc improved from 0.80395 to 0.80745, saving model to /projectnb/nonarch/adversarial_experiment/adversarial_models/vgg/untargeted_trained_20targets_vgg16.keras\n",
      "\n",
      "Epoch 107: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 108: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 109: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 110: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 111: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 112: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 113: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 114: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 115: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 116: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 117: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 118: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 119: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 120: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 121: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 122: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 123: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 124: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 125: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 126: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 127: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 128: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 129: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 130: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 131: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 132: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 133: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 134: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 135: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 136: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 137: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 138: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 139: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 140: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 141: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 142: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 143: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 144: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 145: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 146: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 147: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 148: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 149: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 150: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 151: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 152: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 153: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 154: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 155: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 156: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 157: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 158: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 159: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 160: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 161: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 162: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 163: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 164: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 165: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 166: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 167: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 168: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 169: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 170: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 171: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 172: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 173: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 174: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 175: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 176: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 177: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 178: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 179: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 180: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 181: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 182: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 183: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 184: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 185: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 186: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 187: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 188: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 189: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 190: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 191: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 192: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 193: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 194: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 195: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 196: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 197: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 198: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 199: val_acc did not improve from 0.80745\n",
      "\n",
      "Epoch 200: val_acc did not improve from 0.80745\n"
     ]
    }
   ],
   "source": [
    "vgg = trainer(path,training_x,training_y_long,validating_x,validating_y_long,'vgg16',20)\n",
    "vgg.model.summary()\n",
    "vgg.train(save_best_only=True,save_weights_only = False)\n",
    "model = load_model(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3efcd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
