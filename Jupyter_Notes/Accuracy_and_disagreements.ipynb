{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f149343",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "In this note, I'll do the following experiment.\n",
    "\n",
    "1. Get committee.Here we choose SB1 committee.\n",
    "2. Get adversarial samples: CWL2 and PGD\n",
    "3. For each sample, get mask of dataset at which committee disagree. Values are 0, 0.24, 0.3, 0.45, 0.6. We select 0.4 as the entropy threshold so that new labels are $0,\\ldots,19$.\n",
    "4. $D = (X,Y) = (X_0, Y_0) \\sqcup (X_1, Y_1)$ where $X_0 = \\{I(x)<0.4\\}, X_1 = \\{I(x) \\geq 0.4\\},$ and  $Y_1 = \\{y+10 :  x \\in X_1\\}$. See the accuracy on $X_0$ and $X_1$ of Committee.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f8439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comm 1: (0, 3, 2, 1)\n",
      "comm_SB_1 [('ResNet20v1_SB_0', <keras.engine.functional.Functional object at 0x1479dfad9fc0>), ('ResNet20v2_SB_3', <keras.engine.functional.Functional object at 0x1479d2982ec0>), ('ResNet56v1_SB_2', <keras.engine.functional.Functional object at 0x1479d2b25f60>), ('ResNet56v2_SB_1', <keras.engine.functional.Functional object at 0x1479df51a320>)]\n",
      "-------------------------------------------------- keys for adv samples --------------------------------------------------\n",
      "('cwl2', 'untargeted', 'train')\n",
      "('PGD by ResNet56v1', 'untargeted', 'train')\n",
      "('PGD by ResNet56v1', 'targeted to 2nd', 'train')\n",
      "('PGD by ResNet56v1', 'targeted to least', 'train')\n",
      "('PGD by ResNet56v1', 'targeted to least', 'val')\n",
      "('cwl2', 'untargeted', 'val')\n",
      "('PGD by ResNet56v1', 'targeted to 2nd', 'val')\n",
      "('PGD by ResNet56v1', 'untargeted', 'val')\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries and set experiments.\n",
    "\n",
    "# load necessary libraries\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras import Model\n",
    "from scipy.stats import entropy\n",
    "import math\n",
    "loaded_models = {}\n",
    "# load additional models from another folder\n",
    "# assuming these models are also saved in Keras format with '.keras' extension\n",
    "# Say 'SB-type', where 'SB' stands for 'Specialized Base'.\n",
    "folder = 'CIFAR10models/more_tunned/'\n",
    "pattern = os.path.join(folder, '*_more_specialized*.keras')\n",
    "file_list = sorted(glob.glob(pattern))\n",
    "loaded_models.update({os.path.basename(f): load_model(f) for f in file_list})\n",
    "\n",
    "label_dict = {(3,1) : 'ResNet20v1',\n",
    "        (3,2) : 'ResNet20v2',\n",
    "        (9,1): 'ResNet56v1',\n",
    "        (9,2): 'ResNet56v2'}\n",
    "\n",
    "(x, y), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_v, y_train, y_v = train_test_split(x, y, test_size=0.2, \n",
    "                                              random_state=42) # random state has been always 42.\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_val = x_v.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train_categorical_10 = to_categorical(y_train,10)\n",
    "y_val_categorical_10 = to_categorical(y_v,10)\n",
    "y_test_categorical_10 = to_categorical(y_test,10)\n",
    "y_test_categorical_20 = to_categorical(y_test,20)\n",
    "\n",
    "# Set the predetermined random seed\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# Define ranges\n",
    "range1 = [range(8), range(4), range(4), range(4)]\n",
    "range2 = [range(8), range(4), [0], range(4)]\n",
    "\n",
    "# Sample one tuple from each\n",
    "tuple1 = tuple(rng.choice(r) for r in range1)\n",
    "\n",
    "print(\"Comm 1:\", tuple1)\n",
    "comm_SB_1 = []\n",
    "for file_name, model in loaded_models.items():\n",
    "    # Extract model name from the file name\n",
    "    base = file_name.replace('.keras','')\n",
    "    parts = base.split('_')\n",
    "    if parts[0] == 'n':\n",
    "        model_name = label_dict[(int(parts[1]),int(parts[2][-1]))] + '_B_'+parts[-1][-1]\n",
    "    else:\n",
    "        model_name = parts[0] + '_SB_' + parts[-1]\n",
    "    # print(f\"Model: {model_name}\")\n",
    "    parts = model_name.split('_')\n",
    "    if parts[0] == 'ResNet20v1':\n",
    "        if parts[1] == 'SB':\n",
    "            if int(parts[-1]) == tuple1[0]:\n",
    "                comm_SB_1.append((model_name,model))\n",
    "    if parts[0] == 'ResNet20v2':\n",
    "        if parts[1] == 'SB':\n",
    "            if int(parts[-1]) == tuple1[1]:\n",
    "                comm_SB_1.append((model_name,model))\n",
    "    if parts[0] == 'ResNet56v1':\n",
    "        if parts[1] == 'SB':\n",
    "            if int(parts[-1]) == tuple1[2]:\n",
    "                comm_SB_1.append((model_name,model))\n",
    "    if parts[0] == 'ResNet56v2':\n",
    "        if parts[1] == 'SB':\n",
    "            if int(parts[-1]) == tuple1[3]:\n",
    "                comm_SB_1.append((model_name,model))\n",
    "                \n",
    "print('comm_SB_1', comm_SB_1)\n",
    "\n",
    "\n",
    "# As SB model shows better performance on the certain part, let use SB type models to analyze the behavior on the certain part against adversarial examples.\n",
    "\n",
    "# Load the adversarial examples\n",
    "\n",
    "## set all files.\n",
    "## Possibly there is no merged testing dataset, or validation dataset.\n",
    "## We only look for testing dataset.\n",
    "import re\n",
    "\n",
    "pattern1 = re.compile(r'_\\d+to\\d+_')\n",
    "pattern2 = re.compile(r'test')\n",
    "\n",
    "folder = './adversarial_examples/gen_by_ResNet'\n",
    "all_files = os.listdir(folder)\n",
    "\n",
    "filtered_files = [\n",
    "    fname for fname in all_files\n",
    "    if fname.endswith('.npy') and not pattern1.search(fname) and not pattern2.search(fname)\n",
    "]\n",
    "\n",
    "\n",
    "## load all the training and validation dataset\n",
    "\n",
    "loaded_training_dataset = {}\n",
    "loaded_validation_dataset = {}\n",
    "import re\n",
    "for f in filtered_files:\n",
    "    \n",
    "    base = f.replace('.keras.npy','').replace('.npy','')\n",
    "    parts = base.split('_')\n",
    "    '''\n",
    "    cwl2_x_tr_untargeted\n",
    "    cwl2_x_v_untargeted.npy\n",
    "    pgd_0.376_x_target_to_ll.npy\n",
    "    pgd_0.376_x_target_to_second.npy\n",
    "    pgd_0.376_x_untarget.npy\n",
    "    pgd_0.376_x_val_target_to_ll.npy\n",
    "    pgd_0.376_x_val_target_to_second.npy\n",
    "    pgd_0.376_x_val_untarget.npy\n",
    "    '''\n",
    "    \n",
    "    attack_type = parts[0]\n",
    "    if attack_type == 'cwl2':\n",
    "        direction = 'untargeted'\n",
    "        if parts[2] == 'tr':\n",
    "            train_or_val = 'train'\n",
    "        else:\n",
    "            train_or_val = 'val'\n",
    "    else:\n",
    "        attack_type = 'PGD by ResNet56v1'\n",
    "        direction = parts[-1]\n",
    "        if direction == 'll':\n",
    "            direction = 'targeted to least'\n",
    "        elif direction =='second':\n",
    "            direction = 'targeted to 2nd'\n",
    "        else:\n",
    "            direction = 'untargeted'\n",
    "        if parts[3] == 'val':\n",
    "            train_or_val = 'val'\n",
    "        else:\n",
    "            train_or_val = 'train'\n",
    "    key = (attack_type, direction, train_or_val)\n",
    "    if train_or_val == 'train':\n",
    "        loaded_training_dataset[key] = np.load(os.path.join(folder, f))\n",
    "    else:\n",
    "        loaded_validation_dataset[key] = np.load(os.path.join(folder, f))\n",
    "\n",
    "print('-'*50, 'keys for adv samples', '-'*50)\n",
    "for k in loaded_training_dataset.keys():\n",
    "    print(k)\n",
    "    \n",
    "for k in loaded_validation_dataset.keys():\n",
    "    print(k)\n",
    "    \n",
    "    \n",
    "def get_entropy_array(committee : list[tuple[str,Model]], sample : np.ndarray): \n",
    "    '''\n",
    "    param committee: list of tuple (member, model)\n",
    "    param sample: numpy array of (n,) shape\n",
    "    \n",
    "    return tuple of dict, numpy array of (n,) shape\n",
    "    dictionary : committee member -> list of [answer to the sample, certainty to the sample]\n",
    "    '''\n",
    "    comm_pred = {}\n",
    "    for member, model in committee:\n",
    "        p = model.predict(sample,verbose = 0)\n",
    "        comm_pred[member] = [\n",
    "                                np.argmax(p,axis=-1),\n",
    "                                np.max(p,axis=-1)\n",
    "                                ]\n",
    "    stacked = np.stack([member_pred[0] for member_pred in comm_pred.values()], axis=1)\n",
    "    counts = np.apply_along_axis(lambda x: np.bincount(x, minlength=10), axis=1, arr=stacked)\n",
    "    probs = counts / counts.sum(axis=1, keepdims=True)\n",
    "    disagreements = entropy(probs, axis=1, base = 10)\n",
    "    \n",
    "    return disagreements\n",
    "\n",
    "committee = comm_SB_1\n",
    "\n",
    "## CWL2 train and val\n",
    "cwl2_train = loaded_training_dataset[('cwl2', 'untargeted', 'train')]\n",
    "cwl2_val = loaded_validation_dataset[('cwl2', 'untargeted', 'val')]\n",
    "entropy_cwl2_train = np.load('./entropies/entropy_SB1_cwl2_untargeted_train.npy')\n",
    "entropy_cwl2_val = np.load('./entropies/entropy_SB1_cwl2_untargeted_val.npy')\n",
    "cwl2_new_label_train = np.load('./new_labels/SB1/new_label_cwl2_untargeted_train.npy')\n",
    "cwl2_new_label_val= np.load('./new_labels/SB1/new_label_cwl2_untargeted_val.npy')\n",
    "cwl2_new_label_test= np.load('./new_labels/SB1/new_label_cwl2_untargeted_test.npy')\n",
    "## PGD untargeted train and val\n",
    "PGD_train = loaded_training_dataset[('PGD by ResNet56v1', 'untargeted', 'train')]\n",
    "PGD_val = loaded_validation_dataset[('PGD by ResNet56v1', 'untargeted', 'val')]\n",
    "entropy_PGD_untargeted_train = np.load('./entropies/entropy_SB1_PGD by ResNet56v1_untargeted_train.npy')\n",
    "entropy_PGD_untargeted_val = np.load('./entropies/entropy_SB1_PGD by ResNet56v1_untargeted_val.npy')\n",
    "PGD_untargeted_new_label_train = np.load('./new_labels/SB1/new_label_PGD_untargeted_train.npy')\n",
    "PGD_untargeted_new_label_val = np.load('./new_labels/SB1/new_label_PGD_untargeted_val.npy')\n",
    "PGD_untargeted_new_label_test = np.load('./new_labels/SB1/new_label_PGD_untargeted_test.npy')\n",
    "## PGD targeted train and val\n",
    "PGD_targeted_train = loaded_training_dataset[('PGD by ResNet56v1', 'targeted to least', 'train')]\n",
    "PGD_targeted_val = loaded_validation_dataset[('PGD by ResNet56v1', 'targeted to least', 'val')]\n",
    "entropy_PGD_targeted_train = np.load('./entropies/entropy_SB1_PGD by ResNet56v1_targeted to least_train.npy')\n",
    "entropy_PGD_targeted_val = np.load('./entropies/entropy_SB1_PGD by ResNet56v1_targeted to least_val.npy')\n",
    "PGD_targeted_new_label_train = np.load('./new_labels/SB1/new_label_PGD_targeted_train.npy')\n",
    "PGD_targeted_new_label_val = np.load('./new_labels/SB1/new_label_PGD_targeted_val.npy')\n",
    "PGD_targeted_new_label_test = np.load('./new_labels/SB1/new_label_PGD_targeted_test.npy')\n",
    "\n",
    "def committee_answers(committee, sample, entropy, mask = None):\n",
    "    if mask is None:\n",
    "        # Create a mask for non-zero entropy values\n",
    "        mask = entropy != 0\n",
    "\n",
    "    # Prepare data for the table\n",
    "    table_data = {\n",
    "        'Original Label': y_train[:sample.shape[0]][mask].reshape(-1),\n",
    "        'Entropy': np.round(entropy[mask], 3)\n",
    "    }\n",
    "\n",
    "    # Loop through the committee to get predictions\n",
    "    for member, model in committee:\n",
    "        # Predictions on CWL2 adversarial data\n",
    "        p  = model.predict(sample[mask], verbose=0)\n",
    "        table_data[f'{member[-1]}p'] = np.argmax(p , axis=-1)\n",
    "        table_data[f'{member[-1]}c'] = np.round(np.max(p , axis=-1), 3)\n",
    "\n",
    "    # Create and display the DataFrame\n",
    "    df = pd.DataFrame(table_data)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3474ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Original training samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 1.0, on X_0: 1.0, Empty X_1\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 1.0, on X_0: 1.0, Empty X_1\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 1.0, on X_0: 1.0, Empty X_1\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.999975, on X_0: 0.999975, Empty X_1\n",
      "On Original validation samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.9082, on X_0: 0.9271809661139149, on X_1: 0.27491408934707906\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.9128, on X_0: 0.9305798743433927, on X_1: 0.31958762886597936\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.9072, on X_0: 0.9242970439798125, on X_1: 0.33676975945017185\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.9222, on X_0: 0.9373776908023483, on X_1: 0.41580756013745707\n",
      "On Original testing samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.9052, on X_0: 0.9224510813594232, on X_1: 0.3275862068965517\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.9068, on X_0: 0.925849639546859, on X_1: 0.2689655172413793\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.9069, on X_0: 0.923686920700309, on X_1: 0.3448275862068966\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.9174, on X_0: 0.9322348094747683, on X_1: 0.4206896551724138\n",
      "On CWL2 training samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.9996000399960004, on X_0: 0.9996000399960004, Empty X_1\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.9995000499950005, on X_0: 0.9995000499950005, Empty X_1\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.9991000899910009, on X_0: 0.9991000899910009, Empty X_1\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.9992000799920008, on X_0: 0.9992000799920008, Empty X_1\n",
      "On CWL2 validation samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.8904, on X_0: 0.9116549149730402, on X_1: 0.3146067415730337\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.8948, on X_0: 0.9154914973040232, on X_1: 0.3342696629213483\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.8841, on X_0: 0.9040854417254252, on X_1: 0.34269662921348315\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.9018, on X_0: 0.9200539195354624, on X_1: 0.40730337078651685\n",
      "On CWL2 testing samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.896, on X_0: 0.9150299772586313, on X_1: 0.3312883435582822\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.8945, on X_0: 0.9148232375439322, on X_1: 0.29141104294478526\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.8891, on X_0: 0.90769071738681, on X_1: 0.3374233128834356\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.9051, on X_0: 0.9218523878437048, on X_1: 0.40797546012269936\n",
      "On PGD untargeted training samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.5974, on X_0: 0.6121302484091695, on X_1: 0.3707496927488734\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.6085, on X_0: 0.6235522777496738, on X_1: 0.3768947152806227\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.5268, on X_0: 0.5442104422375462, on X_1: 0.25891028267103644\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.60035, on X_0: 0.6170025826033707, on X_1: 0.3441212617779599\n",
      "On PGD untargeted validation samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.5216, on X_0: 0.5392358480355017, on X_1: 0.30749014454664914\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.538, on X_0: 0.5537395822058664, on X_1: 0.3469119579500657\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.4577, on X_0: 0.4771079121117004, on X_1: 0.22207621550591328\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.5412, on X_0: 0.5556878450048707, on X_1: 0.36530880420499345\n",
      "On PGD untargeted testing samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.5179, on X_0: 0.5338240069271566, on X_1: 0.32457293035479634\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.5345, on X_0: 0.5524407403398636, on X_1: 0.316688567674113\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.4552, on X_0: 0.4744019915575279, on X_1: 0.22207621550591328\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.5368, on X_0: 0.554280766316701, on X_1: 0.32457293035479634\n",
      "On PGD targeted training samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.7933, on X_0: 0.8368849283223557, on X_1: 0.3859286083807553\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.787875, on X_0: 0.8350583937565728, on X_1: 0.3468701500258665\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.755675, on X_0: 0.8080478219959041, on X_1: 0.2661665804449043\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.76865, on X_0: 0.8174849172524492, on X_1: 0.3122090015519917\n",
      "On PGD targeted validation samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.7209, on X_0: 0.7799152639413718, on X_1: 0.31412786108918705\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.7202, on X_0: 0.7792282148173595, on X_1: 0.31333859510655093\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.6898, on X_0: 0.754150921790908, on X_1: 0.2462509865824783\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.7142, on X_0: 0.7762510019466392, on X_1: 0.2865035516969219\n",
      "On PGD targeted testing samples...\n",
      "Member: ResNet20v1_SB_0, Acc on Whole: 0.7198, on X_0: 0.7731169276488742, on X_1: 0.3469224620303757\n",
      "Member: ResNet20v2_SB_3, Acc on Whole: 0.7226, on X_0: 0.7830609212481426, on X_1: 0.2997601918465228\n",
      "Member: ResNet56v1_SB_2, Acc on Whole: 0.6865, on X_0: 0.7493427820322323, on X_1: 0.24700239808153476\n",
      "Member: ResNet56v2_SB_1, Acc on Whole: 0.7118, on X_0: 0.7709452508858156, on X_1: 0.2981614708233413\n"
     ]
    }
   ],
   "source": [
    "y_samples = [y_train.reshape(-1), y_v.reshape(-1), y_test.reshape(-1)]\n",
    "name = ['training','validation','testing']\n",
    "## Original\n",
    "for i, sample in enumerate([x_train, x_val, x_test]):\n",
    "    print(f'On Original {name[i]} samples...')\n",
    "    entropy_array = get_entropy_array(committee,sample)\n",
    "    mask = entropy_array>0.4\n",
    "    \n",
    "    y = y_samples[i]\n",
    "    for member, model in comm_SB_1:\n",
    "        \n",
    "        p = model.predict(sample,verbose =0)\n",
    "        a = np.argmax(p,axis=-1)\n",
    "        c = np.max(p, axis=-1)\n",
    "        print(f'Member: {member}, Acc on Whole: {np.sum(a == y)/len(y)}, on X_0: {np.sum(a[~mask] == y[~mask])/len(y[~mask])},', end=' ')\n",
    "        if np.sum(mask) == 0:\n",
    "            print('Empty X_1')\n",
    "        else:\n",
    "            print(f'on X_1: {np.sum(a[mask] == y[mask])/len(y[mask])}') \n",
    "        \n",
    "\n",
    "\n",
    "## CWL2\n",
    "entropy_array = get_entropy_array(committee,np.load('./adversarial_examples/gen_by_ResNet/cwl2_x_test_untargeted.npy'))\n",
    "entropies = [entropy_cwl2_train,entropy_cwl2_val,entropy_array]\n",
    "\n",
    "for i, sample in enumerate([cwl2_train, cwl2_val, np.load('./adversarial_examples/gen_by_ResNet/cwl2_x_test_untargeted.npy')]):\n",
    "    print(f'On CWL2 {name[i]} samples...')\n",
    "    if i == 0 :\n",
    "        size = 10001\n",
    "    else: \n",
    "        size = 10000\n",
    "    mask = entropies[i] > 0.4\n",
    "    y = y_samples[i][:size]\n",
    "    for member, model in comm_SB_1:\n",
    "        p = model.predict(sample[:size],verbose =0)\n",
    "        a = np.argmax(p,axis=-1)\n",
    "        c = np.max(p, axis=-1)\n",
    "        print(f'Member: {member}, Acc on Whole: {np.sum(a == y)/len(y)}, on X_0: {np.sum(a[~mask] == y[~mask])/len(y[~mask])},', end=' ')\n",
    "        if np.sum(mask) == 0:\n",
    "            print('Empty X_1')\n",
    "        else:\n",
    "            print(f'on X_1: {np.sum(a[mask] == y[mask])/len(y[mask])}') \n",
    "        \n",
    "\n",
    "## PGD untargeted\n",
    "entropy_array = get_entropy_array(committee,np.load('./adversarial_examples/gen_by_ResNet/pgd_0.376_x_test_untarget_gen_by_n_9_v1_cifar10.keras.npy'))\n",
    "entropies = [entropy_PGD_untargeted_train,entropy_PGD_untargeted_val,entropy_array]\n",
    "\n",
    "for i, sample in enumerate([PGD_train, PGD_val, np.load('./adversarial_examples/gen_by_ResNet/pgd_0.376_x_test_untarget_gen_by_n_9_v1_cifar10.keras.npy')]):\n",
    "    print(f'On PGD untargeted {name[i]} samples...')\n",
    "    mask = entropies[i] > 0.4\n",
    "    y = y_samples[i]\n",
    "    for member, model in comm_SB_1:\n",
    "        p = model.predict(sample,verbose =0)\n",
    "        a = np.argmax(p,axis=-1)\n",
    "        c = np.max(p, axis=-1)\n",
    "        print(f'Member: {member}, Acc on Whole: {np.sum(a == y)/len(y)}, on X_0: {np.sum(a[~mask] == y[~mask])/len(y[~mask])},', end=' ')\n",
    "        if np.sum(mask) == 0:\n",
    "            print('Empty X_1')\n",
    "        else:\n",
    "            print(f'on X_1: {np.sum(a[mask] == y[mask])/len(y[mask])}') \n",
    "        \n",
    "\n",
    "## PGD targeted\n",
    "\n",
    "entropy_array = get_entropy_array(committee,np.load('./adversarial_examples/gen_by_ResNet/pgd_0.376_x_test_target_to_ll_gen_by_n_9_v1_cifar10.keras.npy'))\n",
    "entropies = [entropy_PGD_targeted_train,entropy_PGD_targeted_val,entropy_array]\n",
    "for i, sample in enumerate([PGD_targeted_train, PGD_targeted_val, np.load('./adversarial_examples/gen_by_ResNet/pgd_0.376_x_test_target_to_ll_gen_by_n_9_v1_cifar10.keras.npy')]):\n",
    "    print(f'On PGD targeted {name[i]} samples...')\n",
    "    mask = entropies[i] > 0.4\n",
    "    y = y_samples[i]\n",
    "    for member, model in comm_SB_1:\n",
    "        p = model.predict(sample,verbose =0)\n",
    "        a = np.argmax(p,axis=-1)\n",
    "        c = np.max(p, axis=-1)\n",
    "        print(f'Member: {member}, Acc on Whole: {np.sum(a == y)/len(y)}, on X_0: {np.sum(a[~mask] == y[~mask])/len(y[~mask])},', end=' ')\n",
    "        if np.sum(mask) == 0:\n",
    "            print('Empty X_1')\n",
    "        else:\n",
    "            print(f'on X_1: {np.sum(a[mask] == y[mask])/len(y[mask])}') \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68df67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
