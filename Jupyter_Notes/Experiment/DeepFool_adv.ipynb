{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3459c24b",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "Here we focus only untargeted attack.\n",
    "\n",
    "| Attack Method | Attack generating Model  Structure |  direction|\n",
    "|---------------|---------|----------|\n",
    "| **DeepFool**      | ResNet  | Untargeted (train / val / test) |\n",
    "\n",
    "Assumed directories are\n",
    "\n",
    "- experiment_untargeted_adv.ipynb\n",
    "- data\n",
    "| -- modules\n",
    "| | --- CIFAR10models\n",
    "| | --- Adversarial_models\n",
    "| -- samples\n",
    "| | --- cwl2_targeted_to-2nd_test_by_resnet56v1_ver0.npy\n",
    "| | --- ...\n",
    "| | --- fgm_eps216_targeted_to-2nd_test_by_resnet56v1_ver0.npy\n",
    "| | --- ...\n",
    "...\n",
    "\n",
    "- logifld_modules\n",
    "| -- logifoldv1_4_modified.py\n",
    "adv_lofiold.py\n",
    "- runs\n",
    "| -- cache\n",
    "| | --- preds\n",
    "| | --- metrics\n",
    "| | --- index\n",
    "- analysis\n",
    "\n",
    "TODO: Edit above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944199a2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from __future__ import annotations\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac0b04",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22df2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "\n",
    "ROOT = Path(\".\").resolve()\n",
    "DATA = ROOT / \"data\"\n",
    "MODELS_DIR = DATA / \"models\"\n",
    "ADV_MODELS_DIR = DATA / \"adversarial_models\"\n",
    "ADV_SAMPLES = DATA / \"samples\"\n",
    "EXPERTS_DIR = DATA / \"specialized_models\"\n",
    "LOGIFOLD_MODS = (ROOT / \"logifold_modules\") \n",
    "\n",
    "\n",
    "CACHE = DATA / \"cache\"\n",
    "CACHE_PREDS = CACHE / \"preds\"\n",
    "CACHE_METRICS = CACHE / \"metrics\"\n",
    "CACHE_INDEX = CACHE / \"index\"\n",
    "ANALYSIS = ROOT / \"analysis\"\n",
    "ANALYSIS.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES = ANALYSIS / \"figures\"\n",
    "FIGURES.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS = ANALYSIS / \"reports\"\n",
    "REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "LGFD_PATH = DATA / \"logifold\"\n",
    "# Define Judge\n",
    "JUDGES_DIR = sorted(glob.glob(str(MODELS_DIR / 'resnet*original_tuned-once-on_original*')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f985c",
   "metadata": {},
   "source": [
    "## Import project libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logifold_modules.logifoldv1_4_modified import Logifold, _stem_all, int_from_model_path\n",
    "from logifold_modules.resnet_modified import ResNet\n",
    "import logifold_modules.custom_specialization as specialization\n",
    "from adv_logifold import AdvLogifold, get_statistics, plot_disagreements\n",
    "import cache_store\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d243c0",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5dffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_resnet(training_x,\n",
    "                     training_y_long,\n",
    "                     validating_x,\n",
    "                     validating_y_long,\n",
    "                     path,\n",
    "                     n ,\n",
    "                     v ,\n",
    "                     ) -> tf.keras.Model:\n",
    "    resnet_model = ResNet(path, training_x, training_y_long, validating_x, validating_y_long, n=n, version=v)\n",
    "    resnet_model.train(save_best_only=True, epochs=200)\n",
    "    return\n",
    "\n",
    "def load_adv_samples(pattern: str, _print_ : bool = False) -> np.ndarray:\n",
    "    files = sorted(glob.glob(str(ADV_SAMPLES / pattern)))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No samples for pattern: {pattern}\")\n",
    "    if _print_:\n",
    "        print(f\"Loading {len(files)} files matching pattern: {pattern}\")\n",
    "        for f in files:\n",
    "            \n",
    "            print(f\" - {f}\")\n",
    "    samples = [np.load(f) for f in files]\n",
    "    if len(samples) == 1:\n",
    "        samples = samples[0]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6704347",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca15686",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AttackEntry:\n",
    "    short_tag: str                    # short_tag\n",
    "    glob_pattern: str            # pattern in data/samples\n",
    "    adv_label: str                     # label for cache\n",
    "\n",
    "# Untargeted sets generated by ResNet56v1 ver0\n",
    "ATTACKS: List[AttackEntry] = [\n",
    "    AttackEntry(\"DeepFool\",            \"*deepfool_untargeted_train_by_resnet56v1_ver0.npy\", \"deepfool-untargeted-gen-by-resnet56v1-ver0\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9601e",
   "metadata": {},
   "source": [
    "## Original Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4391a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_val = x_val.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train_categorical_10 = to_categorical(y_train,10)\n",
    "y_val_categorical_10 = to_categorical(y_val,10)\n",
    "y_test_categorical_10 = to_categorical(y_test,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77029248",
   "metadata": {},
   "source": [
    "## Define helper function after loading samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_union_and_specialize(\n",
    "    x_adv_tr: np.ndarray, x_adv_val: np.ndarray, adv_label: str,\n",
    "    \n",
    ") -> Tuple[tf.keras.Model, tf.keras.Model]:\n",
    "    \"\"\"\n",
    "    Returns (baseline_adv_model, tuned_baseline_adv_model, tuned_history_dict_or_None)\n",
    "    \"\"\"\n",
    "    size = x_adv_tr.shape[0] # CWL2 example training size is not 40000 but 10001.\n",
    "    train_union = np.concatenate([x_train, x_adv_tr], axis=0)\n",
    "    val_union = np.concatenate([x_val, x_adv_val], axis=0)\n",
    "\n",
    "    training_y_long=np.concatenate([y_train,y_train[:size]],axis=0)\n",
    "    validating_y_long=np.concatenate([y_val,y_val],axis=0)\n",
    "    if training_y_long.ndim == 1 or training_y_long.shape[1] != 10:\n",
    "        training_y_long = to_categorical(training_y_long, 10)\n",
    "    if validating_y_long.ndim == 1 or validating_y_long.shape[1] != 10:\n",
    "        validating_y_long = to_categorical(validating_y_long, 10)\n",
    "\n",
    "    path = ADV_MODELS_DIR / f\"ResNet56v1_union-of-original-and-{adv_label}_ver0.keras\"\n",
    "    if path.exists():\n",
    "        base_model = load_model(path)\n",
    "    else:\n",
    "        build_and_train_resnet(train_union,\n",
    "                    training_y_long,\n",
    "                    val_union,\n",
    "                    validating_y_long,\n",
    "                    path = path,\n",
    "                    n = 9,\n",
    "                    v = 1\n",
    "                    )\n",
    "        base_model = load_model(path)\n",
    "    baseline_before_tuning = base_model\n",
    "    path = ADV_MODELS_DIR / f\"ResNet56v1_union-of-original-and-{adv_label}_tuned-once-on_union-of-original-and-{adv_label}_ver0.keras\"\n",
    "    if path.exists():\n",
    "        baseline_after_tuning = load_model(path)\n",
    "        hist_baseline = specialization.load_history(path) # it could be none.\n",
    "        if hist_baseline is None:\n",
    "            print(f\"[WARN] No history found for {path}\")\n",
    "    else:\n",
    "        baseline_after_tuning,hist_baseline = specialization.turn_specialist(base_model, path = path,\n",
    "                                                x_tr=train_union, y_tr=training_y_long,\n",
    "                                                  x_v=val_union,   y_v=validating_y_long,\n",
    "                                                  epochs=21, learning_rate=1e-3, batch_size=128, verbose=1, name=f\"tuned_once\")\n",
    "        hist_baseline = {\"history\": hist_baseline.history, \"params\": hist_baseline.params, \"epoch\": hist_baseline.epoch}\n",
    "\n",
    "    return baseline_before_tuning, baseline_after_tuning, hist_baseline\n",
    "\n",
    "def construct_or_load_logifold(num_classes:int = 10):\n",
    "    \"\"\"\n",
    "    Build AdvLogifold instance and add models to AdvLogifold.\n",
    "    After constructing, we will call getFuzDoms(x=val, y=val_onehot, ...)\n",
    "    returns (adversarial_lgfd, JUDGES_KEYS)\n",
    "    \"\"\"\n",
    "    path = LGFD_PATH\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "    eval_path = path/'evals'\n",
    "    if not eval_path.exists():\n",
    "        eval_path.mkdir(parents=True, exist_ok=True)\n",
    "    adversarial_lgfd = AdvLogifold(num_classes, new_story = False, path = path, path_for_cache = CACHE)\n",
    "    adversarial_lgfd.load()\n",
    "    JUDGES_KEYS = []\n",
    "    for a_judge_path in JUDGES_DIR:\n",
    "        key = (int_from_model_path(a_judge_path),)\n",
    "        JUDGES_KEYS.append(key)\n",
    "        if key not in adversarial_lgfd.keys():\n",
    "            print(f\"Adding a judge from {a_judge_path} with key {key}...\")\n",
    "            model = load_model(a_judge_path)\n",
    "            adversarial_lgfd.add(model, key = key, filetype = '.keras',\n",
    "                         fuzDom = {}, model_path=_stem_all(a_judge_path))\n",
    "        for k in JUDGES_KEYS:\n",
    "            if not adversarial_lgfd.charts[k]['fuzDom']:\n",
    "                print(f'{k} has no fuzDom,')\n",
    "                adversarial_lgfd.getFuzDoms(keys = [k],\n",
    "                            x = x_val, y = y_val_categorical_10, sample_name = 'original_val',\n",
    "                            update = False, autosave = False, verbose = 0)\n",
    "    return adversarial_lgfd, JUDGES_KEYS\n",
    "\n",
    "def specialize_Committee(adversarial_lgfd : AdvLogifold, Comm_keys : List[Tuple],  adv_short_tag: str):\n",
    "    \n",
    "    # Get adversarial sample corresponding to the adv_short_tag\n",
    "    adv_type = adv_short_tag\n",
    "    for atk in ATTACKS:\n",
    "        if atk.short_tag == adv_type:\n",
    "            adv_sample_name = atk.adv_label\n",
    "            \n",
    "            adv_sample_train = load_adv_samples(atk.glob_pattern)\n",
    "            pattern = atk.glob_pattern.replace(\"train\", \"val\")\n",
    "            adv_sample_val = load_adv_samples(pattern)\n",
    "            break\n",
    "\n",
    "    # Compute entropy of adversarial sample by JUDGE models\n",
    "    ent_original_train =adversarial_lgfd.get_entropy_array(Comm_keys, sample_name = 'original_train', sample = x_train)\n",
    "    ent_adv_train = adversarial_lgfd.get_entropy_array(Comm_keys, sample_name = adv_sample_name + '_train', sample = adv_sample_train)\n",
    "    plot_disagreements(ent_adv_train, title = \"Entropy Disagreements on Adversarial Training Samples\", save_path = FIGURES / f\"entropy-disagreements-on-{adv_sample_name}_train.png\")\n",
    "\n",
    "    ent_original_val = adversarial_lgfd.get_entropy_array(Comm_keys, sample_name = 'original_val', sample = x_val)\n",
    "    ent_adv_val = adversarial_lgfd.get_entropy_array(Comm_keys, sample_name = adv_sample_name + '_val', sample = adv_sample_val)\n",
    "    plot_disagreements(ent_adv_val, title = \"Entropy Disagreements on Adversarial Validation Samples\", save_path = FIGURES / f\"entropy-disagreements-on-{adv_sample_name}_val.png\")\n",
    "    \n",
    "    # Including original sample, compute average of entropy\n",
    "    stats = {}\n",
    "    stats[('original','train')] = get_statistics(ent_original_train)\n",
    "    stats[('original','val')] = get_statistics(ent_original_val)\n",
    "    stats[('adv','train')] = get_statistics(ent_adv_train)\n",
    "    stats[('adv','val')] = get_statistics(ent_adv_val)\n",
    "    train_alpha_union = (stats[('original','train')]['average'] + stats[('adv','train')]['average'])/2\n",
    "    val_alpha_union = (stats[('original','val')]['average'] + stats[('adv','val')]['average'])/2\n",
    "\n",
    "    # separate union of original and adversarial samples into high entropy and low entropy samples\n",
    "    loc_1_original_train = ent_original_train>=train_alpha_union\n",
    "    loc_1_adv_train = ent_adv_train>=train_alpha_union\n",
    "    loc_1_original_val = ent_original_val>=val_alpha_union\n",
    "    loc_1_adv_val = ent_adv_val>=val_alpha_union\n",
    "    print('alpha for train: {}, for val: {}'.format(train_alpha_union, val_alpha_union))\n",
    "    print('the number of data greater than alpha:')\n",
    "    print(f'Training set original + {adv_type}:', np.sum(loc_1_original_train), '+',np.sum(loc_1_adv_train), '=', np.sum(loc_1_original_train) + np.sum(loc_1_adv_train))\n",
    "    print(f'Validation set original + {adv_type}:', np.sum(loc_1_original_val), '+', np.sum(loc_1_adv_val), '=', np.sum(loc_1_original_val) + np.sum(loc_1_adv_val))\n",
    "\n",
    "    DATASETS = {\"Experts_union\":dict(train = (np.concatenate([x_train[loc_1_original_train], adv_sample_train[loc_1_adv_train]]), \n",
    "                                            to_categorical(\n",
    "                                                np.concatenate(\n",
    "                                                [y_train[loc_1_original_train], y_train[:adv_sample_train.shape[0]][loc_1_adv_train]]\n",
    "                                                ), 10)\n",
    "                                            ),\n",
    "                                    val=(np.concatenate([x_val[loc_1_original_val], adv_sample_val[loc_1_adv_val]]), \n",
    "                                        to_categorical(\n",
    "                                            np.concatenate(\n",
    "                                                [y_val[loc_1_original_val], y_val[loc_1_adv_val]]\n",
    "                                                ),10)))}\n",
    "    \n",
    "    # specialize Judge models on the high entropy samples\n",
    "    EXPERTS_KEYS = []\n",
    "    experts_paths = []\n",
    "    \n",
    "    for a_judge_key in Comm_keys: \n",
    "        a_judge = adversarial_lgfd.getModel(a_judge_key)\n",
    "        a_judge_name = adversarial_lgfd.model_source_name(a_judge_key)\n",
    "        print(f\"Specializing Judge {a_judge_name} on union of original and {adv_type} samples...\")\n",
    "        \n",
    "        path = EXPERTS_DIR / f\"{a_judge_name}_specialized-once-on_high-entropy-union-of-original-and-{adv_sample_name}_ver0.keras\"\n",
    "        specialist, hist = specialization.turn_specialist(model = a_judge, path = path,\n",
    "                                       x_tr = DATASETS[\"Experts_union\"][\"train\"][0], y_tr = DATASETS[\"Experts_union\"][\"train\"][1],\n",
    "                                       x_v = DATASETS[\"Experts_union\"][\"val\"][0], y_v = DATASETS[\"Experts_union\"][\"val\"][1],\n",
    "                                       epochs = 21, learning_rate = 1e-3, batch_size = 128, verbose = 1, \n",
    "                                       name = f\"specialized_once_on_high-entropy_union_of_original_and_{adv_sample_name}\")\n",
    "        plt.plot(hist.history['accuracy'], label='train accuracy')\n",
    "        plt.plot(hist.history['val_accuracy'], label='val accuracy')\n",
    "        plt.title(f'Accuracy of specialized {a_judge_name} (tuned once)\\non high-ent-union-{adv_sample_name}')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.savefig(FIGURES / f'Accuracy of specialized {a_judge_name} (tuned once) on high-ent-union-{adv_sample_name}.png', dpi=150)\n",
    "        # Add them to Advlogifold\n",
    "        adversarial_lgfd.add(specialist, \n",
    "                             model_path = path, \n",
    "                             target = 10, \n",
    "                             description = f'specialized on high entropy union of original and {adv_sample_name}', \n",
    "                             fuzDom = {})\n",
    "        # compute fuzdom\n",
    "        adversarial_lgfd.getFuzDoms(keys = [(int_from_model_path(path),)],\n",
    "                            x = DATASETS[\"Experts_union\"][\"val\"][0], y = DATASETS[\"Experts_union\"][\"val\"][1], sample_name = f'union_of_original_and_{adv_sample_name}_val',\n",
    "                            update = False, autosave = False, verbose = 0)\n",
    "        EXPERTS_KEYS.append((int_from_model_path(path),))\n",
    "        experts_paths.append(path)\n",
    "        \n",
    "        alpha = val_alpha_union\n",
    "    return EXPERTS_KEYS, experts_paths, alpha\n",
    "\n",
    "def _pick_acc(result):\n",
    "        # Accuracy by using History\n",
    "        return result[4][-1][-1][\"Accuracy\"][-1], result[4][-1][0].loc[0,\"acc by taking average\"], result[4][-1][0].loc[0,\"acc by simple vote\"], result[4][-1][0].loc[0,\"acc by refined vote\"]\n",
    "    \n",
    "def evaluate_logifold_and_baselines(adversarial_lgfd :AdvLogifold, adv_samples_labels : str, JUDGES_KEYS : List[Tuple], EXPERTS_KEYS : List[Tuple], EXPERTS_DIR : List[str], alpha : float, single_run : bool = False):\n",
    "    \n",
    "    '''\n",
    "    testing dataset:\n",
    "    \n",
    "    x_test = original test\n",
    "    adv_type = cwl2, deepfool, fgm, pgd_bigstep, pgd_std\n",
    "    generating model = resnet20v1_ver0 - 7, resnet20v2_ver0 - 3, resnet56v1_ver0 - 3, resnet56v2_ver0 - 3, vgg11_ver0 - 3, vgg13_ver0 - 3, vgg16_ver0 - 3, vgg19_ver0 - 3\n",
    "    directions = untargeted, targeted_to-least, targeted_to-2nd\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Load adversarial (val/test) numpy datasets\n",
    "    # ------------------------------------------------------------------\n",
    "    test_files = sorted(glob.glob(str(ADV_SAMPLES / \"*test*.npy\")))\n",
    "    adv_test_samples = {}\n",
    "    adv_val_samples = {}\n",
    "    for f in test_files:\n",
    "        name = Path(f).stem\n",
    "        parts = name.split('_')\n",
    "        parts_wo_test = [p for p in parts if p != 'test']\n",
    "        \n",
    "        val_name = name.replace('test','val', 1)\n",
    "        name = '-'.join(parts_wo_test)\n",
    "        adv_test_samples[name] = np.load(f)\n",
    "        val_path = ADV_SAMPLES / (val_name + '.npy')\n",
    "        if val_path.exists():\n",
    "            adv_val_samples[name] = np.load(str(val_path))\n",
    "        else:\n",
    "            print(f\"[warn] No val sample for {name}\")\n",
    "            adv_val_samples[name] = None\n",
    "        \n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Load baselines\n",
    "    # ------------------------------------------------------------------\n",
    "    original_baselines = {}\n",
    "    adversarial_trained_baselines = {}\n",
    "    if single_run:\n",
    "        for model_path in sorted(glob.glob(str(MODELS_DIR / \"*.keras\"))):\n",
    "            model_name = Path(model_path).stem\n",
    "            original_baselines[model_name] = load_model(model_path)\n",
    "        for model_path in sorted(glob.glob(str(ADV_MODELS_DIR / \"*.keras\"))):\n",
    "            model_name = Path(model_path).stem\n",
    "            adversarial_trained_baselines[model_name] = load_model(model_path)\n",
    "    \n",
    "    storage = cache_store.ResultStore(CACHE) # Storage for raw predictions\n",
    "    \n",
    "    baseline_rows = []          # per-model x per-dataset\n",
    "    logifold_rows = []          # Judges/All x per-dataset <-- All means Judges + Experts\n",
    "    adv_logifold_rows = []      # AdvLogifold x per-dataset <-- name of advlogifold is given by the dataset where experts are specialized on.\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Helper: run and record a single baseline model on a dataset\n",
    "    # ------------------------------------------------------------------\n",
    "    original_truth = y_test.reshape(-1)\n",
    "\n",
    "    def _eval_baseline_model(model_name, model, X, dataset_tag, y_true = original_truth):\n",
    "        preds = model.predict(X, verbose=0)\n",
    "        saved_to = storage.set_pred(model_name, dataset_tag, preds)\n",
    "        ans = np.argmax(preds, axis=-1)\n",
    "        acc = float(np.mean(ans == y_true.reshape(-1)))\n",
    "        baseline_rows.append({\n",
    "            \"model\": model_name,\n",
    "            \"dataset\": dataset_tag,\n",
    "            \"accuracy\": round(acc, 4),\n",
    "        })\n",
    "        print(f\"Saved raw predictions of {model_name} on {dataset_tag} to {saved_to}\")\n",
    "    # ------------------------------------------------------------------\n",
    "    # Evaluate baselines on ORIGINAL test\n",
    "    # ------------------------------------------------------------------\n",
    "    if single_run:\n",
    "        for model_name, m in {**original_baselines, **adversarial_trained_baselines}.items():\n",
    "            _eval_baseline_model(model_name, m, x_test,\"original_test\")\n",
    "\n",
    "\n",
    "    # evaluation on simple ensemble.\n",
    "    # We measure it using Logifold with certainty threshold = 0 which represents weighted voting with weight computed on validation dataset.\n",
    "    # We can also measure it using simple majority voting.\n",
    "    # For each dataset we save not only those simple voting results but also all logifold results.\n",
    "    # But let us start with original dataset.\n",
    "    logifold_rows = []\n",
    "    sample_name = 'original'\n",
    "    committee_sig = AdvLogifold._committee_sig_from_keys(JUDGES_KEYS)\n",
    "    all_sig = AdvLogifold._committee_sig_from_keys(JUDGES_KEYS+EXPERTS_KEYS)\n",
    "    experts_sig = AdvLogifold._committee_sig_from_keys(EXPERTS_KEYS)\n",
    "\n",
    "    Logifold.predict(\n",
    "        adversarial_lgfd, x_val, x_name = sample_name + '_val',y=y_val_categorical_10,\n",
    "        keys=JUDGES_KEYS,\n",
    "        evalOutputFile= 'evals/' + committee_sig + 'original_val_eval.csv',\n",
    "        show_av_acc=True, show_simple_vote=True, write_story=False\n",
    "    )\n",
    "    \n",
    "    _, _, _, _, result, _, _, _ = Logifold.predict(\n",
    "        adversarial_lgfd, x_test, x_name = sample_name + '_test', y=y_test_categorical_10,\n",
    "        keys=JUDGES_KEYS,\n",
    "        show_av_acc=True, show_simple_vote=True, write_story=False,\n",
    "        useHistory = 'evals/' + committee_sig + 'original_val_eval.csv'\n",
    "    ) # result1 is a list containing panda dataframe, list of figures, etc.\n",
    "    j_hist, j_avg, j_maj, j_wavg = _pick_acc(result)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Logifold.predict(\n",
    "        adversarial_lgfd, x_val, x_name = sample_name + '_val',y=y_val_categorical_10,\n",
    "        keys=JUDGES_KEYS + EXPERTS_KEYS,\n",
    "        evalOutputFile= 'evals/' + all_sig + 'original_val_eval.csv',\n",
    "        show_av_acc=True, show_simple_vote=True, write_story=False\n",
    "    )\n",
    "    _, _, _, _, result, _, _, _ = Logifold.predict(\n",
    "        adversarial_lgfd, x_test, x_name = sample_name + '_test', y=y_test_categorical_10,\n",
    "        keys=JUDGES_KEYS + EXPERTS_KEYS,\n",
    "        show_av_acc=True, show_simple_vote=True, write_story=False,\n",
    "        useHistory = 'evals/' + all_sig + 'original_val_eval.csv'\n",
    "    )\n",
    "    a_hist, a_avg, a_maj, a_wavg = _pick_acc(result)\n",
    "    \n",
    "    logifold_rows.append({\n",
    "        \"testing_dataset\": \"original\",\n",
    "        \"simple_majority_voting_by_Judges\": j_maj,\n",
    "        \"weighted_voting_by_Judges\": j_wavg,\n",
    "        \"average_voting_by_Judges\": j_avg,\n",
    "        \"using_val_history_by_Judges\": j_hist,\n",
    "        \"simple_majority_voting_by_all\": a_maj,\n",
    "        \"weighted_voting_by_all\": a_wavg,\n",
    "        \"average_voting_by_all\": a_avg,\n",
    "        \"using_val_history_by_all\": a_hist,\n",
    "    })\n",
    "    \n",
    "    \n",
    "    adversarial_lgfd.predict(\n",
    "        x_val, x_name= sample_name + '_val', y=y_val_categorical_10,\n",
    "        committee_Judge=JUDGES_KEYS,\n",
    "        committee_experts=EXPERTS_KEYS,\n",
    "        entropy_threshold=alpha,\n",
    "        show_av_acc=True, show_simple_vote=True,\n",
    "        reportSeq=[100],\n",
    "        evalOutputFile='evals/' + experts_sig + 'original_val_eval.csv',\n",
    "        write_story=False\n",
    "    )\n",
    "    _, _, _, _, result, _, _, _ = adversarial_lgfd.predict(\n",
    "        x_test, x_name = sample_name + '_test', y=y_test_categorical_10,\n",
    "        committee_Judge=JUDGES_KEYS,\n",
    "        committee_experts=EXPERTS_KEYS,\n",
    "        entropy_threshold=alpha,\n",
    "        show_av_acc=True, show_simple_vote=True,\n",
    "        reportSeq=[100],\n",
    "        useHistory='evals/' + experts_sig + f\"original_val_eval.csv\",\n",
    "        write_story=False\n",
    "    )\n",
    "    \n",
    "    r_hist, r_avg, r_maj, r_wavg = _pick_acc(result)\n",
    "    \n",
    "    adv_logifold_rows.append({\n",
    "        \"testing_dataset\": \"original\",\n",
    "        \"simple_majority_voting_by_all\": r_maj,\n",
    "        \"weighted_voting_by_all\": r_wavg,\n",
    "        \"average_voting_by_all\": r_avg,\n",
    "        \"using_val_history_by_all\": r_hist,\n",
    "        \"entropy_threshold\": alpha,\n",
    "    })\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Evaluate on each ADVERSARIAL sample\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    for testing_adv_label, value in adv_test_samples.items():\n",
    "        sample_name = testing_adv_label\n",
    "        adv_x_val = adv_val_samples[testing_adv_label]\n",
    "        if adv_x_val is None:\n",
    "            print(f\"[warn] No val sample for {testing_adv_label}, skipping validation history results and AdvLogifold results...\")\n",
    "            skip = True\n",
    "        else:\n",
    "            skip = False\n",
    "        adv_x_test = value\n",
    "        if single_run:\n",
    "            for model_name, m in {**original_baselines, **adversarial_trained_baselines}.items():\n",
    "                    _eval_baseline_model(model_name, m, adv_x_test, sample_name+\"_test\", y_true = original_truth)\n",
    "        if skip:\n",
    "            useHistory = None\n",
    "            _, _, _, _, resultJ, _, _, _ = Logifold.predict(\n",
    "                adversarial_lgfd, adv_x_test, x_name = sample_name + '_test', y=y_test_categorical_10,\n",
    "                keys=JUDGES_KEYS,\n",
    "                show_av_acc=True, show_simple_vote=True, write_story=False,\n",
    "                useHistory = useHistory\n",
    "            )\n",
    "            _, _, _, _, resultA, _, _, _ = Logifold.predict(\n",
    "            adversarial_lgfd, adv_x_test, x_name = sample_name + '_test', y=y_test_categorical_10,\n",
    "            keys=JUDGES_KEYS + EXPERTS_KEYS,\n",
    "            show_av_acc=True, show_simple_vote=True, write_story=False,\n",
    "            useHistory = useHistory\n",
    "        )\n",
    "            _, _, _, _, resultAdv, _, _, _ = adversarial_lgfd.predict(\n",
    "            adv_x_test, x_name = sample_name + '_test', y=y_test_categorical_10,\n",
    "            committee_Judge=JUDGES_KEYS,\n",
    "            committee_experts=EXPERTS_KEYS,\n",
    "            entropy_threshold=alpha,\n",
    "            show_av_acc=True, show_simple_vote=True,\n",
    "            reportSeq=[100],\n",
    "            useHistory= useHistory,\n",
    "            write_story=False\n",
    "        )\n",
    "        else:\n",
    "            useHistory = 'evals/' + committee_sig + f'{sample_name}_val_eval.csv'\n",
    "            Logifold.predict(\n",
    "                adversarial_lgfd, adv_x_val, x_name = sample_name + '_val',y=y_val_categorical_10,\n",
    "                keys=JUDGES_KEYS,\n",
    "                evalOutputFile= useHistory,\n",
    "                show_av_acc=True, show_simple_vote=True, write_story=False\n",
    "            )\n",
    "            \n",
    "            _, _, _, _, resultJ, _, _, _ = Logifold.predict(\n",
    "                adversarial_lgfd, adv_x_test, x_name = sample_name + '_test', y=y_test_categorical_10,\n",
    "                keys=JUDGES_KEYS,\n",
    "                show_av_acc=True, show_simple_vote=True, write_story=False,\n",
    "                useHistory = useHistory\n",
    "            )\n",
    "            useHistory = 'evals/' + all_sig + f'{sample_name}_val_eval.csv'\n",
    "            Logifold.predict(\n",
    "            adversarial_lgfd, adv_x_val, x_name = sample_name + '_val',y=y_val_categorical_10,\n",
    "            keys=JUDGES_KEYS + EXPERTS_KEYS,\n",
    "            evalOutputFile= useHistory,\n",
    "            show_av_acc=True, show_simple_vote=True, write_story=False\n",
    "        )\n",
    "            _, _, _, _, resultA, _, _, _ = Logifold.predict(\n",
    "                adversarial_lgfd, adv_x_test, x_name = sample_name + '_test', y=y_test_categorical_10,\n",
    "                keys=JUDGES_KEYS + EXPERTS_KEYS,\n",
    "                show_av_acc=True, show_simple_vote=True, write_story=False,\n",
    "                useHistory = useHistory\n",
    "            )\n",
    "            \n",
    "            useHistory = 'evals/' + experts_sig + f'{sample_name}_val_eval.csv'\n",
    "            adversarial_lgfd.predict(\n",
    "            adv_x_val, x_name= sample_name + '_val', y=y_val_categorical_10,\n",
    "            committee_Judge=JUDGES_KEYS,\n",
    "            committee_experts=EXPERTS_KEYS,\n",
    "            entropy_threshold=alpha,\n",
    "            show_av_acc=True, show_simple_vote=True,\n",
    "            reportSeq=[100],\n",
    "            evalOutputFile=useHistory,\n",
    "            write_story=False\n",
    "        )\n",
    "            _, _, _, _, resultAdv, _, _, _ = adversarial_lgfd.predict(\n",
    "            adv_x_test, x_name = sample_name + '_test', y=y_test_categorical_10,\n",
    "            committee_Judge=JUDGES_KEYS,\n",
    "            committee_experts=EXPERTS_KEYS,\n",
    "            entropy_threshold=alpha,\n",
    "            show_av_acc=True, show_simple_vote=True,\n",
    "            reportSeq=[100],\n",
    "            useHistory=useHistory,\n",
    "            write_story=False\n",
    "        )\n",
    "            \n",
    "        j_hist, j_avg, j_maj, j_wavg = _pick_acc(resultJ)\n",
    "        a_hist, a_avg, a_maj, a_wavg = _pick_acc(resultA)\n",
    "        r_hist, r_avg, r_maj, r_wavg = _pick_acc(resultAdv)\n",
    "\n",
    "        logifold_rows.append({\n",
    "            \"testing_dataset\": sample_name,\n",
    "            \"simple_majority_voting_by_Judges\": j_maj,\n",
    "            \"weighted_voting_by_Judges\": j_wavg,\n",
    "            \"average_voting_by_Judges\": j_avg,\n",
    "            \"using_val_history_by_Judges\": j_hist,\n",
    "            \"simple_majority_voting_by_all\": a_maj,\n",
    "            \"weighted_voting_by_all\": a_wavg,\n",
    "            \"average_voting_by_all\": a_avg,\n",
    "            \"using_val_history_by_all\": a_hist,\n",
    "        })\n",
    "        \n",
    "        adv_logifold_rows.append({\n",
    "            \"testing_dataset\": sample_name,\n",
    "            \"simple_majority_voting_by_all\": r_maj,\n",
    "            \"weighted_voting_by_all\": r_wavg,\n",
    "            \"average_voting_by_all\": r_avg,\n",
    "            \"using_val_history_by_all\": r_hist,\n",
    "            \"entropy_threshold\": alpha,\n",
    "        })\n",
    "        \n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Save & return results\n",
    "    # ------------------------------------------------------------------\n",
    "    out_dir = ANALYSIS / \"results\"\n",
    "    if not out_dir.exists():\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if single_run:\n",
    "        df_baselines   = pd.DataFrame(baseline_rows).sort_values([\"dataset\", \"model\"])\n",
    "        f1 = out_dir / \"baseline_single_models.csv\"\n",
    "        df_baselines.to_csv(f1, index=False)\n",
    "        print(f\"[ok] Saved baseline results to:   {f1}\")\n",
    "        \n",
    "    df_logifold    = pd.DataFrame(logifold_rows).sort_values([\"testing_dataset\"])\n",
    "    df_advlogifold = pd.DataFrame(adv_logifold_rows).sort_values([\"testing_dataset\"])\n",
    "\n",
    "    \n",
    "    f2 = out_dir / f\"logifold_committees_experts-{adv_samples_labels}.csv\"\n",
    "    f3 = out_dir / f\"advlogifold_routed_experts-{adv_samples_labels}.csv\"\n",
    "\n",
    "    \n",
    "    df_logifold.to_csv(f2, index=False)\n",
    "    df_advlogifold.to_csv(f3, index=False)\n",
    "\n",
    "    \n",
    "    print(f\"[ok] Saved Logifold results to:    {f2}\")\n",
    "    print(f\"[ok] Saved AdvLogifold results to: {f3}\")\n",
    "\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff476f4",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca37ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgfd_key_record = {}\n",
    "adversarial_lgfd, JUDGES_KEYS = construct_or_load_logifold(num_classes=10)\n",
    "attack_entries = ['DeepFool']\n",
    "experts_keys, experts_paths, alpha = specialize_Committee(adversarial_lgfd, JUDGES_KEYS, adv_short_tag = attack_entries[1])\n",
    "\n",
    "lgfd_key_record[(attack_entries[0], 'untargeted')] = (experts_keys, experts_paths, alpha)\n",
    "evaluate_logifold_and_baselines(adversarial_lgfd, adv_samples_labels = f\"{attack_entries[1]}_untargeted\", JUDGES_KEYS = JUDGES_KEYS, EXPERTS_KEYS = experts_keys, EXPERTS_DIR = experts_paths, alpha = alpha, single_run = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
