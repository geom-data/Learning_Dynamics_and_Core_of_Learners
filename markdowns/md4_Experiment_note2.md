# '24. October Experiment note



## Hypothesis

1. Having trained model on (original  adversarials) and expert derived
from the model will improve overall accuracy.

2. Logifold structure provides further improvements.



## Made adversarial examples
See "How Adversarial Examples were Genetrated?" [in this note](/markdowns/md2_generation.md) and 
 [Brief Note on Adversarial attack methods](/markdowns/md1_NoteOnAdversarial.md) to review what adversarial attacks are.

Design experiment, but there are too many combinations to conduct.
See "experiment design" [in this note](/markdowns/md2_generation.md).

And there were some mistakes... let me record it.





## Experiment procedure

Adversarial examples are generated by PGD method with $\epsilon = 0.396$, untargeted way.
### Preprocessing data
```
(x, y), (x_test, y_test)= cifar10.load_data()
x_tr, x_v, y_tr, y_v = train_test_split(x, y, test_size=0.2, random_state=42)
x_tr = x_tr.reshape(x_tr.shape[0],32,32,3)
x_v = x_v.reshape(x_v.shape[0],32,32,3)
x_v = x_v.astype('float32')
x_tr = x_tr.astype('float32')
x_v /= 255
x_tr /= 255
x_train, x_val, y_train, y_val = x_tr,x_v,y_tr,y_v
x_test = x_test.reshape(x_test.shape[0],32,32,3)
x_test = x_test.astype('float32')
x_test /= 255
```
### Prepare for logifold : Construct models
Base model : resnet56v1

Full model : Trained model on pulluted data in $1:1$ ratio with ResNet56v1 structure.

Filter model(trained) : Trained model, having only two targets ([Origianal], [Adversaries])

Filter model(specialized) : Specialized model from **full model**, having only two targets as above.

Filter model(specialized) : Specialized model from **base model**, having only two targets as above.

Adversaries are generated from ResNet56v1 model.

```
resnet56v1 =  load_model('CIFAR10models/n_9_v1_cifar10.keras')

training_y_long =np.concatenate([y_train,y_train+10],axis=0)
training_y_long = keras.utils.to_categorical(training_y_long,20)
validating_y_long =np.concatenate([y_v,y_v+10],axis=0)
validating_y_long = keras.utils.to_categorical(validating_y_long,20)

path = 'adversarial_models/untargeted_trained_20targets.keras'

adv_x_tr = np.load("adversarial_examples/pgd_0.376_x_untarget.npy")
adv_x_val = np.load("adversarial_examples/pgd_0.376_x_val_untarget.npy")

training_x = np.concatenate([x_tr,adv_x_tr],axis=0)
validating_x = np.concatenate([x_v,adv_x_val],axis=0)

resnet = ResNet(path,
                training_x,training_y_long,
                validating_x,validating_y_long,
                n=9,version=1) 
resnet.train(save_best_only=True,epochs=200)
full_model = load_model('adversarial_models/untargeted_trained_20targets.keras')


path = 'adversarial_models/untargeted_trained_filter.keras'
filter_y_tr = np.zeros((40000,1),dtype='uint8')
filter_y_tr = np.concatenate([filter_y_tr,filter_y_tr+1],axis=0)
filter_y_tr = keras.utils.to_categorical(filter_y_tr,2)
filter_y_val = np.zeros((10000,1),dtype='uint8')
filter_y_val = np.concatenate([filter_y_val,filter_y_val+1],axis=0)
filter_y_val = keras.utils.to_categorical(filter_y_val,2)
resnet = ResNet(path,training_x,filter_y_tr,validating_x,filter_y_val,n=9,version=1)
resnet.train(save_best_only=True,epochs=200)


path = 'adversarial_models/untargeted_specialized_filter_from20targets.keras'
model = load_model('adversarial_models/untargeted_trained_20targets.keras')
base = Model(inputs = model.inputs, outputs = model.layers[-2].output, name='base')             
inputs = keras.Input(shape=model.layers[0].input_shape[0][1:],name='Input')
y = base(inputs)
y = Dense(2,name='Dense')(y)
outputs = layers.Softmax(name=f'Softmax')(y)
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=opt, 
                loss=tf.keras.losses.CategoricalCrossentropy(), 
                metrics=["accuracy"])
checkpoint = ModelCheckpoint(filepath=path,
                            monitor='val_accuracy',
                            verbose=1,
                            save_best_only=True,
                            save_weights_only=False)
callbacks = [checkpoint, lr_reducer, lr_scheduler]
model.save(path)
hist = model.fit(training_x, filter_y_tr, 
                    batch_size=128,
                    validation_data=(validating_x, filter_y_val), 
                    epochs=20,
                    callbacks=callbacks,
                    verbose=1)

(same for the specialized filter from base model with path 'adversarial_models/untargeted_specialized_filter_from10targets.keras' and model = resNet56v1)
````

note : both specialized models have high $\simeq 99.5\%$.

### Construct a logifold


```
lgfd = logifold.Logifold(20,
                            name = "test20241124",
                            x_tr = training_x,
                            y_tr = training_y_long,
                            x_v = validating_x,
                            y_v = validating_y_long, 
                            path = 'logifold_test20241124/',
                            storyFile='story')
```

| key | model | targets |
| --- | --- | --- |
| (0,0,0) | ResNet56v1(Base model) | original 10 targets (0 - 9)|
|(0,0,0,0)| ResNet56v1(Trained on original + adversaries)| all 20 targets (0 - 20)|
| (0,1,0) | Trained on Adversaries | Adversarial 10 targets (10 - 19)|
| (0,2,0) | Specialized from Base model | Adversarial 10 targets (10 - 19)|
| (0,0,1) | Specialized from (0,0,0,0) | Filter. Two targets (original, adversaries)|
| (0,0,2) | Specialized from Base model | Filter. Two targets (original, adversaries)|

### Testing dataset


```
testing_y_long =np.concatenate([y_test,y_test+10],axis=0)
testing_y_long = keras.utils.to_categorical(testing_y_long,20)
adv_x_test = np.load("adversarial_examples/pgd_0.376_x_test_untarget.npy")
testing_x = np.concatenate([x_test,adv_x_test],axis=0)
```


| Model           | Testing Dataset         | Accuracy |
|-------------------|-------------------------|----------|
| Base   | Original Testing Dataset | 0.8785   |
| Base    | Adversarial Testing Dataset | 0.0097   |
| Adversarial Model  | Original Testing Dataset | 0.783    |
| Adversarial Model | Adversarial Testing Dataset | 0.8868   |

In Logifold, with 1:1 pullution testing dataset, using validation history, 

| Models          |           Accuracy (Validation accuracy) |
|-------------------------------------------|----------|
| key = (0,0,0,0). Full and Fine model | 0.8269  (0.9159) |
| Base + Filter specialized from (0,0,0,0) + Adversarial, trained    | 0.8783 (0.9589)  |
| Base + Filter specialized from base + Adversarial, trained   | 0.8775  (0.9583) |
| Base + Filter specialized from base + Adversarial, specialized from base | 0.822 (0.9322)   |
| All experts Specialized from (0,0,0,0)| 0.9022 (0.9304)   |
| All experts Specialized from (0,0,0,0) + (0,0,0,0)| 0.9081 (0.9112)   |


# Conclusion

1. Logifold outperforms single base models.
2. Specializing base models does not enhance performance.

Further experiments will be..

1. Explore different types of adversarial examples (untargeted -> targeted to least likely target or 2nd likely target, or CWL2 type, or DeepFool). DeepFool has not been generated yet.
2. Train models on PGD-type adversaries and defend against CWL2 attacks, and vice versa.
3. Use different structures for generating model, models in logifold, and model trained on adversaries.

What's the purpose?

We aim to demonstrate that (1) the Logifold structure provides a better approach to adversarial attacks and (2) it can be enhanced by incorporating models refined through adversarial examples. Additionally, we seek to determine if Logifold can assess the pollution level of a dataset.